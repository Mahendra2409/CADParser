{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl -f https://data.dgl.ai/wheels/cu121/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzIIuR9ZxCI-",
        "outputId": "6ed5f639-0252-46c9-807a-ef2f4b6779ce",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/cu121/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/cu121/dgl-2.1.0%2Bcu121-cp310-cp310-manylinux1_x86_64.whl (467.5 MB)\n",
            "\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/467.5 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sRJBNvZ7e5w",
        "outputId": "fa44d9d6-c67f-4edd-aee9-b0fc21e3e641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, dgl\n",
            "Successfully installed dgl-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.spatial.transform import Rotation\n",
        "\n",
        "\n",
        "def bounding_box_uvgrid(inp: torch.Tensor):\n",
        "    pts = inp[..., :3].reshape((-1, 3))\n",
        "    mask = inp[..., 6].reshape(-1)\n",
        "    point_indices_inside_faces = mask == 1\n",
        "    pts = pts[point_indices_inside_faces, :]\n",
        "    return bounding_box_pointcloud(pts)\n",
        "\n",
        "\n",
        "def bounding_box_pointcloud(pts: torch.Tensor):\n",
        "    x = pts[:, 0]\n",
        "    y = pts[:, 1]\n",
        "    z = pts[:, 2]\n",
        "    box = [[x.min(), y.min(), z.min()], [x.max(), y.max(), z.max()]]\n",
        "    return torch.tensor(box)\n",
        "\n",
        "\n",
        "def center_and_scale_uvgrid(inp: torch.Tensor, return_center_scale=False):\n",
        "    bbox = bounding_box_uvgrid(inp)\n",
        "    diag = bbox[1] - bbox[0]\n",
        "    scale = 2.0 / max(diag[0], diag[1], diag[2])\n",
        "    center = 0.5 * (bbox[0] + bbox[1])\n",
        "    inp[..., :3] -= center\n",
        "    inp[..., :3] *= scale\n",
        "    if return_center_scale:\n",
        "        return inp, center, scale\n",
        "    return inp\n",
        "\n",
        "\n",
        "def get_random_rotation():\n",
        "    \"\"\"Get a random rotation in 90 degree increments along the canonical axes\"\"\"\n",
        "    axes = [\n",
        "        np.array([1, 0, 0]),\n",
        "        np.array([0, 1, 0]),\n",
        "        np.array([0, 0, 1]),\n",
        "    ]\n",
        "    angles = [0.0, 90.0, 180.0, 270.0]\n",
        "    axis = random.choice(axes)\n",
        "    angle_radians = np.radians(random.choice(angles))\n",
        "    return Rotation.from_rotvec(angle_radians * axis)\n",
        "\n",
        "\n",
        "def rotate_uvgrid(inp, rotation):\n",
        "    \"\"\"Rotate the node features in the graph by a given rotation\"\"\"\n",
        "    Rmat = torch.tensor(rotation.as_matrix()).float()\n",
        "    orig_size = inp[..., :3].size()\n",
        "    inp[..., :3] = torch.mm(inp[..., :3].view(-1, 3), Rmat).view(\n",
        "        orig_size\n",
        "    )  # Points\n",
        "    inp[..., 3:6] = torch.mm(inp[..., 3:6].view(-1, 3), Rmat).view(\n",
        "        orig_size\n",
        "    )  # Normals/tangents\n",
        "    return inp\n",
        "\n",
        "\n",
        "INVALID_FONTS = [\n",
        "    \"Bokor\",\n",
        "    \"Lao Muang Khong\",\n",
        "    \"Lao Sans Pro\",\n",
        "    \"MS Outlook\",\n",
        "    \"Catamaran Black\",\n",
        "    \"Dubai\",\n",
        "    \"HoloLens MDL2 Assets\",\n",
        "    \"Lao Muang Don\",\n",
        "    \"Oxanium Medium\",\n",
        "    \"Rounded Mplus 1c\",\n",
        "    \"Moul Pali\",\n",
        "    \"Noto Sans Tamil\",\n",
        "    \"Webdings\",\n",
        "    \"Armata\",\n",
        "    \"Koulen\",\n",
        "    \"Yinmar\",\n",
        "    \"Ponnala\",\n",
        "    \"Noto Sans Tamil\",\n",
        "    \"Chenla\",\n",
        "    \"Lohit Devanagari\",\n",
        "    \"Metal\",\n",
        "    \"MS Office Symbol\",\n",
        "    \"Cormorant Garamond Medium\",\n",
        "    \"Chiller\",\n",
        "    \"Give You Glory\",\n",
        "    \"Hind Vadodara Light\",\n",
        "    \"Libre Barcode 39 Extended\",\n",
        "    \"Myanmar Sans Pro\",\n",
        "    \"Scheherazade\",\n",
        "    \"Segoe MDL2 Assets\",\n",
        "    \"Siemreap\",\n",
        "    \"Signika SemiBold\" \"Taprom\",\n",
        "    \"Times New Roman TUR\",\n",
        "    \"Playfair Display SC Black\",\n",
        "    \"Poppins Thin\",\n",
        "    \"Raleway Dots\",\n",
        "    \"Raleway Thin\",\n",
        "    \"Segoe MDL2 Assets\",\n",
        "    \"Segoe MDL2 Assets\",\n",
        "    \"Spectral SC ExtraLight\",\n",
        "    \"Txt\",\n",
        "    \"Uchen\",\n",
        "    \"Yinmar\",\n",
        "    \"Almarai ExtraBold\",\n",
        "    \"Fasthand\",\n",
        "    \"Exo\",\n",
        "    \"Freckle Face\",\n",
        "    \"Montserrat Light\",\n",
        "    \"Inter\",\n",
        "    \"MS Reference Specialty\",\n",
        "    \"MS Outlook\",\n",
        "    \"Preah Vihear\",\n",
        "    \"Sitara\",\n",
        "    \"Barkerville Old Face\",\n",
        "    \"Bodoni MT\" \"Bokor\",\n",
        "    \"Fasthand\",\n",
        "    \"HoloLens MDL2 Assests\",\n",
        "    \"Libre Barcode 39\",\n",
        "    \"Lohit Tamil\",\n",
        "    \"Marlett\",\n",
        "    \"MS outlook\",\n",
        "    \"MS office Symbol Semilight\",\n",
        "    \"MS office symbol regular\",\n",
        "    \"Ms office symbol extralight\",\n",
        "    \"Ms Reference speciality\",\n",
        "    \"Segoe MDL2 Assets\",\n",
        "    \"Siemreap\",\n",
        "    \"Sitara\",\n",
        "    \"Symbol\",\n",
        "    \"Wingdings\",\n",
        "    \"Metal\",\n",
        "    \"Ponnala\",\n",
        "    \"Webdings\",\n",
        "    \"Souliyo Unicode\",\n",
        "    \"Aguafina Script\",\n",
        "    \"Yantramanav Black\",\n",
        "    # \"Yaldevi\",\n",
        "    # Taprom,\n",
        "    # \"Zhi Mang Xing\",\n",
        "    # \"Taviraj\",\n",
        "    # \"SeoulNamsan EB\",\n",
        "]\n",
        "\n",
        "\n",
        "def valid_font(filename):\n",
        "    for name in INVALID_FONTS:\n",
        "        if name.lower() in str(filename).lower():\n",
        "            return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "ecmjwzSkXuKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import FloatTensor\n",
        "import dgl\n",
        "from dgl.data.utils import load_graphs\n",
        "from tqdm import tqdm\n",
        "from abc import abstractmethod\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import dgl\n",
        "from torch import FloatTensor, stack\n",
        "\n",
        "class BaseDataset(Dataset):\n",
        "    @staticmethod\n",
        "    def num_classes():\n",
        "        pass\n",
        "\n",
        "    def __init__(self, X_train, Y_train):\n",
        "        \"\"\"\n",
        "        self.data is a list of dictionaries with keys graph and label\n",
        "        \"\"\"\n",
        "        assert len(X_train) == len(Y_train), \"The number of graphs must match the number of labels\"\n",
        "        self.data = [{\"graph\": graph, \"label\": label} for graph, label in zip(X_train, Y_train)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        return sample[\"graph\"], sample[\"label\"]  # Returns a tuple of the sample graph and its corresponding label\n",
        "\n",
        "    # def _collate(self, batch):\n",
        "    #     graphs, labels = zip(*batch)\n",
        "    #     batched_graph = dgl.batch(graphs)\n",
        "    #     if any(label.ndim > 1 for label in labels):  # Check if any labels have more than one dimension\n",
        "    #         # Assuming labels are 2D and you want to pad along the first dimension\n",
        "    #         padded_labels = pad_sequence([torch.tensor(label, dtype=torch.float32) for label in labels], batch_first=True, padding_value=0)\n",
        "    #     else:\n",
        "    #         # Convert labels to tensor directly if they are all the same size or 1D\n",
        "    #         padded_labels = torch.tensor(labels)\n",
        "    #     return {\"graph\": batched_graph, \"labels\": padded_labels}\n",
        "\n",
        "    def _collate(self, batch):\n",
        "        graphs, labels = zip(*batch)\n",
        "        batched_graph = dgl.batch(graphs)\n",
        "\n",
        "        # Create a default padding command vector\n",
        "        pad_vector = torch.tensor([6] + [-1]*16, dtype=torch.float32)\n",
        "\n",
        "        # Prepare labels with padding\n",
        "        padded_labels = []\n",
        "        for label in labels:\n",
        "            label_length = label.shape[0]\n",
        "            if label_length < 60:\n",
        "                # Calculate how many padding vectors are needed\n",
        "                padding_count = 60 - label_length\n",
        "                # Create a tensor of padding vectors\n",
        "                padding = pad_vector.repeat(padding_count, 1)\n",
        "                # Concatenate the original label with the padding\n",
        "                padded_label = torch.cat([torch.tensor(label, dtype=torch.float32), padding], dim=0)\n",
        "            else:\n",
        "                padded_label = torch.tensor(label, dtype=torch.float32)\n",
        "            padded_labels.append(padded_label)\n",
        "\n",
        "        # Stack all the padded labels into a single tensor\n",
        "        padded_labels = stack(padded_labels)\n",
        "\n",
        "        return {\"graph\": batched_graph, \"labels\": padded_labels}\n",
        "\n",
        "\n",
        "    def get_dataloader(self, batch_size=128, shuffle=True, num_workers=0):\n",
        "        return DataLoader(\n",
        "            self,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            collate_fn=self._collate,\n",
        "            num_workers=num_workers,  # Can be set to non-zero on Linux\n",
        "            drop_last=True\n",
        "        )\n"
      ],
      "metadata": {
        "id": "y7DSBZ2eWU0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb5a810-8c5e-45cb-ed40-8fe604c99e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from dgl.nn.pytorch.conv import NNConv\n",
        "from dgl.nn.pytorch.glob import MaxPooling"
      ],
      "metadata": {
        "id": "RLIY6EKQYAzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Layers"
      ],
      "metadata": {
        "id": "iqwTN_X5i8F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _conv1d(in_channels, out_channels, kernel_size=3, padding=0, bias=False):\n",
        "    \"\"\"\n",
        "    Helper function to create a 1D convolutional layer with batchnorm and LeakyReLU activation\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Input channels\n",
        "        out_channels (int): Output channels\n",
        "        kernel_size (int, optional): Size of the convolutional kernel. Defaults to 3.\n",
        "        padding (int, optional): Padding size on each side. Defaults to 0.\n",
        "        bias (bool, optional): Whether bias is used. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        nn.Sequential: Sequential contained the Conv1d, BatchNorm1d and LeakyReLU layers\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        nn.Conv1d(\n",
        "            in_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=bias\n",
        "        ),\n",
        "        nn.BatchNorm1d(out_channels),\n",
        "        nn.LeakyReLU(),\n",
        "    )\n",
        "\n",
        "\n",
        "def _conv2d(in_channels, out_channels, kernel_size, padding=0, bias=False):\n",
        "    \"\"\"\n",
        "    Helper function to create a 2D convolutional layer with batchnorm and LeakyReLU activation\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Input channels\n",
        "        out_channels (int): Output channels\n",
        "        kernel_size (int, optional): Size of the convolutional kernel. Defaults to 3.\n",
        "        padding (int, optional): Padding size on each side. Defaults to 0.\n",
        "        bias (bool, optional): Whether bias is used. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        nn.Sequential: Sequential contained the Conv2d, BatchNorm2d and LeakyReLU layers\n",
        "    \"\"\"\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            padding=padding,\n",
        "            bias=bias,\n",
        "        ),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.LeakyReLU(),\n",
        "    )\n",
        "\n",
        "\n",
        "def _fc(in_features, out_features, bias=False):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_features, out_features, bias=bias),\n",
        "        nn.BatchNorm1d(out_features),\n",
        "        nn.LeakyReLU(),\n",
        "    )"
      ],
      "metadata": {
        "id": "6PZVEEGri69Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MLP Modules"
      ],
      "metadata": {
        "id": "cJkyB_cJjHAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class _MLP(nn.Module):\n",
        "    \"\"\"\"\"\"\n",
        "\n",
        "    def __init__(self, num_layers, input_dim, hidden_dim, output_dim):\n",
        "        \"\"\"\n",
        "        MLP with linear output\n",
        "        Args:\n",
        "            num_layers (int): The number of linear layers in the MLP\n",
        "            input_dim (int): Input feature dimension\n",
        "            hidden_dim (int): Hidden feature dimensions for all hidden layers\n",
        "            output_dim (int): Output feature dimension\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If the given number of layers is <1\n",
        "        \"\"\"\n",
        "        super(_MLP, self).__init__()\n",
        "        self.linear_or_not = True  # default is linear model\n",
        "        self.num_layers = num_layers\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        if num_layers < 1:\n",
        "            raise ValueError(\"Number of layers should be positive!\")\n",
        "        elif num_layers == 1:\n",
        "            # Linear model\n",
        "            self.linear = nn.Linear(input_dim, output_dim)\n",
        "        else:\n",
        "            # Multi-layer model\n",
        "            self.linear_or_not = False\n",
        "            self.linears = torch.nn.ModuleList()\n",
        "            self.batch_norms = torch.nn.ModuleList()\n",
        "\n",
        "            self.linears.append(nn.Linear(input_dim, hidden_dim))\n",
        "            for layer in range(num_layers - 2):\n",
        "                self.linears.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            self.linears.append(nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "            # TODO: this could move inside the above loop\n",
        "            for layer in range(num_layers - 1):\n",
        "                self.batch_norms.append(nn.BatchNorm1d((hidden_dim)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.linear_or_not:\n",
        "            # If linear model\n",
        "            return self.linear(x)\n",
        "        else:\n",
        "            # If MLP\n",
        "            h = x\n",
        "            for i in range(self.num_layers - 1):\n",
        "                h = F.relu(self.batch_norms[i](self.linears[i](h)))\n",
        "            return self.linears[-1](h)"
      ],
      "metadata": {
        "id": "_0HwNvTsjGCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#UV-Net Curve Encoder and Surface Encoder"
      ],
      "metadata": {
        "id": "avV6r5l9jUcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UVNetCurveEncoder(nn.Module):\n",
        "    def __init__(self, in_channels=6, output_dims=64):\n",
        "        \"\"\"\n",
        "        This is the 1D convolutional network that extracts features from the B-rep edge\n",
        "        geometry described as 1D UV-grids (see Section 3.2, Curve & surface convolution\n",
        "        in paper)\n",
        "\n",
        "        Args:\n",
        "            in_channels (int, optional): Number of channels in the edge UV-grids. By default\n",
        "                                         we expect 3 channels for point coordinates and 3 for\n",
        "                                         curve tangents. Defaults to 6.\n",
        "            output_dims (int, optional): Output curve embedding dimension. Defaults to 64.\n",
        "        \"\"\"\n",
        "        super(UVNetCurveEncoder, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.conv1 = _conv1d(in_channels, 64, kernel_size=3, padding=1, bias=False)\n",
        "        self.conv2 = _conv1d(64, 128, kernel_size=3, padding=1, bias=False)\n",
        "        self.conv3 = _conv1d(128, 256, kernel_size=3, padding=1, bias=False)\n",
        "        self.final_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = _fc(256, output_dims, bias=False)\n",
        "\n",
        "        for m in self.modules():\n",
        "            self.weights_init(m)\n",
        "\n",
        "    def weights_init(self, m):\n",
        "        if isinstance(m, (nn.Linear, nn.Conv1d)):\n",
        "            torch.nn.init.kaiming_uniform_(m.weight.data)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.fill_(0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert x.size(1) == self.in_channels\n",
        "        batch_size = x.size(0)\n",
        "        x = x.float()\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.final_pool(x)\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UVNetSurfaceEncoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=7,\n",
        "        output_dims=64,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        This is the 2D convolutional network that extracts features from the B-rep face\n",
        "        geometry described as 2D UV-grids (see Section 3.2, Curve & surface convolution\n",
        "        in paper)\n",
        "\n",
        "        Args:\n",
        "            in_channels (int, optional): Number of channels in the edge UV-grids. By default\n",
        "                                         we expect 3 channels for point coordinates and 3 for\n",
        "                                         surface normals and 1 for the trimming mask. Defaults\n",
        "                                         to 7.\n",
        "            output_dims (int, optional): Output surface embedding dimension. Defaults to 64.\n",
        "        \"\"\"\n",
        "        super(UVNetSurfaceEncoder, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.conv1 = _conv2d(in_channels, 64, 3, padding=1, bias=False)\n",
        "        self.conv2 = _conv2d(64, 128, 3, padding=1, bias=False)\n",
        "        self.conv3 = _conv2d(128, 256, 3, padding=1, bias=False)\n",
        "        self.final_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = _fc(256, output_dims, bias=False)\n",
        "        for m in self.modules():\n",
        "            self.weights_init(m)\n",
        "\n",
        "    def weights_init(self, m):\n",
        "        if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
        "            torch.nn.init.kaiming_uniform_(m.weight.data)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.fill_(0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert x.size(1) == self.in_channels\n",
        "        batch_size = x.size(0)\n",
        "        x = x.float()\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.final_pool(x)\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "HnLy3iw8jSGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Encoder"
      ],
      "metadata": {
        "id": "QT8BzVuwjhuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class _EdgeConv(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        edge_feats,\n",
        "        out_feats,\n",
        "        node_feats,\n",
        "        num_mlp_layers=2,\n",
        "        hidden_mlp_dim=64,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        This module implements Eq. 2 from the paper where the edge features are\n",
        "        updated using the node features at the endpoints.\n",
        "\n",
        "        Args:\n",
        "            edge_feats (int): Input edge feature dimension\n",
        "            out_feats (int): Output feature deimension\n",
        "            node_feats (int): Input node feature dimension\n",
        "            num_mlp_layers (int, optional): Number of layers used in the MLP. Defaults to 2.\n",
        "            hidden_mlp_dim (int, optional): Hidden feature dimension in the MLP. Defaults to 64.\n",
        "        \"\"\"\n",
        "        super(_EdgeConv, self).__init__()\n",
        "        self.proj = _MLP(1, node_feats, hidden_mlp_dim, edge_feats)\n",
        "        self.mlp = _MLP(num_mlp_layers, edge_feats, hidden_mlp_dim, out_feats)\n",
        "        self.batchnorm = nn.BatchNorm1d(out_feats)\n",
        "        self.eps = torch.nn.Parameter(torch.FloatTensor([0.0]))\n",
        "\n",
        "    def forward(self, graph, nfeat, efeat):\n",
        "        src, dst = graph.edges()\n",
        "        proj1, proj2 = self.proj(nfeat[src]), self.proj(nfeat[dst])\n",
        "        agg = proj1 + proj2\n",
        "        h = self.mlp((1 + self.eps) * efeat + agg)\n",
        "        h = F.leaky_relu(self.batchnorm(h))\n",
        "        return h\n",
        "\n",
        "\n",
        "class _NodeConv(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_feats,\n",
        "        out_feats,\n",
        "        edge_feats,\n",
        "        num_mlp_layers=2,\n",
        "        hidden_mlp_dim=64,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        This module implements Eq. 1 from the paper where the node features are\n",
        "        updated using the neighboring node and edge features.\n",
        "\n",
        "        Args:\n",
        "            node_feats (int): Input edge feature dimension\n",
        "            out_feats (int): Output feature deimension\n",
        "            node_feats (int): Input node feature dimension\n",
        "            num_mlp_layers (int, optional): Number of layers used in the MLP. Defaults to 2.\n",
        "            hidden_mlp_dim (int, optional): Hidden feature dimension in the MLP. Defaults to 64.\n",
        "        \"\"\"\n",
        "        super(_NodeConv, self).__init__()\n",
        "        self.gconv = NNConv(\n",
        "            in_feats=node_feats,\n",
        "            out_feats=out_feats,\n",
        "            edge_func=nn.Linear(edge_feats, node_feats * out_feats),\n",
        "            aggregator_type=\"sum\",\n",
        "            bias=False,\n",
        "        )\n",
        "        self.batchnorm = nn.BatchNorm1d(out_feats)\n",
        "        self.mlp = _MLP(num_mlp_layers, node_feats, hidden_mlp_dim, out_feats)\n",
        "        self.eps = torch.nn.Parameter(torch.FloatTensor([0.0]))\n",
        "\n",
        "    def forward(self, graph, nfeat, efeat):\n",
        "        h = (1 + self.eps) * nfeat\n",
        "        h = self.gconv(graph, h, efeat)\n",
        "        h = self.mlp(h)\n",
        "        h = F.leaky_relu(self.batchnorm(h))\n",
        "        return h\n",
        "\n",
        "\n",
        "class UVNetGraphEncoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim,\n",
        "        input_edge_dim,\n",
        "        output_dim,\n",
        "        hidden_dim=64,\n",
        "        learn_eps=True,\n",
        "        num_layers=3,\n",
        "        num_mlp_layers=2,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        This is the graph neural network used for message-passing features in the\n",
        "        face-adjacency graph.\n",
        "\n",
        "        Args:\n",
        "            input_dim ([type]): [description]\n",
        "            input_edge_dim ([type]): [description]\n",
        "            output_dim ([type]): [description]\n",
        "            hidden_dim (int, optional): [description]. Defaults to 64.\n",
        "            learn_eps (bool, optional): [description]. Defaults to True.\n",
        "            num_layers (int, optional): [description]. Defaults to 3.\n",
        "            num_mlp_layers (int, optional): [description]. Defaults to 2.\n",
        "        \"\"\"\n",
        "        super(UVNetGraphEncoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.learn_eps = learn_eps\n",
        "\n",
        "        # List of layers for node and edge feature message passing\n",
        "        self.node_conv_layers = torch.nn.ModuleList()\n",
        "        self.edge_conv_layers = torch.nn.ModuleList()\n",
        "\n",
        "        for layer in range(self.num_layers - 1):\n",
        "            node_feats = input_dim if layer == 0 else hidden_dim\n",
        "            edge_feats = input_edge_dim if layer == 0 else hidden_dim\n",
        "            self.node_conv_layers.append(\n",
        "                _NodeConv(\n",
        "                    node_feats=node_feats,\n",
        "                    out_feats=hidden_dim,\n",
        "                    edge_feats=edge_feats,\n",
        "                    num_mlp_layers=num_mlp_layers,\n",
        "                    hidden_mlp_dim=hidden_dim,\n",
        "                ),\n",
        "            )\n",
        "            self.edge_conv_layers.append(\n",
        "                _EdgeConv(\n",
        "                    edge_feats=edge_feats,\n",
        "                    out_feats=hidden_dim,\n",
        "                    node_feats=node_feats,\n",
        "                    num_mlp_layers=num_mlp_layers,\n",
        "                    hidden_mlp_dim=hidden_dim,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Linear function for graph poolings of output of each layer\n",
        "        # which maps the output of different layers into a prediction score\n",
        "        self.linears_prediction = torch.nn.ModuleList()\n",
        "\n",
        "        for layer in range(num_layers):\n",
        "            if layer == 0:\n",
        "                self.linears_prediction.append(nn.Linear(input_dim, output_dim))\n",
        "            else:\n",
        "                self.linears_prediction.append(nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.drop1 = nn.Dropout(0.3)\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        self.pool = MaxPooling()\n",
        "\n",
        "    def forward(self, g, h, efeat):\n",
        "        hidden_rep = [h]\n",
        "        he = efeat\n",
        "\n",
        "        for i in range(self.num_layers - 1):\n",
        "            # Update node features\n",
        "            h = self.node_conv_layers[i](g, h, he)\n",
        "            # Update edge features\n",
        "            he = self.edge_conv_layers[i](g, h, he)\n",
        "            hidden_rep.append(h)\n",
        "\n",
        "        out = hidden_rep[-1]\n",
        "        out = self.drop1(out)\n",
        "        score_over_layer = 0\n",
        "\n",
        "        # Perform pooling over all nodes in each graph in every layer\n",
        "        for i, h in enumerate(hidden_rep):\n",
        "            pooled_h = self.pool(g, h)\n",
        "            score_over_layer += self.drop(self.linears_prediction[i](pooled_h))\n",
        "        return out, score_over_layer"
      ],
      "metadata": {
        "id": "NUP_JKC8jeyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoder"
      ],
      "metadata": {
        "id": "2EHAEpDXi09u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CADEncoder(nn.Module):\n",
        "  def __init__(self, crv_emb_dim=64, srf_emb_dim=64, graph_emb_dim=128, dropout=0.3):\n",
        "    super(CADEncoder, self).__init__()\n",
        "    self.curv_encoder = UVNetCurveEncoder(in_channels=10, output_dims=crv_emb_dim) # in_channels originally 6\n",
        "    self.surf_encoder = UVNetSurfaceEncoder(in_channels=10, output_dims=srf_emb_dim)\n",
        "    self.graph_encoder = UVNetGraphEncoder(srf_emb_dim, crv_emb_dim, graph_emb_dim)\n",
        "\n",
        "  def forward(self, batched_graph):\n",
        "    input_crv_feat = batched_graph.edata[\"x\"]\n",
        "    input_srf_feat = batched_graph.ndata[\"x\"]\n",
        "    hidden_crv_feat = self.curv_encoder(input_crv_feat)\n",
        "    hidden_srf_feat = self.surf_encoder(input_srf_feat)\n",
        "    _, graph_emb = self.graph_encoder(batched_graph, hidden_srf_feat, hidden_crv_feat)\n",
        "    return graph_emb"
      ],
      "metadata": {
        "id": "xNNA04oRYQeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
        "import math"
      ],
      "metadata": {
        "id": "lDIyR0NijynS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding"
      ],
      "metadata": {
        "id": "TkL1vEFmj_Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncodingLUT(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=250):\n",
        "        super(PositionalEncodingLUT, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(0, max_len, dtype=torch.long).unsqueeze(1)\n",
        "        self.register_buffer('position', position)\n",
        "\n",
        "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
        "\n",
        "        self._init_embeddings()\n",
        "\n",
        "    def _init_embeddings(self):\n",
        "        nn.init.kaiming_normal_(self.pos_embed.weight, mode=\"fan_in\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_length, _ = x.shape\n",
        "\n",
        "        # Get positional encodings for the sequence length\n",
        "        pos = self.position[:seq_length]  # This will have shape [seq_length, 1]\n",
        "\n",
        "        # Expand positional encodings to cover the whole batch\n",
        "        pos = pos.expand(-1, batch_size).contiguous()  # Reshape to [seq_length, batch_size]\n",
        "        pos = pos.transpose(0, 1)  # Transpose to [batch_size, seq_length]\n",
        "\n",
        "        # Retrieve positional embeddings\n",
        "        pos_embeddings = self.pos_embed(pos)  # This should now be [batch_size, seq_length, d_model]\n",
        "\n",
        "        # Element-wise addition of embeddings to input x\n",
        "        x = x + pos_embeddings\n",
        "\n",
        "        # Apply dropout and return\n",
        "        return self.dropout(x)\n",
        "\n",
        "class CADEmbedding(nn.Module):\n",
        "    \"\"\"Embedding: positional embed + command embed + parameter embed + group embed (optional)\n",
        "\n",
        "    Note: d_model could also be 257\n",
        "    \"\"\"\n",
        "    # I think the d_model should be 64 dim\n",
        "    # n_args should be 16\n",
        "    # Shouldn't the embedding be that command embed + param embed + positional embed?\n",
        "    def __init__(self, n_commands=7, d_model=64, n_args=16, args_dim=257, seq_len=60, use_group=False, group_len=None):\n",
        "        super(CADEmbedding, self).__init__()\n",
        "\n",
        "        self.command_embed = nn.Embedding(n_commands, d_model)\n",
        "\n",
        "        # args_dim = args_dim + 1\n",
        "        self.arg_embed = nn.Embedding(args_dim, d_model, padding_idx=0)\n",
        "        self.embed_fcn = nn.Linear(d_model * n_args, d_model)\n",
        "\n",
        "        # use_group: additional embedding for each sketch-extrusion pair\n",
        "        # self.use_group = use_group\n",
        "        # if use_group:\n",
        "        #     if group_len is None:\n",
        "        #         group_len = cfg.max_num_groups\n",
        "        #     self.group_embed = nn.Embedding(group_len + 2, cfg.d_model)\n",
        "\n",
        "        self.pos_encoding = PositionalEncodingLUT(d_model, max_len=seq_len+2)\n",
        "\n",
        "    def forward(self, commands, args, groups=None):\n",
        "        S, N = commands.shape\n",
        "\n",
        "        # print(f'S = {S}')\n",
        "        # print(f'N = {N}')\n",
        "        src = self.command_embed(commands.long()) + \\\n",
        "              self.embed_fcn(self.arg_embed((args + 1).long()).view(S, N, -1))  # shift due to -1 PAD_VAL\n",
        "\n",
        "        # if self.use_group:\n",
        "        #     src = src + self.group_embed(groups.long())\n",
        "\n",
        "        src = self.pos_encoding(src)\n",
        "\n",
        "        return src\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# class CADCommandEmbedding(nn.Module):\n",
        "#     def __init__(self, d_E=512, n_commands=12, n_params=19, n_args, seq_len=100):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.d_E = d_E\n",
        "#         self.n_params = n_params\n",
        "\n",
        "#         # Command type embedding\n",
        "#         self.command_type_embed = nn.Embedding(n_commands, d_E)\n",
        "\n",
        "#         # Command parameters matrix and embedding layer\n",
        "#         self.param_matrix = nn.Linear(257, d_E)\n",
        "#         self.param_embed = nn.Linear(d_E * n_params, d_E)\n",
        "\n",
        "#         # Index (positional) embedding\n",
        "#         self.index_embed = nn.Embedding(seq_len, d_E)\n",
        "\n",
        "#     def forward(self, command_types, command_params, indices):\n",
        "#         # Embed command types using one-hot vectors\n",
        "#         command_type_embeddings = self.command_type_embed(command_types)\n",
        "\n",
        "#         # Process and embed command parameters\n",
        "#         # Assuming command_params i s a batch of one-hot encoded matrices for parameters\n",
        "#         flat_params = self.param_matrix(command_params.view(-1, 257))\n",
        "#         flat_params = flat_params.view(-1, self.n_params * self.d_E)\n",
        "#         command_param_embeddings = self.param_embed(flat_params)\n",
        "\n",
        "#         # Embed index (position)\n",
        "#         index_embeddings = self.index_embed(indices)\n",
        "\n",
        "#         # Combine all embeddings\n",
        "#         embeddings = command_type_embeddings + command_param_embeddings + index_embeddings\n",
        "#         return embeddings"
      ],
      "metadata": {
        "id": "YG5xqOtljzRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fusion Module"
      ],
      "metadata": {
        "id": "GOCSqKYWkCYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class FusionModule(nn.Module):\n",
        "#     def __init__(self, latent_size, num_commands, command_embedding_size=257, hidden_size=256, output_size=128):\n",
        "#         \"\"\"\n",
        "#         Args:\n",
        "#             latent_size: dimension of z, the latent vector produced by encoder\n",
        "#             command_embedding_size: dimension of command embedding, size 257 in the paper\n",
        "#             hidden_size: perhaps the paper mentioned what its exact value is somewhere...\n",
        "#             output_size: input dimension into the standard transformer decoder\n",
        "#         \"\"\"\n",
        "#         super(FusionModule, self).__init__()\n",
        "#         self.fc1 = nn.Linear(latent_size + command_embedding_size * num_commands, hidden_size)\n",
        "#         self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "#     def forward(self, latent, command_embeddings):\n",
        "#         combined = torch.cat((latent, command_embeddings), dim=1)\n",
        "#         x = self.fc1(combined)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.fc2(x)\n",
        "#         x = F.relu(x)\n",
        "#         return x\n",
        "\n",
        "# class FusionModule(nn.Module):\n",
        "#     def __init__(self, latent_size, command_embedding_size=257, N_c=60, hidden_size=256, output_size=128):\n",
        "#         super(FusionModule, self).__init__()\n",
        "#         self.latent_size = latent_size\n",
        "#         self.command_embedding_size = command_embedding_size\n",
        "#         self.N_c = N_c\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.output_size = output_size\n",
        "\n",
        "\n",
        "#         # Initial dummy parameters to be replaced on the first forward pass\n",
        "#         self.fc1 = nn.Linear(latent_size + command_embedding_size, hidden_size)  # Placeholder\n",
        "#         self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#     def forward(self, latent, command_embeddings):\n",
        "#         command_embeddings_flat = command_embeddings.view(command_embeddings.size(0), -1)\n",
        "#         combined = torch.cat((latent, command_embeddings_flat), dim=1)\n",
        "\n",
        "#         # required_size = self.latent_size + self.command_embedding_size * self.N_c\n",
        "\n",
        "#         current_size = combined.size(1)\n",
        "#         if current_size < required_size:\n",
        "#             padding_size = required_size - current_size\n",
        "#             combined = F.pad(combined, (0, padding_size))\n",
        "\n",
        "#         x = self.fc1(combined)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.fc2(x)\n",
        "#         x = F.relu(x)\n",
        "#         return x\n",
        "\n",
        "\n",
        "class FusionModule(nn.Module):\n",
        "    # THe command_embedding size, hidden size, and output size needs to be changed.\n",
        "    def __init__(self, latent_size, command_embedding_size=64, N_c=60, hidden_size=128, output_size=128):\n",
        "        super(FusionModule, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "        self.command_embedding_size = command_embedding_size\n",
        "        self.N_c = N_c\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "\n",
        "        # Initial dummy parameters to be replaced on the first forward pass\n",
        "        # THis needs to be changed\n",
        "        self.fc1 = nn.Linear(latent_size + command_embedding_size, hidden_size)  # Placeholder\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, latent, command_embedding):\n",
        "        # command_embeddings_flat = command_embeddings.view(command_embeddings.size(0), -1)\n",
        "        command_embedding = torch.unsqueeze(command_embedding, 1)\n",
        "        combined = torch.cat((latent, command_embedding), dim=2)\n",
        "\n",
        "        # required_size = self.latent_size + self.command_embedding_size * self.N_c\n",
        "\n",
        "        # current_size = combined.size(1)\n",
        "        # if current_size < required_size:\n",
        "        #     padding_size = required_size - current_size\n",
        "        #     combined = F.pad(combined, (0, padding_size))\n",
        "\n",
        "        x = self.fc1(combined)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "mKHlq6Ijj4BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder"
      ],
      "metadata": {
        "id": "GbkyVQMikDwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import Tensor\n",
        "from typing import Optional\n",
        "\n",
        "class CausalTransformerDecoder(nn.TransformerDecoder):\n",
        "    \"\"\"Implementation of a transformer decoder based on torch implementation but\n",
        "    more efficient. The difference is that it doesn't need to recompute the\n",
        "    embeddings of all the past decoded tokens but instead uses a cache to\n",
        "    store them. This makes use of the fact that the attention of a decoder is\n",
        "    causal, so new predicted tokens don't affect the old tokens' embedding bc\n",
        "    the corresponding attention cells are masked.\n",
        "    The complexity goes from seq_len^3 to seq_len^2.\n",
        "\n",
        "    This only happens in eval mode.\n",
        "    In training mode, teacher forcing makes these optimizations unnecessary. Hence the\n",
        "    Decoder acts like a regular nn.TransformerDecoder (except that the attention tgt\n",
        "    masks are handled for you).\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        tgt: Tensor,\n",
        "        memory: Optional[Tensor] = None,\n",
        "        cache: Optional[Tensor] = None,\n",
        "        memory_mask: Optional[Tensor] = None,\n",
        "        tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "        memory_key_padding_mask: Optional[Tensor] = None,\n",
        "    ) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tgt (Tensor): current_len_output x bsz x hidden_dim\n",
        "            memory (Tensor): len_encoded_seq x bsz x hidden_dim\n",
        "            cache (Optional[Tensor]):\n",
        "                n_layers x (current_len_output - 1) x bsz x hidden_dim\n",
        "                If current_len_output == 1, nothing is cached yet, so cache\n",
        "                should be None. Same if the module is in training mode.\n",
        "            others (Optional[Tensor]): see official documentations\n",
        "        Returns:\n",
        "            output (Tensor): current_len_output x bsz x hidden_dim\n",
        "            cache (Optional[Tensor]): n_layers x current_len_output x bsz x hidden_dim\n",
        "                Only returns it when module is in eval mode (no caching in training)\n",
        "        \"\"\"\n",
        "\n",
        "        output = tgt\n",
        "\n",
        "        if self.training:\n",
        "            if cache is not None:\n",
        "                raise ValueError(\"cache parameter should be None in training mode\")\n",
        "            for mod in self.layers:\n",
        "                output = mod(\n",
        "                    output,\n",
        "                    memory,\n",
        "                    memory_mask=memory_mask,\n",
        "                    tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                    memory_key_padding_mask=memory_key_padding_mask,\n",
        "                )\n",
        "\n",
        "            return output\n",
        "\n",
        "        new_token_cache = []\n",
        "\n",
        "        for i, mod in enumerate(self.layers):\n",
        "            output = mod(output, memory)\n",
        "            new_token_cache.append(output)\n",
        "            if cache is not None:\n",
        "                output = torch.cat([cache[i], output], dim=0)\n",
        "\n",
        "        if cache is not None:\n",
        "            new_cache = torch.cat([cache, torch.stack(new_token_cache, dim=0)], dim=1)\n",
        "        else:\n",
        "            new_cache = torch.stack(new_token_cache, dim=0)\n",
        "\n",
        "        return output, new_cache\n",
        "\n",
        "\n",
        "class CausalTransformerDecoderLayer(nn.TransformerDecoderLayer):\n",
        "    def __init__(self, d_model, nhead=6, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
        "        super().__init__(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        tgt: torch.Tensor,\n",
        "        memory: Optional[torch.Tensor] = None,\n",
        "        tgt_mask: Optional[torch.Tensor] = None,\n",
        "        memory_mask: Optional[torch.Tensor] = None,\n",
        "        tgt_key_padding_mask: Optional[torch.Tensor] = None,\n",
        "        memory_key_padding_mask: Optional[torch.Tensor] = None,\n",
        "    ) -> torch.Tensor:\n",
        "        if self.training:\n",
        "            # In training mode, follow the standard procedure including masking\n",
        "            return super().forward(\n",
        "                tgt,\n",
        "                memory,\n",
        "                tgt_mask=self._generate_causal_mask(tgt.size(0), tgt.device),\n",
        "                memory_mask=memory_mask,\n",
        "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                memory_key_padding_mask=memory_key_padding_mask,\n",
        "            )\n",
        "        else:\n",
        "            # In evaluation mode, proceed with the autoregressive manner\n",
        "\n",
        "            # Handle the last token from the sequence only\n",
        "            tgt_last_tok = tgt[-1:, :, :]\n",
        "\n",
        "            # Perform self-attention on the last token\n",
        "            tgt_last_tok = self.self_attn(\n",
        "                tgt_last_tok,\n",
        "                tgt,\n",
        "                tgt,\n",
        "                attn_mask=None,  # no need for mask since we're only concerned with the last token\n",
        "                key_padding_mask=tgt_key_padding_mask,\n",
        "            )[0] + tgt_last_tok\n",
        "            tgt_last_tok = self.norm1(tgt_last_tok)\n",
        "\n",
        "            # Perform cross-attention with the memory (encoder's output)\n",
        "            if memory is not None:\n",
        "                tgt_last_tok = self.multihead_attn(\n",
        "                    tgt_last_tok,\n",
        "                    memory,\n",
        "                    memory,\n",
        "                    attn_mask=memory_mask,\n",
        "                    key_padding_mask=memory_key_padding_mask,\n",
        "                )[0] + tgt_last_tok\n",
        "                tgt_last_tok = self.norm2(tgt_last_tok)\n",
        "\n",
        "            # Pass through the final feed-forward network\n",
        "            tgt_last_tok = self.linear2(self.dropout(self.activation(self.linear1(tgt_last_tok)))) + tgt_last_tok\n",
        "            tgt_last_tok = self.norm3(tgt_last_tok)\n",
        "\n",
        "            return tgt_last_tok\n",
        "\n",
        "    @staticmethod\n",
        "    def _generate_causal_mask(sz, device):\n",
        "        \"\"\"\n",
        "        Generates a causal mask to hide future tokens for autoregressive tasks.\n",
        "        \"\"\"\n",
        "        mask = torch.full((sz, sz), float('-inf'))\n",
        "        mask_cond = torch.triu(mask, diagonal=1)\n",
        "        return mask_cond.to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "1UVkhDRrsLLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CADDecoder(nn.Module):\n",
        "    def __init__(self, d_model=128, nhead=8, num_decoder_layers=4,\n",
        "                 dim_feedforward=2048, dropout=0.1, activation=\"relu\",\n",
        "                 num_commands=7, max_seq_len=5000, num_parameters=16, param_cat=257, num_embeddings=128):\n",
        "        super(CADDecoder, self).__init__()\n",
        "\n",
        "        # embedding\n",
        "        # self.cad_command_embedding = CADEmbedding(d_model, num_commands, max_seq_len, num_parameters, num_embeddings)\n",
        "        self.param_cat = param_cat\n",
        "        self.cad_command_embedding = CADEmbedding()\n",
        "\n",
        "        # fusion module\n",
        "        self.fusion_module = FusionModule(d_model) # not too sure about the dimensions, needs checking\n",
        "\n",
        "        # decoder\n",
        "        decoder_layer = CausalTransformerDecoderLayer(d_model=128, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, activation=activation)\n",
        "        self.transformer_decoder = CausalTransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "\n",
        "        # final output\n",
        "        # self.output_layer1 = nn.Linear(d_model, num_parameters + 1)\n",
        "\n",
        "        # implementation with softmax\n",
        "        self.output_layer1 = nn.Linear(d_model, num_commands) # t_i\n",
        "        self.output_layer2 = nn.Linear(d_model, num_parameters * param_cat) # p_i\n",
        "        # self.output_layer2 = nn.Linear(d_model, num_parameters) # p_i\n",
        "\n",
        "    def forward(self, latent, command_seq,\n",
        "                tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            latent: 2D latent vector from Encoder\n",
        "            command_types: tensor of command type indices\n",
        "            command_params: tensor of command parameter indices\n",
        "            command_indices: tensor of command indices in the sequence\n",
        "        \"\"\"\n",
        "\n",
        "        # embedding\n",
        "        commands_count = command_seq.shape[1]\n",
        "        commands = command_seq[:, :, 0]\n",
        "        args = command_seq[:, :, 1:]\n",
        "        # print(\"commands shape\", commands.shape)\n",
        "        # print(\"commands\",commands)\n",
        "        # print(\"args\", args.shape)\n",
        "        # print(\"args\",args)\n",
        "        construct_embed = self.cad_command_embedding(commands, args)\n",
        "        # print(\"construct_embd\",construct_embed.shape)\n",
        "\n",
        "        fusion_outputs = None\n",
        "        # fusion module\n",
        "        for i in range(commands_count):\n",
        "            fusion_output = self.fusion_module(latent, construct_embed[:,i,:])\n",
        "\n",
        "            if fusion_outputs is None:\n",
        "                fusion_outputs = fusion_output.unsqueeze(1)  # Add an extra dimension for concatenation\n",
        "            else:\n",
        "                fusion_outputs = torch.cat((fusion_outputs, fusion_output.unsqueeze(1)), dim=1)\n",
        "\n",
        "        # fusion module\n",
        "        # fusion_output = self.fusion_module(latent, construct_embed)\n",
        "\n",
        "        # decoder\n",
        "        decoder_output = self.transformer_decoder(tgt=fusion_output,\n",
        "                                          memory=latent,\n",
        "                                          memory_mask=memory_mask,\n",
        "                                          tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                                          memory_key_padding_mask=memory_key_padding_mask)\n",
        "\n",
        "        # final output\n",
        "        # output1 = self.output_layer1(decoder_output)\n",
        "        # output1 = F.relu(output1)\n",
        "\n",
        "        # return output1\n",
        "\n",
        "\n",
        "        # softmax implementation\n",
        "        output1 = self.output_layer1(decoder_output)\n",
        "        output1 = F.softmax(output1) # t_i\n",
        "\n",
        "        output2 = self.output_layer2(decoder_output)\n",
        "        output2 = output2.view(-1, 16, self.param_cat)\n",
        "        output2 = F.softmax(output2, dim=2) # p_i\n",
        "\n",
        "        return output1, output2\n",
        "\n",
        "\n",
        "# class CADDecoder(nn.Module):\n",
        "#     def __init__(self, d_model=128, nhead=8, num_decoder_layers=4,\n",
        "#                  dim_feedforward=2048, dropout=0.1, activation=\"relu\",\n",
        "#                  num_commands=6, max_seq_len=5000, num_parameters=16, num_embeddings=128):\n",
        "#         super(CADDecoder, self).__init__()\n",
        "\n",
        "#         # embedding\n",
        "#         # self.cad_command_embedding = CADEmbedding(d_model, num_commands, max_seq_len, num_parameters, num_embeddings)\n",
        "#         self.cad_command_embedding = CADEmbedding()\n",
        "\n",
        "#         # fusion module\n",
        "#         self.fusion_module = FusionModule(d_model) # not too sure about the dimensions, needs checking\n",
        "\n",
        "#         # decoder\n",
        "#         decoder_layer = CausalTransformerDecoderLayer(d_model=128, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, activation=activation)\n",
        "#         self.transformer_decoder = CausalTransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "\n",
        "#         # final output\n",
        "#         # self.output_layer1 = nn.Linear(d_model, num_parameters + 1)\n",
        "\n",
        "#         # implementation with softmax\n",
        "#         self.output_layer1 = nn.Linear(d_model, num_commands) # t_i\n",
        "#         self.output_layer2 = nn.Linear(d_model, num_parameters) # p_i\n",
        "\n",
        "#     def forward(self, latent, command_seq,\n",
        "#                 tgt_mask=None, memory_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
        "#         \"\"\"\n",
        "#         Args:\n",
        "#             latent: 2D latent vector from Encoder\n",
        "#             command_types: tensor of command type indices\n",
        "#             command_params: tensor of command parameter indices\n",
        "#             command_indices: tensor of command indices in the sequence\n",
        "#         \"\"\"\n",
        "\n",
        "#         # embedding\n",
        "#         commands_count = command_seq.shape[1]\n",
        "#         commands = command_seq[:, :, 0]\n",
        "#         args = command_seq[:, :, 1:]\n",
        "#         construct_embed = self.cad_command_embedding(commands, args)\n",
        "#         fusion_outputs = None\n",
        "#         # fusion module\n",
        "#         for i in range(commands_count):\n",
        "#             fusion_output = self.fusion_module(latent, construct_embed[:,i,:])\n",
        "\n",
        "#             if fusion_outputs is None:\n",
        "#                 fusion_outputs = fusion_output.unsqueeze(1)  # Add an extra dimension for concatenation\n",
        "#             else:\n",
        "#                 fusion_outputs = torch.cat((fusion_outputs, fusion_output.unsqueeze(1)), dim=1)\n",
        "\n",
        "#         print(f'fusion_outputs.shape = {fusion_outputs.shape}')\n",
        "#         # decoder\n",
        "#         decoder_output = self.transformer_decoder(tgt=fusion_outputs,\n",
        "#                                           memory=latent,\n",
        "#                                           memory_mask=memory_mask,\n",
        "#                                           tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "#                                           memory_key_padding_mask=memory_key_padding_mask)\n",
        "\n",
        "#         # final output\n",
        "#         # output1 = self.output_layer1(decoder_output)\n",
        "#         # output1 = F.relu(output1)\n",
        "\n",
        "#         # return output1\n",
        "\n",
        "\n",
        "#         # softmax implementation\n",
        "#         output1 = self.output_layer1(decoder_output)\n",
        "#         output1 = F.softmax(output1) # t_i\n",
        "\n",
        "#         output2 = self.output_layer2(decoder_output)\n",
        "#         output2 = F.softmax(output2) # p_i\n",
        "\n",
        "#         return output1, output2"
      ],
      "metadata": {
        "id": "ZWKOsU2Dj5lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CadParser"
      ],
      "metadata": {
        "id": "XBx_j4lGNL6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Model"
      ],
      "metadata": {
        "id": "HYv8XmX7mRqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CADParserModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CADParserModel, self).__init__()\n",
        "\n",
        "        # encoder\n",
        "        self.cad_encoder = CADEncoder()\n",
        "\n",
        "        # decoder\n",
        "        self.cad_decoder = CADDecoder()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, graph_input, label_input):\n",
        "        # encoder\n",
        "        latent = self.cad_encoder(graph_input)\n",
        "        # print(\"LATENT VECTOR\", latent.shape)\n",
        "        print(latent)\n",
        "        # decoder\n",
        "        output1, output2 = self.cad_decoder(latent, label_input)\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "MCaKR6Y4mRby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "4U893YmZmS2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "print(dgl.__version__)\n",
        "print(torch.__version__)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um7MfbneKyWj",
        "outputId": "9818b9d9-eb6e-4a1c-e7cc-37014f43d3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n",
            "2.2.1+cu121\n",
            "Tue Apr 30 13:11:41 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   42C    P8              12W /  72W |      1MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "J7Vd3V0ijv4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968f5fb2-03ef-4a34-aa0e-622949b697cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import numpy as np\n",
        "\n",
        "# graphs, label_dict = dgl.load_graphs(\"/content/drive/My Drive/DeepCADDataset/all_graphs.bin\")\n",
        "# print(graphs)\n",
        "# print(label_dict)\n",
        "\n",
        "graphs, label_dict = dgl.load_graphs(\"/content/drive/My Drive/DeepCADDataset/all_graphs.bin\")\n",
        "print(label_dict)\n",
        "print(len(graphs))\n",
        "print(graphs[0])\n",
        "\n",
        "npz = np.load(\"/content/drive/My Drive/DeepCADDataset/all_npz.npz\")\n",
        "print(\"type: \",type(npz))\n",
        "print(\"length: \",len(npz))\n",
        "print(npz)\n",
        "print(npz['vec_0'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFOnO9QGnd8d",
        "outputId": "5ef5565b-b571-4961-8a89-c13d9d2fe168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n",
            "7059\n",
            "Graph(num_nodes=6, num_edges=24,\n",
            "      ndata_schemes={'x': Scheme(shape=(10, 10, 7), dtype=torch.float64)}\n",
            "      edata_schemes={'x': Scheme(shape=(10, 6), dtype=torch.float64)})\n",
            "type:  <class 'numpy.lib.npyio.NpzFile'>\n",
            "length:  7059\n",
            "NpzFile '/content/drive/My Drive/DeepCADDataset/all_npz.npz' with keys: vec_0, vec_1, vec_2, vec_3, vec_4...\n",
            "[[  4  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1]\n",
            " [  0 223 128  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1]\n",
            " [  0 223 223  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1]\n",
            " [  0 128 223  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1]\n",
            " [  0 128 128  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1]\n",
            " [  5  -1  -1  -1  -1  -1 192 192  64  32 128 151   3 161 128   0   0]\n",
            " [  3  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1  -1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = []\n",
        "\n",
        "# Iterate over the sorted keys to maintain the order\n",
        "for key in npz.keys():\n",
        "    # print(key)\n",
        "    Y.append(npz[key])"
      ],
      "metadata": {
        "id": "HKmRp0pbntI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = graphs"
      ],
      "metadata": {
        "id": "6FrhQ6L3zbx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42) # train size = 6353"
      ],
      "metadata": {
        "id": "hwHqc42DztQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPWMe3Pmu9aJ",
        "outputId": "d7bc7c4e-8223-4922-8f49-1968cdc49813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seednumber=2024\n",
        "torch.manual_seed(seednumber)\n",
        "torch.cuda.manual_seed(seednumber)\n",
        "np.random.seed(seednumber)"
      ],
      "metadata": {
        "id": "yeqTx7CPXNSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "torch.set_printoptions(threshold=10_000)\n",
        "# Path where checkpoints are stored\n",
        "checkpoint_dir = '/content/drive/My Drive/CADParser_Checkpoint_kevin_v1'\n",
        "loss_log_file_path = os.path.join(checkpoint_dir, 'loss_log.txt')\n",
        "\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 100\n",
        "initial_learning_rate = 1e-3\n",
        "batch_size = 96  # Adjust according to your GPU memory\n",
        "warmup_epochs = 10\n",
        "root_dir = \"\"\n",
        "\n",
        "# Initialize the dataset and data loader\n",
        "dataset = BaseDataset(X_train, Y_train)\n",
        "data_loader = dataset.get_dataloader()\n",
        "\n",
        "# Initialize the model\n",
        "model = CADParserModel().to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=initial_learning_rate)\n",
        "\n",
        "# Gradual warmup and learning rate decay\n",
        "scheduler = LambdaLR(\n",
        "    optimizer,\n",
        "    lr_lambda=lambda epoch: 0.9**(epoch // 30) * min((epoch + 1) / warmup_epochs, 1)\n",
        ")\n",
        "\n",
        "# Function to find the latest checkpoint file\n",
        "def find_latest_checkpoint(checkpoint_dir):\n",
        "    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
        "    if checkpoint_files:\n",
        "        latest_file = max(checkpoint_files, key=lambda x: int(x.strip('model_epoch_').strip('.pth')))\n",
        "        return os.path.join(checkpoint_dir, latest_file)\n",
        "    return None\n",
        "start_epoch = 0\n",
        "\n",
        "# Load the latest checkpoint if it exists\n",
        "# latest_checkpoint = find_latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "# if latest_checkpoint:\n",
        "#     print(f\"Loading checkpoint '{latest_checkpoint}'\")\n",
        "#     checkpoint = torch.load(latest_checkpoint, map_location=device)\n",
        "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#     scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "#     start_epoch = checkpoint['epoch']\n",
        "#     print(f\"Resuming training from epoch {start_epoch}\")\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    print_out = True\n",
        "    for batch_idx, batch in enumerate(data_loader):\n",
        "        graphs, sequences = batch['graph'].to(device), batch['labels'].to(device)\n",
        "        # for label in sequences[4]:\n",
        "            # print(f'label = {label}')\n",
        "\n",
        "        # optimizer.zero_grad()\n",
        "        # outputs1, outputs2 = model(graphs)\n",
        "        # print(f'outputs1 = {outputs1}')\n",
        "        # print(f'outputs2 = {outputs2}')\n",
        "        # print(f'outputs1.shape = {outputs1.shape}')\n",
        "        # print(f'outputs2.shape = {outputs2.shape}')\n",
        "\n",
        "        # print('graphs =', graphs)\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss = 0\n",
        "\n",
        "        latent_vector = model.cad_encoder(graphs)\n",
        "        latent_vector = torch.unsqueeze(latent_vector, 1)\n",
        "        print(f\"latent vector size: {latent_vector.shape}\")\n",
        "        decoder_input_seq = sequences[:, 0:1, :]  # Start with the first vector (START token)\n",
        "\n",
        "        for t in range(1, sequences.size(1)):\n",
        "            # print(f't = {t}')\n",
        "            decoder_output_t_i, decoder_output_p_i = model.cad_decoder(latent_vector, decoder_input_seq) # two probability vectors: t_i, v_i\n",
        "            gt_t = sequences[:, t, :] # ground truth seq in raw 17-len vector form\n",
        "\n",
        "            command_type_t = sequences[:, t, 0] # get command type\n",
        "            command_type_t = command_type_t.long()\n",
        "            true_t_i = F.one_hot(command_type_t, num_classes=7)\n",
        "            # print(f'true_t_i.shape = {true_t_i.shape}')\n",
        "\n",
        "            param_t = sequences[:, t, 1:]# get parameters\n",
        "            param_t_mapped = param_t + 1\n",
        "            true_p_i = F.one_hot(param_t_mapped.long(), num_classes=257)\n",
        "            # print(f'true_p_i.shape = {true_p_i.shape}')\n",
        "            # print(f'decoder_output_p_i.shape = {decoder_output_p_i.shape}')\n",
        "\n",
        "            # print(f'decoder_output_t_i.shape = {decoder_output_t_i.shape}')\n",
        "            # print(f'true_t_i.shape = {true_t_i.shape}')\n",
        "            # t_i_loss = -(true_t_i.float() * torch.log(true_t_i)).sum(dim=1).mean()\n",
        "            # print(f't_i_loss = {t_i_loss}')\n",
        "            t_i_loss = criterion(decoder_output_t_i, true_t_i)\n",
        "            p_i_loss = criterion(decoder_output_p_i, true_p_i.float())\n",
        "            # print(f'p_i_loss = {p_i_loss}')\n",
        "\n",
        "            loss = t_i_loss + p_i_loss # compare decoder output with the true next output\n",
        "            # print(f'decoder_output_t_i.shape = {decoder_output_t_i.shape}')\n",
        "\n",
        "            # convert softmax distribution back into valid token\n",
        "            _, command_type_pred_next = torch.max(decoder_output_t_i, dim=1, keepdim=True)\n",
        "            command_args_pred_next = torch.argmax(decoder_output_p_i, dim=2)\n",
        "            # print(f'command_args_pred_next.shape = {command_args_pred_next.shape}')\n",
        "            command_args_pred_next = command_args_pred_next - 1\n",
        "            next_token_pred = torch.cat((command_type_pred_next, command_args_pred_next), dim=1) # next_token_pred shape should be [128, 17]\n",
        "\n",
        "            next_token_pred = next_token_pred.unsqueeze(1) # reshaping next_token_pred to size [128, 1, 17]\n",
        "            decoder_input_seq = torch.cat((decoder_input_seq, next_token_pred), dim=1)\n",
        "            # print(f'decoder_input_seq.shape = {decoder_input_seq.shape}')\n",
        "            # print(f'decoder_input_seq[0] = {decoder_input_seq[0]}')\n",
        "            batch_loss += loss\n",
        "\n",
        "        if print_out:\n",
        "            print('batch_idx:', batch_idx)\n",
        "            print('pred:', decoder_input_seq[0])\n",
        "            print('true:', sequences[0])\n",
        "            print_out = False\n",
        "\n",
        "        # Normalize loss by seq length\n",
        "        batch_loss /= (sequences.size(1) - 1)\n",
        "        batch_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += batch_loss.item()\n",
        "\n",
        "        scheduler.step()  # Update the learning rate\n",
        "        # print(f'batch_idx = {batch_idx}')\n",
        "        # print(f'epoch {epoch+1}, training batch_loss = {batch_loss}')\n",
        "\n",
        "\n",
        "\n",
        "    loss_list.append(total_loss / 49)\n",
        "    with open(loss_log_file_path, 'a') as f:\n",
        "        f.write(str(total_loss / 49))\n",
        "    print(f'----------------------EPOCH {epoch+1}, TOTAL LOSS = {total_loss / 49}')\n",
        "        # if epoch % 10 == 0:\n",
        "        #     print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(data_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    # Save checkpoint at the end of each epoch\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'loss': loss_list,\n",
        "    }\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        torch.save(checkpoint, f'{checkpoint_dir}/model_epoch_{epoch+1}.pth')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a plot of the losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss_list, label='Loss per Epoch')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Save the plot to a PNG file\n",
        "plt.savefig('/content/drive/My Drive/CADParser_Checkpoint_kevin_v1/loss_plot.png')\n",
        "plt.close()  # Close the plot explicitly after saving to free up memory\n",
        "\n"
      ],
      "metadata": {
        "id": "ctYARkuhNP0B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "dddd3fa7-298d-4ac9-ded9-d460430fa0ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "latent vector size: torch.Size([128, 1, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-6b8b367163c6>:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output1 = F.softmax(output1) # t_i\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-91e057a7774c>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# print(f't_i_loss = {t_i_loss}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mt_i_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output_t_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_t_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mp_i_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output_p_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_p_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;31m# print(f'p_i_loss = {p_i_loss}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3058\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3059\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iter = 0\n",
        "for batch_id, batch in enumerate(data_loader):\n",
        "    iter += 1\n",
        "\n",
        "print(iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygPASx8zrRbo",
        "outputId": "00dfb8f1-6791-4787-b7ae-7af8055402b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "checkpoint_dir = '/content/drive/My Drive/CADParser_Checkpoint'\n",
        "\n",
        "dataset = BaseDataset(X_train, Y_train)\n",
        "data_loader = dataset.get_dataloader()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CADParserModel().to(device)\n",
        "\n",
        "def find_latest_checkpoint(checkpoint_dir):\n",
        "    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
        "    if checkpoint_files:\n",
        "        latest_file = max(checkpoint_files, key=lambda x: int(x.strip('model_epoch_').strip('.pth')))\n",
        "        return os.path.join(checkpoint_dir, latest_file)\n",
        "    return None\n",
        "\n",
        "# Load the latest checkpoint if it exists\n",
        "latest_checkpoint = find_latest_checkpoint(checkpoint_dir)\n",
        "start_epoch = 0\n",
        "if latest_checkpoint:\n",
        "    print(f\"Loading checkpoint '{latest_checkpoint}'\")\n",
        "    checkpoint = torch.load(latest_checkpoint, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    # scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print(f\"loading epoch {start_epoch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9QnFYEpQLw1",
        "outputId": "710eac63-40f0-449e-ef41-0f31752abc91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint '/content/drive/My Drive/CADParser_Checkpoint/model_epoch_100.pth'\n",
            "loading epoch 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_vector_total = np.empty([0, 128])"
      ],
      "metadata": {
        "id": "v19SbKagxEf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, batch in enumerate(data_loader):\n",
        "    graphs, sequences = batch['graph'].to(device), batch['labels'].to(device)\n",
        "    latent_vector = model.cad_encoder(graphs)\n",
        "    latent_vector = latent_vector.cpu().detach().numpy()\n",
        "    latent_vector_total = np.concatenate((latent_vector_total, latent_vector), axis=0)"
      ],
      "metadata": {
        "id": "_wGsZPpSxCCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming latent_vector is your tensor of shape (128, 128)\n",
        " # Make sure it's a numpy array\n",
        "\n",
        "\n",
        "# Initialize t-SNE\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results = tsne.fit_transform(latent_vector_total)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(tsne_results[:, 0], tsne_results[:, 1])\n",
        "plt.colorbar()\n",
        "plt.xlabel('t-SNE feature 0')\n",
        "plt.ylabel('t-SNE feature 1')\n",
        "plt.title('t-SNE Visualization of Latent Vectors')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "i1z1fiI9sAzL",
        "outputId": "7f7c400c-8fa6-48d2-d6a7-b14a0f1c3455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[t-SNE] Computing 121 nearest neighbors...\n",
            "[t-SNE] Indexed 6272 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 6272 samples in 0.259s...\n",
            "[t-SNE] Computed conditional probabilities for sample 1000 / 6272\n",
            "[t-SNE] Computed conditional probabilities for sample 2000 / 6272\n",
            "[t-SNE] Computed conditional probabilities for sample 3000 / 6272\n",
            "[t-SNE] Computed conditional probabilities for sample 4000 / 6272\n",
            "[t-SNE] Computed conditional probabilities for sample 5000 / 6272\n",
            "[t-SNE] Computed conditional probabilities for sample 6000 / 6272\n",
            "[t-SNE] Computed conditional probabilities for sample 6272 / 6272\n",
            "[t-SNE] Mean sigma: 0.714438\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 82.417313\n",
            "[t-SNE] KL divergence after 300 iterations: 3.664727\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw8AAAIjCAYAAABFxScvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADo6ElEQVR4nOzdeXwTdfoH8M8kzdEzvSgpZ0spQi1SQBAsIiAsKAJeKAjK4eLJqrD7Uzy4REW8wF1QPFBW2aKIByAIUkDBUkQpRUpBoLScLaV3m97J/P4oE3JnJpncz/v16q5Nk8m3pU3mme9zMCzLsiCEEEIIIYQQOySeXgAhhBBCCCHEN1DwQAghhBBCCOGFggdCCCGEEEIILxQ8EEIIIYQQQnih4IEQQgghhBDCCwUPhBBCCCGEEF4oeCCEEEIIIYTwQsEDIYQQQgghhBcKHgghhBBCCCG8UPBACHG5tWvXgmEYFBUVed06hg0bhmHDhrl9LZ56XiEuX76M++67DzExMWAYBitWrPD0kgghhHgYBQ+EuNH+/fuxaNEiVFVV8X5MXV0dFi5ciNTUVISGhiImJgZpaWl45plncOnSJf39Fi1aBIZh0L59e9TX15sdJyEhAXfeeafRbQzDWP14/PHHra5p/PjxCAkJQW1trdX7TJkyBXK5HOXl5by/V3+Tn5+PRYsWeTxoctScOXOwY8cOvPDCC/jiiy8wZswYq/dlGAazZ88W5XkzMjLcFqjw/ZtsaWlBbGwshgwZYvU+LMuic+fO6Nevn6hrvHTpEhYtWoTc3FxRj0sIIY4I8vQCCAkk+/fvx+LFizF9+nRERkbavX9LSwuGDh2KEydOYNq0afjHP/6Buro6HDt2DBkZGbj77rvRoUMHo8eUlpbigw8+wD//+U9eaxo1ahQefvhhs9t79Ohh9TFTpkzBli1b8N1331l8bH19PTZt2oQxY8YgJiYGDz30ECZNmgSFQsFrTe70008/uezY+fn5WLx4MYYNG4aEhAS3Pa9Ydu/ejQkTJuBf//qXW583IyMDeXl5ePbZZ13+XHz/JmUyGSZOnIgPP/wQZ8+eRdeuXc3us3fvXly4cAFz5swRdY2XLl3C4sWLkZCQgLS0NFGPTQghQlHwQIgX+/7773H48GH873//w4MPPmj0tcbGRjQ3N5s9Ji0tDW+99RaefPJJBAcH232OHj16YOrUqYLWNX78eISHhyMjI8Ni8LBp0yZoNBpMmTIFACCVSiGVSgU9h7vI5fKAel4hSktLeQW5gWLKlClYvXo11q9fj3nz5pl9PSMjAxKJBJMmTfLA6oTTaDQIDQ319DIIIT6G0pYIcZNFixbh//7v/wAAiYmJ+vQgWyktBQUFAID09HSzrymVSkRERJjdvmDBAly+fBkffPCBOAu3IDg4GPfccw927dqF0tJSs69nZGQgPDwc48ePB2C51uCPP/7A6NGjERsbi+DgYCQmJmLmzJn6r//8889gGAY///yz0bGLiorAMAzWrl2rv+3PP//E9OnT0a1bNyiVSqjVasycOZNXypRp7UFCQoLVVC5uLWfPnsWTTz6J6667DsHBwYiJicHEiRONvr+1a9di4sSJAIDhw4ebHcNSzUNpaSkeeeQRtG/fHkqlEn369MF///tfi9//22+/jY8++ghJSUlQKBQYMGAAfv/9d7vfLwCcOXMGEydORHR0NEJCQjBo0CBs3brVaO0Mw4BlWaxatUq/dmdt2rQJY8eORYcOHaBQKJCUlIQlS5ZAq9Xq7zNs2DBs3boVZ8+e1T+v4a5NU1MTFi5ciO7du0OhUKBz58547rnn0NTUZPRcXBrV999/j9TUVCgUClx//fXYvn27/j5C/ybT09ORkJCAjIwMs6+1tLRg48aNGD58uH438MSJE7jvvvsQHR0NpVKJG2+8EZs3bzZ7bFVVFebMmYOEhAQoFAp06tQJDz/8MMrKyvDzzz9jwIABAIAZM2bo12j4+//111+jf//+CA4ORmxsLKZOnYqLFy8aPcf06dMRFhaGgoIC3HHHHQgPD9cH96dOncK9994LtVoNpVKJTp06YdKkSaiurrb4cyCEBDbaeSDETe655x6cPHkS69evx/LlyxEbGwsAaNeundXHcKkRn3/+OV5++WVeJ3C33HILRowYgTfffBNPPPGE3d2HxsZGlJWVmd0eERFh8+r4lClT8N///hcbNmwwynWvqKjAjh07MHnyZKvPXVpair/97W9o164d5s2bh8jISBQVFeHbb7+1+/1ZsnPnTpw5cwYzZsyAWq3GsWPH8NFHH+HYsWM4cOCAoBPfFStWoK6uzui25cuXIzc3FzExMQCA33//Hfv378ekSZPQqVMnFBUV4YMPPsCwYcOQn5+PkJAQDB06FE8//TT+/e9/48UXX0SvXr0AQP//phoaGjBs2DCcPn0as2fPRmJiIr7++mtMnz4dVVVVeOaZZ4zun5GRgdraWjz22GNgGAZvvvkm7rnnHpw5cwYymczq93f58mXcfPPNqK+vx9NPP42YmBj897//xfjx47Fx40bcfffdGDp0KL744gs89NBDVtPaHLF27VqEhYVh7ty5CAsLw+7du7FgwQLU1NTgrbfeAgC89NJLqK6uxoULF7B8+XIAQFhYGABAp9Nh/Pjx+PXXX/Hoo4+iV69eOHr0KJYvX46TJ0/i+++/N3q+X3/9Fd9++y2efPJJhIeH49///jfuvfdenDt3DjExMYL/JhmGwYMPPojXX38dx44dw/XXX6//2vbt21FRUaE/IT927BjS09PRsWNHzJs3D6GhodiwYQPuuusufPPNN7j77rsBtNU03XLLLTh+/DhmzpyJfv36oaysDJs3b8aFCxfQq1cvvPLKK1iwYAEeffRR3HLLLQCAm2++Wf8znTFjBgYMGIClS5fi8uXLeO+995CVlYXDhw8b7Ry1trZi9OjRGDJkCN5++22EhISgubkZo0ePRlNTE/7xj39ArVbj4sWL+OGHH1BVVQWVSuXMPzkhxB+xhBC3eeutt1gAbGFhIa/719fXs9dddx0LgO3atSs7ffp0ds2aNezly5fN7rtw4UIWAHvlyhX2l19+YQGw7777rv7rXbt2ZceOHWv0GABWP9avX29zba2trWx8fDw7ePBgo9tXr17NAmB37Nihv+2zzz4z+r6/++47FgD7+++/Wz3+nj17WADsnj17jG4vLCxkAbCfffaZ0c/J1Pr161kA7N69e62ug2VZ9tZbb2VvvfVWq+vYsGEDC4B95ZVXbD5fdnY2C4D9/PPP9bd9/fXXFr8HS8+7YsUKFgC7bt06/W3Nzc3s4MGD2bCwMLampsbo+4+JiWErKir09920aRMLgN2yZYvV74VlWfbZZ59lAbD79u3T31ZbW8smJiayCQkJrFar1d8OgH3qqadsHk/IfS393B577DE2JCSEbWxs1N82duxYtmvXrmb3/eKLL1iJRGK0dpa99juXlZVltB65XM6ePn1af9uRI0dYAOx//vMf/W1C/yaPHTvGAmBfeOEFo9snTZrEKpVKtrq6mmVZlr3tttvY3r17G31fOp2Ovfnmm9nk5GT9bQsWLGABsN9++63Zc+l0OpZlWfb33383+51n2bbfj7i4ODY1NZVtaGjQ3/7DDz+wANgFCxbob5s2bRoLgJ03b57RMQ4fPswCYL/++mte3z8hhFDaEiFeLDg4GL/99ps+tWLt2rV45JFHEB8fj3/84x9mqRqcoUOHYvjw4XjzzTfR0NBg8zkmTJiAnTt3mn0MHz7c5uOkUikmTZqE7OxsozSPjIwMtG/fHrfddpvVx3JXQ3/44Qe0tLTYfB4+DHc4uJ2UQYMGAQBycnIcPm5+fj5mzpyJCRMm4OWXX7b4fC0tLSgvL0f37t0RGRnp8PNt27YNarUakydP1t8mk8nw9NNPo66uDr/88ovR/R944AFERUXpP+euSJ85c8bu8wwcONCoa1BYWBgeffRRFBUVIT8/36H182H4c6utrUVZWRluueUW1NfX48SJE3Yf//XXX6NXr17o2bMnysrK9B8jRowAAOzZs8fo/iNHjkRSUpL+8xtuuAERERF2f0a2pKSkoG/fvvjyyy/1t2k0GmzevBl33nknIiIiUFFRgd27d+P+++/Xf59lZWUoLy/H6NGjcerUKX1a0TfffIM+ffrodyIM2dsx++OPP1BaWoonn3wSSqVSf/vYsWPRs2dPo1Q0zhNPPGH0ObezsGPHDotd2gghxBQFD4R4gYqKCpSUlOg/DHONVSoV3nzzTRQVFaGoqAhr1qzBddddh5UrV2LJkiVWj7lo0SKUlJRg9erVNp+7U6dOGDlypNlH+/bt7a6bS9HgcsAvXLiAffv2YdKkSTYLpG+99Vbce++9WLx4MWJjYzFhwgR89tlnVoMheyoqKvDMM8+gffv2CA4ORrt27ZCYmAgADudt19TU4J577kHHjh3x+eefG53INTQ0YMGCBejcuTMUCgViY2PRrl07VFVVOfx8Z8+eRXJyMiQS45dlLs3p7NmzRrd36dLF6HMukKisrLT7PNddd53Z7daeR0zHjh3D3XffDZVKhYiICLRr105frM/n53bq1CkcO3YM7dq1M/rgOoOZ1t+Y/oyAtp+TvZ+RPVOmTEFhYSH2798PoK2xQX19vf7v4fTp02BZFvPnzzdb68KFC43WWlBQgNTUVIfWwf1bWfr37Nmzp9m/ZVBQEDp16mR0W2JiIubOnYtPPvkEsbGxGD16NFatWkX1DoQQq6jmgRAvcM899xhdWZ42bZpRQSSna9eumDlzJu6++25069YN//vf//Dqq69aPObQoUMxbNgwvPnmmzZnNjijf//+6NmzJ9avX48XX3wR69evB8uy+pMoaxiGwcaNG3HgwAFs2bIFO3bswMyZM/HOO+/gwIEDCAsLs3rV1bC4lnP//fdj//79+L//+z+kpaUhLCwMOp0OY8aMgU6nc+h7mz59Oi5duoSDBw+aFab/4x//wGeffYZnn30WgwcPhkqlAsMwmDRpksPPJ5S14IxlWbc8v1BVVVW49dZbERERgVdeeQVJSUlQKpXIycnB888/z+vnptPp0Lt3b7z77rsWv965c2ejz131M5o8eTKee+45ZGRk4Oabb0ZGRgaioqJwxx136NcJAP/6178wevRoi8fo3r27U2twhEKhMAtOAeCdd97B9OnTsWnTJvz00094+umnsXTpUhw4cMAs2CCEEAoeCHEjayfE77zzjtHVUNPZDaaioqKQlJSEvLw8m/dbtGgRhg0bhg8//FD4YnmaMmUK5s+fjz///BMZGRlITk7Wd4exZ9CgQRg0aBBee+01ZGRkYMqUKfjyyy/x97//XX8l3XR4l+nV1MrKSuzatQuLFy/GggUL9LefOnXK4e/pjTfewPfff49vv/0WPXv2NPv6xo0bMW3aNLzzzjv62xobG83WKqRQu2vXrvjzzz+h0+mMTvC4dB5LcwUc0bVrV/z1119mt4v9PKZ+/vlnlJeX49tvv8XQoUP1txcWFprd19rPLSkpCUeOHMFtt90mSvcnW89lS4cOHTB8+HB8/fXXmD9/Pnbu3Inp06frGwx069YNQFva2ciRI20ei8/fsbU1cv9Wf/31lz51i/PXX38J+rfs3bs3evfujZdffhn79+9Heno6Vq9ebfXiBCEkcFHaEiFuxPVUNz3J7N+/v1HKUEpKCgDgyJEjFjshnT17Fvn5+RbTFQzdeuutGDZsGJYtW4bGxkZxvgkT3C7DggULkJuba3fXAWg74Te9+ssNv+JSl7p27QqpVIq9e/ca3e/99983+py7umx6PEcnFGdmZuLll1/GSy+9hLvuusvifaRSqdnz/ec//zHbFbH2723JHXfcgZKSEnz11Vf621pbW/Gf//wHYWFhuPXWW4V9Izae5+DBg8jOztbfptFo8NFHHyEhIUH/uyc2S/9Ozc3NZv+eQNvPzVLazP3334+LFy/i448/NvtaQ0MDNBqN4HUJ+TcyNGXKFJSWluKxxx5DS0uL0e99XFycPmgvLi42e+yVK1f0/33vvffiyJEj+O6778zux/2srK3xxhtvRFxcHFavXm2U8vfjjz/i+PHjGDt2rN3vo6amBq2trUa39e7dGxKJxOE0QkKIf6OdB0LcqH///gDa2lFOmjQJMpkM48aNszqoaefOnVi4cCHGjx+PQYMGISwsDGfOnMGnn36KpqYmLFq0yO5zLly40Gbx88mTJ7Fu3Tqz29u3b49Ro0bZPX5iYiJuvvlmbNq0CQB4BQ///e9/8f777+Puu+9GUlISamtr8fHHHyMiIkKf+qFSqTBx4kT85z//AcMwSEpKwg8//GCW1x4REYGhQ4fizTffREtLCzp27IiffvrJ4hVtPiZPnox27dohOTnZ7OcyatQotG/fHnfeeSe++OILqFQqpKSkIDs7G5mZmfpWrpy0tDRIpVIsW7YM1dXVUCgUGDFiBOLi4sye99FHH8WHH36I6dOn49ChQ0hISMDGjRuRlZWFFStWIDw83KHvx9S8efOwfv163H777Xj66acRHR2N//73vygsLMQ333xjMa2Frz/++MPilephw4bh5ptvRlRUFKZNm4ann34aDMPgiy++sJhC1L9/f3z11VeYO3cuBgwYgLCwMIwbNw4PPfQQNmzYgMcffxx79uxBeno6tFotTpw4gQ0bNmDHjh248cYbBa1Z6N8k595778WTTz6JTZs2oXPnzka7KQCwatUqDBkyBL1798asWbPQrVs3XL58GdnZ2bhw4QKOHDkCAPi///s/bNy4ERMnTsTMmTPRv39/VFRUYPPmzVi9ejX69OmDpKQkREZGYvXq1QgPD0doaChuuukmJCYmYtmyZZgxYwZuvfVWTJ48Wd+qNSEhgdek6927d2P27NmYOHEievTogdbWVnzxxReQSqW49957Bf0sCSEBwlNtnggJVEuWLGE7duzISiQSuy0iz5w5wy5YsIAdNGgQGxcXxwYFBbHt2rVjx44dy+7evdvovoatWk3deuutLABBrVpttS81tWrVKhYAO3DgQItfN22RmpOTw06ePJnt0qULq1Ao2Li4OPbOO+9k//jjD6PHXblyhb333nvZkJAQNioqin3sscfYvLw8s7aVFy5cYO+++242MjKSValU7MSJE9lLly6xANiFCxdaXQf3szH8Xm39TLiWq5WVleyMGTPY2NhYNiwsjB09ejR74sQJtmvXruy0adOMvoePP/6Y7datGyuVSo2OYalF7OXLl/XHlcvlbO/evc3ac3KtWt966y2zn7Pp92tNQUEBe99997GRkZGsUqlkBw4cyP7www8WjyekVau1jyVLlrAsy7JZWVnsoEGD2ODgYLZDhw7sc889x+7YscOsnW1dXR374IMPspGRkfo2xZzm5mZ22bJl7PXXX88qFAo2KiqK7d+/P7t48WJ9m1Rba7f0byTkb9LQxIkTWQDsc889Z/HrBQUF7MMPP8yq1WpWJpOxHTt2ZO+8805248aNRvcrLy9nZ8+ezXbs2JGVy+Vsp06d2GnTprFlZWX6+2zatIlNSUlhg4KCzH7/v/rqK7Zv376sQqFgo6Oj2SlTprAXLlwweo5p06axoaGhZms8c+YMO3PmTDYpKYlVKpVsdHQ0O3z4cDYzM5PXz4AQEngYlvXS6jpCCCGEEEKIV6GaB0IIIYQQQggvFDwQQgghhBBCeKHggRBCCCGEEMILBQ+EEEIIIYT4mL1792LcuHHo0KEDGIbB999/b/cxP//8M/r16weFQoHu3btbHEhrDwUPhBBCCCGE+BiNRoM+ffpg1apVvO5fWFiIsWPHYvjw4cjNzcWzzz6Lv//979ixY4eg56VuS4QQQgghhPgwhmHw3XffWR1uCgDPP/88tm7dajTVftKkSaiqqsL27dt5P1dADYnT6XS4dOkSwsPDwTCMp5dDCCGEEEJMsCyL2tpadOjQwanBla7S2NiI5uZmlxybZVmzc1SFQgGFQuH0sbOzszFy5Eij20aPHo1nn31W0HECKni4dOkSOnfu7OllEEIIIYQQO86fP49OnTp5ehlGGhsbkdg1DCWlWpccPywsDHV1dUa3LVy4EIsWLXL62CUlJWjfvr3Rbe3bt0dNTQ0aGhoQHBzM6zgBFTyEh4cDaPtljIiI8PBqCCGEEEKIqZqaGnTu3Fl/3uZNmpubUVKqxdlDCYgIF3dXpKZWh679i8zOU8XYdRBTQAUP3DZQREQEBQ+EEEIIIV7Mm1PMw8IZhIWLuz4dXHueqlarcfnyZaPbLl++jIiICN67DkCABQ+EEEIIIYQ4S8vqoBW55ZCW1Yl7QBODBw/Gtm3bjG7buXMnBg8eLOg43leFQgghhBBCCLGprq4Oubm5yM3NBdDWijU3Nxfnzp0DALzwwgt4+OGH9fd//PHHcebMGTz33HM4ceIE3n//fWzYsAFz5swR9Ly080AIIYQQQogAOrDQQdytB6HH++OPPzB8+HD953PnzgUATJs2DWvXrkVxcbE+kACAxMREbN26FXPmzMF7772HTp064ZNPPsHo0aMFPW9AzXmoqamBSqVCdXU11TwQQgghhHghbz5f49ZW8lcXlxRMq68755XftyHaeSCEEEIIIUQAHXQQu0JB/CO6BtU8EEIIIYQQQnihnQdCCCGEEEIE0LIstCJn/ot9PFehnQdCCCGEEEIIL7TzQAghhBBCiADe0G3JUyh4IIQQQgghRAAdWGgDNHigtCVCCCGEEEIIL7TzQAghhBBCiACBnLZEOw+EEEIIIYQQXmjngRBCAGh1LA4WVqC0thFx4UoMTIyGVMJ4elmEEEK8UCC3aqXggRAS8LbnFWPxlnwUVzfqb4tXKbFwXArGpMZ7cGWEEEKId6G0JUKIqLQ6FtkF5diUexHZBeXQ6rz7Ssr2vGI8sS7HKHAAgJLqRjyxLgfb84o9tDJCCCHeSueiD19AOw+EENEIvYLv6VQhrY7F4i35FkvUWAAMgMVb8jEqRU0pTIQQQggoeCCEiIS7gm96Is5dwf9gaj+jAMIbUoUOFlaY7TgYYgEUVzfiYGEFBifFuGVNhBBCvJ/WBXMexD6eq1DaEiHEafau4ANtV/C5FCZvSRUqrbUeODhyP0IIIYFBy7rmwxdQ8EAIcZqQK/hCAw1XigtXino/QgghxN9R8EAIcZqQK/hCAg1XG5gYjXiVEtaqGRi0pVINTIx2+VoIIYT4jkAumKbggRDiNCFX8L0pVUgqYbBwXAoAmAUQ3OcLx6VQsTQhhBByFQUPhBCnCbmC722pQmNS4/HB1H5Qq4yfT61SmhV5E0IIIQCgAwOtyB86q++i3oW6LRFCnMZdwX9iXQ4YwKiewfQKPhdolFQ3Wqx7YNB24u7OVKExqfEYlaKmCdOEEEKIHbTzQAgRBd8r+N6aKiSVMBicFIMJaR0xOCmGAgdCCCFW6VjXfPgC2nkghIiG7xV8LtAwnfOgdvOcB0IIIYQIQ8EDIV7M0xOYHcFdwbeHUoUIIYT4Kq5OQexj+gIKHgjxUt4wgdnV+AYahBBCiDcJ5OCBah4I8ULeMoGZEEIIIcSQzwQPH3zwAW644QZEREQgIiICgwcPxo8//ujpZREiOkcmMGt1LLILyrEp9yKyC8rdMp2ZEEIICVQ6lnHJhy/wmbSlTp064Y033kBycjJYlsV///tfTJgwAYcPH8b111/v6eURIhohE5gHJ8UERHqTM3yxboQQQgjxVj4TPIwbN87o89deew0ffPABDhw4QMED8StCJjBz6U2m+wxcepMvDjkT82SfAitCCCGuEMg1Dz4TPBjSarX4+uuvodFoMHjwYKv3a2pqQlNTk/7zmpoadyyPEKfwnawcG6bAv74+YjW9iUFbetOoFLXPXGkX82TfHwMrQgghxNN8puYBAI4ePYqwsDAoFAo8/vjj+O6775CSkmL1/kuXLoVKpdJ/dO7c2Y2rJcQx3ARma6f7DNpOqMGCd3qTLxCzSNyRuhFCCCGELy0kLvnwBb6xyquuu+465Obm4rfffsMTTzyBadOmIT8/3+r9X3jhBVRXV+s/zp8/78bVEuIYvhOYyzRN4INvGpQniX2yL6RuxNdQcTwhhBBP8qm0Jblcju7duwMA+vfvj99//x3vvfcePvzwQ4v3VygUUCgU7lwiIaLgM4E5u6Cc17H4pkFZ4q5iY6FF4vYIqRvxJVTDQQgh3oF1QXcklrotuZ5OpzOqaSDEn1iawNy/axQOna3EptyLiA1VQB2hxOWaRotX7Bm0BRsDE6Mdev7tecVYtPkYSmqu/Y2pIxRYNP560U9UxT7Z5xswORNYuRvVcBBCiPeggmkf8MILL+D2229Hly5dUFtbi4yMDPz888/YsWOHp5dGCADXXKU3nMC8Pa8Yt761x+iqc2SITF8cbXhSaZje5MgatucV4/F1OWa3l9Q04fF1OVgt8omq2Cf7XN1ISbVrAit3s5fW5YvF8YQQQnyTzwQPpaWlePjhh1FcXAyVSoUbbrgBO3bswKhRozy9NEJcnk5i7apzdX0LAEAVIkPV1f8GjNObhNLqWMz79qjN+8z79qioJ6pin+xzdSNPrMsRPbDyBLHTugghhDhHy0qgZcUtHdb6SAmbzwQPa9as8fQSCLHI1ekkfK46K4Mk+N/fb0JZXZPFXQ8huyIHCsqNAhFLqupbcKCgHOnJsQ5/X4ZccbLPp27EV/hrDQchhBDf4zPBAyHeyB3pJHyuOpfUNEHCMJiQ1tHs60J3RbLPlPFaV/aZMtGCB8A1J/uW6kZ8ccK0P9ZwEEKIL9OBgU7kpqU6i2cT3oeCB0Kc4I50EmeuOju2K8L3xFr8E3BXnOwb1o34Kn+r4SCEEOK7KHggxAnuSCdx9KqzVsdi0Wb7uyIjerbHobOV+pP1mxKjsXKP/ecT64TcUkqVr5/si83fajgIIcTXUbclQohD3JFOYu+qMwBEh8rQv2uU0Yn4vpNlKKmxvysyaOkuVGia9berIxQIlUuhadZafWxUiAwDEqKRXVDu1A4BzS3gz59qOAghhPguCh4IcYI70klsXXXmVGhaMPD1TACwW+xs/thmo88v1zTZzbq8/8ZOZm1jhZ7009wC4fylhoMQQnyda7otUc0DIX7PXekk1q46GxIaNFjDpTSpQmRQBkmNdi/iVUqM7xOPj/YWOnXSz6fQ/KXv8tDQrEVchBJggTKN5U5SgcYfajgIIcTXtRVMi/teJPbxXIWCB0Kc5K50kjGp8RjRs71ZmpErsGgLRv73SD9IJIzRhOtb39pj9aQf4Nddik+hebmmGXM2HDH7GqU1EUIIIZ5DwQMhIjBNJ4kNVQAMUFbXhOyCcv3VcmenUB86W+nywMFQmabJqP1rdkG5zZN+gF93KWcKyE13OFwx2ZsQQgixRQcJtNSqlRDiDC6dZHteMf618YhZPcD4PvHYfKTYqToBdw8BMy30tlWAbai4qsFmMbUzBeSGnaJ0OmDJViq4JoQQQtyFggdCRKLVsVi5+zSWZ540+1pxdSM+3FtodrulOgFbV9LdOQQs/mqht+F6cs5W8Hrswi3HUNvYanQswxN6Ph2kbOE6RT2ZkWP2NSq4JoQQ4mpUME0Iccr2vGIs2nwMJTVNgh5nOoV6Z36Jzdalzp50CzG+T7zF9fBhGDgA107oVz3YD1GhcpTWNmLSgC4WAy1niTXZmxBCCCHmKHggxEnWWo7yxV1FX7n7FFZknrLbxche21Y+1BEKNLbqbHZo2vDHBYu7JY7g1jl7fQ50briwIsZkb0IIIcQaHSTQUc0DIUQoWy1Hhfosq8juNOhRKWqr3Z2iQmT6LkkcdYQCkwd2QZfoEFRomhEdpoA6Qgkdy2LKJ7/ZXE+lSK1fDbkjcDDk7hoRQgghxN9R8ECIE+y1HBWiqsH6ybrhlfSBidFQBcvx3OjrjAICbhAdn85Dm3IvirJmb2erRoS6NBFCCHGUlmWgZcV9zxD7eK5CwQMhAhmedJ66XCvKMRkG4FMnlZlfgrkbci3WRAD8AgfAvYXXrhIZLEN1Q4vVXR91hMLqZO/tecU2a0sIIYQQW7QuaNWqpbQlQvyPpZNOMfBtsLAmq8jstpLqRjy+LgeRITKjlCVbJ8PuLLx2lek3d8WKXaetfr2xVYed+SVm37+1GhXq0kQIIYTYJ27IRIiP0+pYZBeUY1PuRWQXlENrkKTPnXSKHThwIoNlVgfTMwCsZdRwKzQtfuZOhrfnFZs9RiphML5PvNXAgQEQGWJ9PYb384SoEBm+/P28zftU17eYff+2alTYqx8vfZeH5ladqOslhBDiX3SsxCUfvsA3VkmIi2l1LN7LPIX+S3Zi8scH8MyXuZj88QEMWbYb2/OKnSqMvrtvB173m3ZzVwDmJ+RcVyWhxcbc3RdvyTcKgoC2QOgjG52Uhl3XDiN7xln8fpmrH48NTYRa5Zn0p8r6FrttcS19/3xqVMo1zRi0NNNi0EUIIYQEOkpbIgFve14x5n171GLbUu7q/bMjkx3ecfjlZBmv+zFgLHZRUquUuD1VjU8tpCzZY6llKZ9AaM9fV6yvkwFm3ZKIF+5IwXNjeunrLIrK6rEi86RL06AYAKpgmc3ickPc9//WjuNoF6ZEUXk9r8dVaFq8IoWJiroJIcQ7Uc0DIQFqe14xHl9nPqWYw7VJ/cyBE3dOhaaZ1/1W7DqF1VP74dfnRxidMPbvGoUvsh1/fsC4ZamzHaJ0LPDR3kL07RKFManxRnMUrlOHYd43R3mf3AsVLJc4dOzVvzg2r8KTg+aoqJsQQog3orQlEnC4uobvci7gxe/y7N6fhe02qmJavCUfADA4KQYT0jqiUtOEQUszsWTrcaeOa9hdSazZB5bSocakxuvTr1yhvtl9tQiGuzbuZq2+xlYdCyGEEPfR4Vq7VrE+fKXajnYeSEBxpltSpIB0GUcZphgt3ZYvyoTnyBCZUctSMdq0WpvgrNWx+MpOIbOvceWgOUtpSQBsFnUbDgykFCZCCCHuRsEDCRjWWnTyNSQ5Fj/86forvqW1jdj2ZzHvwMG0RaupqvoWo5alYrZpNT2xPlhYYbeQ2VnRoXJUaprdlhkaG6pwyXGtpSVNGtDZZnBrLXAjhBDiPjpIoBM5gUfs47mKb6ySECc50y0JaBs49kdRpahrsiY2VIGXN9lPpwKA+WN74eCLIxEZIrN6H+5KtVbH6q90356q1l/FdsaZKxqjz4VepRd64TxepcSrE1IBuLFNrAueyFZa0vLMU7yO4codEUIIIbZpWYlLPnyBb6ySECc5UyTMAJg8sAtKalx/shavUgIM/yLr2HAFDp2ttLnzwF2pXrn7FIYs243JHx/Qd25inDwxfm/XKaP8e74pUbOHd8f6WYNwYsntmD28O+/nWzguBXfcEI8PpvaDKth6wCSmXccvi3o8e7Mm+PKHKeGEEEJ8DwUPJCA4epU2KkSGD6b2Q0JsKO/HOHM+vnBcCsrq+Kf9xIUreX9vyzNPmQVQXL3zbT3b8X5OU4aF0/27RiE61PYuSLxKiTmjemBwUgzkQRKkd4/l9TxzRibrU68On6t0WxH797mXkHWqzOLgQEc42+2K+xka1rEQQghxLx0Yl3z4Aqp5IAFB6FXayGAZZqQnYPaIZEglDLILynk9bs7IZHz5+3mHTg65k2O+zxUVIoOOZXHqcq3g5zLEADh0rsrhx3P599UNzVi8JR8VGssn9dxL4sJxKUaFvnxqMOJVSswekQwA2PbnJVEKyfmq0DRjyprfjNbiTLtUIYEsNyDQ8HPA/GdICCGEuAsFDyQg8DlBjQ6VYf6d10MdYT6Mi8/jJQyQHBeun9NQUtOIJT8cs3oybcjw5Jh7LnsBiI5lMeWT32zehw8WsJn2xMfO/BJ8llVkM+1GbXDSbdplaP7YFDyVkWPzZBkAsk6X4f82/unUWp3FtUt1dIAc30B2zsge+PL3c2YDA2nOAyGEeJ4rahR8peaBggcSEKQSBgvHpeCJddZPUF+/u7fVkzLDx1ujY4GnMoxPKhVSCZ7MsP4Yzp03xOuDFcPnsnUyXt3Qave47vJ97iWbaw1TBOGX/xsOeZDEapehR4cmYvORYrOT5fljU/BXSR3mfbPTbalKtjjbLtVeIMqg7fuePaI7Zo/oThOmCSGEeBXfCHEIEcGY1LZCW7XK+MqvWqXkdRV5TGo8Vj3Y126RsWENAN+i3m9yLhjl0nNrjTdZa3SoHKFyKa9jugMDIEwhtVvgXdfUivf3nLLZZeijvYWYP7YX1s8ahPcmpeF/f78JE/t3wpwNuVieeVJw4HBfv05g4JquTM4MkOOCQ8B8baZpSVIJox8YODgphgIHQgjxElpIXPLhC2jngQSUManxGJWi5n011zS95uTlOrA2LrEbnlRWNzRj3jdHea2rQtNi1rffdK1FZRqs3V8ETbNWyLfsUiyAuiZ+63lv12mogmU2h58t2Xocvz4/AjvzS/Do5384/L1KGGBEzziMTIlzeCggH44W4nPBoenaKC2JEEKIt6PggfgFS5N6rQUE3NVceyyl1/C97vt5dhF+zCvhee82tk5Ec89V4rP9ZwUdz9uwgM3dg2stZU9jeeZJp56LSyF7dmQPPDemJ/b+VYrvci85dUxLnGmXKjSQJYQQ4j10LAMdK+7rtdjHcxUKHojPs5ZDb3gF1zS46N81CofOVlo9abM2jZpvk06hgQPQdiJquM6isnqsP3jOLfMlvMmnWeJ0UmIBp4MQa7i6BGfbpfINZAkhhBBvQcED8WnWTvINO+IAMAsuJMy1GQeAcbDh7DRqR0SGyFCpacKQZbtdlmLjCNOfkztUe0FRtC1ciDl/bC/aNSCEkAClc0GNgo5qHghxLXuTehkAL3x7FJUW2pCanhAbBhuqYLnbT+BbtDo8mXHYrc9pj0zKoEXrvsiBQVuBuTd0VOJEhcigCJKgpOba4D61SonxfeKxZOtxm7tdhBBC/JeOlUAncmtVsY/nKhQ8EJ9lb1IvC1gMHKzdl2u/+dyYnqKsTwgNz6JjoWJC5XhoUFes2HVK8GPdGTgAbf8GtyTHYMufwlO+XCW9eyzevT/NKMWtUtOMpzJs73aZBhBCanIIIYQQb0bBA/FZjna6sYYr2K2oa7J7X1+xZML1ABiPpB85YsufJQiVS72mo9QPfxbj19NleOOe3piQ1hFaHYshy3bb3O0ynf/ApybHFAUbhBDi3bRgoBW5GbjYx3MVCh6Iz3Km040t0aFyXtOkDU/Go0NlvCZJuxMD4MXv81Bd3+LW+g1neUvgwKmqb8Hj63KwmkdKm2Gr3sFJMbxqckwDCEeCDUIIIcRdfCO5ivgdrY5FdkE5NuVeRHZBudGANL4GJkYjOlQu+trUqmCbQ7wYACsn99UPM1s/axBeGXc9vO3CMIu2E19fChy82eIt+bw7X5XWNtqtyeGOafi7b2uI3hPrcrA9r9jB1RNCCBETV/Mg9ocvoJ0H4nZiXVmVShjcldYBn2YVibq+Sk0z7riB/xCv7XnF+MeXuU6dpEcGB6G6oZVO9L2YkJS2uHAlr5ocw10KvsGGYUoUIYQQ4m4UPBC3ciSNwxIuJzxELv6v8IvfHYUqRIZRKWq7Q7zEaus6Iz0RyzOFFzUT97KX0mY4/+GHP/kNpeNqd+wFG4BxsEEIIcRztBC/RsG7knato+CBuI1Wx2LR5mOCik0tsbRzYQ0DQBUigzJIyjvlpKqhBVM++Y3XbgifEz4+usSEIjJEhiqe3aGIZ3ApbU+sywEDy0MDF45LgVTC8K7J4e7H9/cz0IYGEkII8S6+kVxF/MLK3aeN+uWbMkzjsMZaTrglXPjxxj29kTVvBNbPGoSHB3flvV4+eeZidXyqqGuiwMGLMWhre1tS3QBVsBz/ntwXoQrzay+qEJn+vwcmRiNepbR6XYpBW7oeN6Wab0qUP3UDI4QQX0U1D4S42Pa8YizPPMnrvtZOyIWmCJnWJ3CpHp9nn+X1eMPdkBE92xv1+ufSl8To+BSvUrqk8JuIhwVQrmnGnA1HAAAMA7AWfhGr61uM0u8WjkvB4+tyzO7HBRTcLgUA3r8D9LtCCCGep2Ul0Ip8si/28VyFggfictxJP1/WTsj5pgjNHp6E9O7tLPbG564G22rDaojbDRm0dBcqNM3627mUplEpaqfbtM4f2wtRoQqHH0/cz1LgAJin3wGwmI6mCpHhjXt6G6XEqVXBvJ6b7/0IIYQQV/CNEIf4NCF1AYZpHKb4pggltw/H4KQYi3UTUgljtQ2rLYaBA3AtpWlnfgn6do4UcCRzUaEKfVBDvEu4Uir4MVzAuXL3KTyxLsdiOlq1hdv4/A7Y+vsghBDiPiwY6ET+YB0owF61ahUSEhKgVCpx00034eDBgzbvv2LFClx33XUIDg5G586dMWfOHDQ2CkvBpuCBuJyQugDDNA5TQgtQrRmT2taGVe3Eybph68ycc1UOHwdoK4CVShjMH5vi1HGIuKJD5ahtdLz3xWdZRTZ3t0xnPHCBra0aCVt/H4QQQgLLV199hblz52LhwoXIyclBnz59MHr0aJSWllq8f0ZGBubNm4eFCxfi+PHjWLNmDb766iu8+OKLgp6XggfiMtwguFOXa3ndf87IZJudjYQWoBquwXQY3ZjUePz6/Aj875GbEBkss3JE27grzJVOFjqX1bYVwJ4qrXPqOMQx1n6f6ppanTpuVYP13wvT5gDc72lTqw7PjuwBdYRxYBuvUvJuY0wIIcT1uJoHsT+EePfddzFr1izMmDEDKSkpWL16NUJCQvDpp59avP/+/fuRnp6OBx98EAkJCfjb3/6GyZMn292tMEU1D8QlhLRTBdpOjmaPSLZ5H+7KrKUCVKDthMzwyqy9YXRSCYP05Fi8cW9vPHH1mJ4Y0rZy9ymU1TXiw72Fbnm+yGCZzRPbQMGgrR5Bx7KobjAPFJpbdS5fQ2lto8XfU3WEAnNGJiMhNtTifBFCCCH+q6amxuhzhUIBhcK4NrK5uRmHDh3CCy+8oL9NIpFg5MiRyM7Otnjcm2++GevWrcPBgwcxcOBAnDlzBtu2bcNDDz0kaH2080BEJ7SdqivSMaytwVL7VWtpTNGhju1ICFXd2Oq2wOGZ27ojvTvlzANtgWJlfQskjOdOyovKNBZ/Ty/XNGFF5ikogiRW63cIIYR4jo5lXPIBAJ07d4ZKpdJ/LF261Oz5y8rKoNVq0b59e6Pb27dvj5KSEotrfvDBB/HKK69gyJAhkMlkSEpKwrBhwwSnLdHOAxGVs+1U+RzbGsO2qtbWwN0279ujCFfIMOjqidmY1Hj9NOmS6gZUaJpxrqIenx84a7WzDjdNuL651eKVa2/0yb5CaJp9ZYalezibduYI7ndn/cFzTg9NJIQQ4l/Onz+PiIgI/eemuw6O+vnnn/H666/j/fffx0033YTTp0/jmWeewZIlSzB//nzex6HggYiKfzvV7kjvHms3HUOrY3GwsAKltY0oq22yeWwuj/yL7CK7a6iqb8GUNb+ZpTFVNzTjzR1/8U63WjguBX+V1GJ55ile93eHp4YnQSaRYMUu8zVR4OAdWACTBnSxOfvEsC6Cm1FCCCHEO2ghgVbkBB7ueBEREUbBgyWxsbGQSqW4fPmy0e2XL1+GWq22+Jj58+fjoYcewt///ncAQO/evaHRaPDoo4/ipZdegkTC7/uh4IGIin871TCjEyLDIIHL8d6ZXyKoboKz99QV3vfl0pg+mNoPAPDEuhxeuyYSBlg5ua9+x+Kz/UVeMyG6e1w4lv14wtPLcDsJAxg0L4IqOAitOhaaJusBEwPP1LnMTE9AQmwIr/uKNcWcEEKIeAzTjMQ8Jl9yuRz9+/fHrl27cNddd7U9XqfDrl27MHv2bIuPqa+vNwsQpNK2luSstTQLCyh4IKJypJ2qpYJRS4O1+OI62PDBpYcs2nwMAMP7RFLHQj/YTSph8MY9va0Wcrvb+t+KUFITeCecOhaQSQEpI0Fjq45XKpknAgcAGJWiho7nC7UYU8wJIYT4n7lz52LatGm48cYbMXDgQKxYsQIajQYzZswAADz88MPo2LGjvmZi3LhxePfdd9G3b1992tL8+fMxbtw4fRDBBwUPRFT2Jjhzud5cO1WusNn0vs5cxW9oEdYlhwVQUtMk+HkMT9DHpMZj9dR+mPftUY/vQBwsqnLJceNVSkwa0AXVDc3Y8McFp1uZukKLFmiB/X9/010Kd+F+/ys1zXjlh2O87ktD4QghxPvoIIFO5LQlocd74IEHcOXKFSxYsAAlJSVIS0vD9u3b9UXU586dM9ppePnll8EwDF5++WVcvHgR7dq1w7hx4/Daa68Jel6GFbJP4eNqamqgUqlQXV1tN5eMOI4LCADjK7vcZhzXr16rYzFk2W7BaUneYv7YXnjklm5GtzW36nDT65keKcJ1pXv7dsDuv64YfV+hCilYFqj3gToKBm1D314e2wtZp8uxMeeCx9bx6NBEfLS30Oauh+nfCiGEBBJvPl/j1jb717uhCBO3K2NTXQtWDvnOK79vQz7TqnXp0qUYMGAAwsPDERcXh7vuugt//fWXp5dFLLDW+lRtMuiKb3G1t4oOlZvdduhspd8FDgDwzeFLZt+XpkmL+mYt5oxMxsz0BM8sjCcWQLmmGWfLNR4NHP5+SyI2Hym2my5l+rdCCCHEu2hZxiUfvsBn0pZ++eUXPPXUUxgwYABaW1vx4osv4m9/+xvy8/MRGhrq6eURE4atTw2LoA07K3lLISgDoH2EAgCDyzWW060sUauCzW7zlu/JndYfPAfrc5q9y3u7TnvsuVkAH+/jN8/j7fv6ID051rULIoQQQhzgM8HD9u3bjT5fu3Yt4uLicOjQIQwdOtRDqyK2SCWMzRaT3lQIumj89QCgT7eyhwGQ1jnS7HZv+p7cxZF6EU/xlRzNMo3v/EwJISQQebrbkif5TPBgqrq6GgAQHW29mLCpqQlNTdfehE3HfRPPsldc7Q6RwTK8cW9vfXrIo0MT8dG+QquD4TgsgAGv7cTfh3RDYrtQ/c4K9z35cjoW8byy2iZodSwNhyOEEOJ1fKbmwZBOp8Ozzz6L9PR0pKamWr3f0qVLjcZ7d+7c2Y2rJPZIJQwWjksBYJ704q5TpocHd9UHDtvzitsKWXlGMnVNWqzYdQrPfJmLyR8fwIDXMrEjrwTj+1CeOnHOkq3HMWTZbmzPK/b0UqDVscguKMem3IvILiiH1hNtqgghxMuwrAQ6kT9Y1jdOy32y29ITTzyBH3/8Eb/++is6depk9X6Wdh46d+7s9VXsgcbSnIeoEBlatKxb2oE+NjQRz43pJVrnpxC51Cc6EIlFEcSgqdXnXkZ8AgPPdlyy9LdpOJWdEEJcwRe6LT3yy/2Qi9xtqbmuBWtu3eCV37chn0tbmj17Nn744Qfs3bvXZuAAAAqFAgqFwk0rI44yLa4uKtNgeeYptz3/h3sLoZRJRUs1CqTAAQAFDi62eEs+RqWo3Z7CZG0Gi+FUdgogCCEk8PjG/gjaxmbPnj0b3333HXbv3o3ExERPL4mIiCuuvvOGDvjy9/Nuf/7393iuC489zNWPZ25LRt/OKk8vh7gRC6C4ulHQ1HQxaHUsFm/Jt1iLxN22eEs+pTARQgKWjr1WNC3eh6e/K358ZufhqaeeQkZGBjZt2oTw8HCUlJQAAFQqFYKDzVtmEt/kqdkPAodSu5VapcT4PvHY8Md5KsQOUO5uAWzv79AwqLHVUY0QQoj/8Zng4YMPPgAADBs2zOj2zz77DNOnT3f/gogZrY61OdfB2tcNbz91uc5j62fgXa08pw7qgrG9O6BS04ynMszTRzj39euIjTkX3bo2Yl28SolJA7qgrK4RXxw4J8ox3d0CmG+wEohzTQghBIC+yFnsY/oCnwkefLCuO6BYKqyMDJZhRnoiZo/ojp35JRYLL8f3icfmI8VecUXd237Dth0twc3dYrFkq+X0EaAt4Nl1otSdyyI2zB/bC9PTEyGVMMguKBcleIhXtQXa7sQ3WAnEuSaEEBLofCZ4IN7LWmFlVUMLlmeexId7CywWERdXN+LDvfwm7gaiSk0znsywPbSOBVBZ3+KeBRGb4lVKfeAAiDfHZP7YXm4pljbcAYwNU0AdocDlmiaLa2fQlk7n7qCGEEK8hQ4MdCI3lhf7eK5CwQOxyF4KkuH9rBVWcgKt+5BYvG0nhNg2vk+80d8IN8fkcZ5Ty62JCnV9xziLO4chMrAwT+fjvsOF41JoiB0hhAQgCh6IGSG93T1V4OwK8SolWJa1e7X17fv6oEzThJ+OlWDr0RJ3L5N4qY/2FqJvlyj934hWx+Kvklqnj+vqugJrO4fVV3e0VCEyVBnsbqlpzgMhhEDLMtCy4l5AEft4rkLBAzEitLe7vxRMMoB+2vUT63JsXm1NT47F9rxibKPAwecFy6RoaBFvZ2zxlnyM6NkeH/xcgE+zClHd4HxKmSvrCuy1ZGXQ9jNa9Ug/lGmabO5CEkJIIKGCaULA70TCdGCVPxRMmu6qfDC1n9nOi+HVVj6pWu6kDJKgsdWLe816qTkje6Bbu1D8Y/1hUY7HtS/tt2SnKJPRXVlXwKUlZp0u49WSVSJhMCGto+jrIIQQ4nsoeAgg9uoYHOntzhWF+mrq0pyRyZg9IhkAkF1Qrv/Z/PJ/w3HobKXFn5W3pWpR4OCYmoZmvL5NnFaqhhwJHNxZV2ApLdEef9lhJIQQsejQNthN7GP6AgoeAgSfOgZHe7tPGtAZyzNPibdYN2AY4NFbEvHMyB42fzaWrrbSiZR/WJNV5OklAGjbAfny93NGv3/tIxSYPLALmlp1yC4oFy1VyFpaoj3+sMNICCFEHBQ8BAC+dQxCe7s7cgXTW7As9G1iP9pbyKvGg9u5OXXZ+SJY4jkM2oJHnYfzzhi0BQk3JkShS0wIKuqaEB0qx7mKBqw/eM4oILfWsEAIR9LtqCUrIYRYxrqgVStLOw/EGwipY7DXl97wRMLRK5jexlLgAJj/bCwNuSO+h0sP8oaZkyyAuiYtpnzym/62SJPORhxrDQuEcCTdjgW1ZCWEEGLMN8q6icOE1DFwfekBmMW+hjnYAGxewWQARIfIoAqWObN0t7B1Dsn9bFbuPo0n1uVQ4OBFGLRdjX//wX4IU0h5P06tUmJmeoLL1sVXiLztpde0PsJS4ABc+z1dvCUfWge3TCjdjhBCxKNjGZd8+AIKHvyc0DqGManx+GBqP6hVxilMapVSf9WTT0BSUd8iSptKb/BZluXdCeIZhoHs6FQ1busZx+txd6V1wNv39UGI3LMbrnekqlHfLLzI3TDQd4QjdQvc7pujAQshhBD/Q2lLfk5oHQPQFkCMSlGbdWYC2joS/ZhXLNr63p3YB+3CFPjm8AUUXKnD0Ys1oh1bLFV+EgT5C65tLgAMWbab947QLydL8X3uJVcujZe9p0qdenzW6TKU1DTqayTUqmD07xpltTsYx15aoiWWOqx5M3sd5QghRCw054H4LSF1DIakEsboZMFVxdHnK+vx1k9/UUoQsSk9KQb3D+isPyHcmV8iuOamst752QtiqGtyrrXuyj2nzW6TmBSAWyqw5tISLQ1BtMcXUp74dJQjhBCxuCLNiNKWiFfgW8dg6+ocVxzN9wSfAaCOUEAdobTaN4ABEBUiw/LMUxQ4+CB3X8xN6xKJCWkd9QGtNw3p8wamWUVcgfV2k11Ca2mJ9nh7q1Zrr1HWfg6EEEIcR8FDAOBTx2CN0PaO3DnlovHXY9F420ELnfz5LnenwN+cFKv/b28b0ueNbBVYj0mNx6/Pj8D6WYOw/IE0RIdab2zAFaa7asp1dkE5NuVeRHZBucN1FfY6ygFUt0EIEZ/uaqtWsT98AaUtBQhrdQz28oGFnqipTdIEPpjazyyVQK1SYtKALlieedKxb4YElDCFFAMSovUTwHf48FVkoelCzrBVr2CYlhgsk+CJdTn6x3DcPeXa0RQjIR3lfKFugxBCvB0FDwHEtI6BD765zg8P7orbU+PNAhJrQcsPf3q+cNUXpHVWIfd8taeX4VE3JUbj1rf2+MVugyeufdv7G+Z2Ji0F+a6oF+A7tJIvoR3lCCFEDIFc80DBA7GJb67z7anxVgMTS0GLt+dQe4vzFQ2eXoLH7TpxxdNLcJppQbM7xYUr7XYhcnRnUighQyv5PrcjHeUIIYQ4joIHYpOj3Zr4Htcfria7UrmmGdGhMlRqWrymRuTO3u3xw9HLnl6GT5g9PAlRIXIs2XrcI88fGSJDpabZrKWttW5Mrk7rcUWKkateowghxJZA3nmggmlikxjdmuwd11dFh8rd8jx3p3UEYP7z94RRKXG4o3cHr1iLL0huH47YcAWv+0YGy0T/uVbVt+DJDO/pQuSKFCNXvUYRQgixjIIHYteoFDWeHZkMVbBxVxY+3ZpsGZMaj/cf7Ot1J6J81qOOUODAC7dh/theLl/PiF7t8ezIHohQem6jMEIZhP9M7ot7+3XCUxmHvWYXxNvFhSt5p8vMSE8E4J4g0VNdiFyVYuRMRzlCCHEEt/Mg9ocvoLQlYsYwP7qoTIOM387hcm2T/uuqYBlmpidi9ojugq7mWcq7lkgYrzsR5bOeyQO7QB4kwfT0RHzya6Ggqb1ChCmCMPerXKOfvzvNHt4d6d1j9Skf6W/s9rp/L29kmCrT3MpvKFxaRxVWPdgPS7aKP4zREsMUoYGJ0W6ZzOzKFCN31W0QQggQ2GlLFDwQI3wmSVc3tGB55klcpw4zuqJnqyjT0nHVEQo08jyx8jYJsaEAnJvay0ddUyvqmjwzGTkmVI45o3ro/w3fyzyJkhqqUbHHNFUm47ezvB437b+/I16lxPyxvRAVqkDW6TKL06TFlplfgrkbct0ymdnW34sYKUbuqNsghJBAR2lLRE/oJOkXvj2qT3nYnleM9Dd2Y/LHB/DMl7mY/PEBpL+xG9vziq1Pf61pQlV9i+jfhzsUlWn0/+3o1F5vd0+/jkbB3/LMUx5ekW8wTZU5W1HP+7HF1Y14KuMwqhuaMWdUD8SrrE9pB8RJcVqTVeTWmgh/SjESa9AdIcT3sBB/UJyvvILQzoMfsteW0dpjhEySBoDK+hYcOFOO2sYWPH51yJShkppGPL4uB5EhMp/5g+BreeYpXKcO15/ojEmNh04HPP/tn6ht9MxOgdg+2VeI/l2jMCpFjcVb8j29HJ/x9n19kJ58bSJ21+gQwcfg2pUuHJdi8W+L48zfFQOAsdJC1tG2qXz5Q4qRmIPuCCHEl1Dw4GccfUMTOkmak3W6DGv3F9m8j6/uLthiemK1Pa8YT2WYD77yZSzavsdwhYxa6gpQpjGuT3locAJe3Xqc9++GYS3CqBQ1IkNkTv8NWUoRYgGwNhbl6snMvpxiJPagO0KI7wnkmgdKW/IjVtODeKQgODp99ffCctQ3ax16rC/jTqwOFJQj63QZ5n1z1K8CB05xdSOyz5R5ehk+xbRTkDxIgpscKAAurW07cXc0cIgOlWH11H54bGgiGJP3I4YBRvRsx3sd5Bp7g+4A93exIoQQd6LgwU84+4bm6PTVo5dqHHqcv3gqIwdTPvkNVQ3+t7tyDb8rIXfeENhXWhm07fJZ6hTUr2uU4OPFhSuxM7/E4fXMv/N6AMBHewvNUpN0LLCb5+Tu2DB+cyoChZBBd4QQ/xXIrVopePATzr6hcS0Uhf7aNrb4Zrcksfh30NBmcFIM4nkUg8erlIgMkdm9n79iYb1TkJBUfi4IqdQ049OsIofXExeuEFzHZBFdQDfiikF3hBDiSyh48BPOvqH5w8RnIr6YUDkGdYvhNQzv432FflnfwteckclW89wHd4u1eLs188f2wpKtjhWpc8EHWIhSq2JawxHoXDXojhDiW2jngfg8Md7QuBaK0aGBe/WYGOPatUaFUuqKPdzsD0sGJcUgRC61ewx1hAIfTO2HqFCFQyf+hrMSxDrpp5NgY/Z2aW2lrxFC/AcFD8TnCXlDs9WbfExqvD5XWmyqYApKfM0n+wqxPa+YUjB4sHeSLQ+y/XIbpgjC3udGYExqPO+fd4jM+JiGsxKcPemnk2DLDHdpTV9vxRh0Rwgh3o5atfoJvpNbd+aX2G3lGueiAsmZ6YlYkXnSoynUCinQZNIcKipEhvv6d8LH+wrN7s/97J4d2QMtWi1W7ilw/SK9zOIt+Xj7vj6eXoZXUwRJbJ5k8+maVNfUikNnKzE4KYb3ib9SHoTHbk1AQmyI2awE7oJCSXWj4L85Ogm2jdulNX0tVdOcB0ICBssyYEXeKRD7eK5COw9+xN7kVgD8WrmK/LvLXcGcPaK7x9OiTAMHoG3Y3f9+O2fx/pEhMnwwtR+eGZmM5PbhLl6d9+EK7cHAoYL6QNHUqsOOPOudkYTWJPFtYFChacbyzJOQSSQYnBQDqYTR7yz+8OclTBrQWT/wTQhfnPZsjaumQI9Jjcevz4/A+lmD8N6kNKyfNQi/Pj/CL35mhBBiC+08+Blrk1sBYMiy3VZbuRoOPSurE69A0vQK5pjUeDS06DDnq1zRnkMM1mZVVBpcLfb23O97+3XElj+L0dwqfgessromqztb7jYjvSs+yzrrwRVYNn9THkanWp7GXFSm4XUM7nfMcCeRj9nrc7ASfSGRMGZXw7kOWHyL2eeP7YXp6Yl+sePg6inQvjzojhDiHB0Y6ES+pCb28VyFdh78EPeGNiGto/5qJN9WrgfOlKOsVrzgwdIVTHWEd5+Em+LmY/TvGiWo5aa7fZNz0SWBA9B2UmttZ8td4lVKrJ7aDyN7qj3y/PaUa5ottkLenleM5Zmn7D5ewgD9DeZBCGlgoGOBJzMO43ELO4vV9S2orm/Bs7clI9JG3RG3Q+hPgYOjQzMJIYRYRzsPAYJv2sSsz/8QZWJ0ZIgMqyb3w6CrwYuhgYnRiAyROd3Wc/7YXohXKbFk63FRWlJaYzgfIxCHxsaEylFS3YDsgnKMSlHrd7ZKqhuwZOtxVGiaXfr8I3vFoac6AoOTYjCoWwze/ekvlz6fMzLzS4yuRGt1LBZtPsbrsToW+poHjhg7ddzO4ld/nMfrd6fiqYzD+ts57q5x0OpYs91RMZ/X3tBMw51WfwiUCCHu54ruSL7SbYmChwDBN+XGXuDApayM6NkOu09csVqc/cY9vZGefK23veHJQmyoQpS8l+gwBaJCFXhuTE9U1DUhMliG1348gUpNs+hpNYHcbahc04w5G44AME75yC4od3ngAACZx0uRebwUK/ecRmSwDOoI720buyarCAMSo/U7bSt3n0ZJDf+dPEu/Z2Ls1HE7i1GhCo8X+ro6lQgQNjST0o4IIUQYCh4ChDOdVwwZnmRYOgmwdBJi6X5imP/9UdQZVEDHq5SY2L8jPtpbKHpevrfXO7gLl/LxwdR+aHJRipQtVQ0tXj/Vm7uivTO/BMszTwp6rKXfM+5vV4y/n9LaRkxI62ixLsodV+C5VCLTv03D3ysxAgiaAk0IcbVA7rZEwUOA4AowH+dZgGmJaSGlteJsruPLwcIKZOaXYE1WkUjfhbE6k9ZJJdWN+GhvIR4dmojNR4pFC1Yig2X6onOxTuJ8lWHKx9sTqX2rJcXVjThQUI7FW4RNiDacqWCa1jN/bAqezHD8b5djWJDt7ivu7kwloinQhBDiOhQ8+DHTE5BRKWrMTE/Apw6ezMeGK3i9qbtqp8Ee7gRk85Fi/PJ/w3HobCVKaxtRVtuEJVuPO3zcHu3DcKCgHIOSYjC+Tzw+3Gs+D8JVGLTt5swf28vltR18cSkfWafLEB0qd0mamK/LPlMm+N9qfJ94SCWM1bSeWbckYs2vhQ7V3XC/R54c+ObOVCKuuYGtn5VpgTohhAhBNQ/E71g7Abmxa6TDxzS9SmfpOcQohOZOdB64sTNW7LLfpcYQdwJiWHi6KfeiU+s5WFSJKWt+Q4hcKkoxOV+GRaxcKseTV4tdvcH7PwfewDy+HAmmProalH60t9Ds8cXVjfh4XyHG9lZj61Hr8yQs8ZaBb+5MJTp0ttJukMUVqA9MjPZIChchxLdR2hLxK9byiourG7HlT2EnHoDlq5bWnkOMwAFoO9FxJqfe8ARErNQEdwYOABAdKsdrd6diTGo8tDoWr/wgLA2GeE5ksFzwY1gAH+8zDxwMbT1aApUyCDVNrWB5RihCiqFd2QXJnalEfAOQzPwSzN2Q69LibUII8TcUPPgZW3nFjrB01VLs5zCkNunm4yjDExAxC07daVyfeIe79tjj6UFvYlIGMWhs9a7vJjpE5lCDAj4pSdWNrbyONXt4d6R3j+UdALi6C5K9pg1iplbxDUAs1WOJXbxNCPFPrAvSlnxl54GGxPkZe3nF9oQppEafq1VKrHqwL1TBcmzKvYjsgnIcKCgX5UScAaCOUOB/f78Jyx9Iw/yxvfDc6OugCpZDq2P1JxtC/pS4QVeGJyBcsbhv/Eles3b/WWzPK746ZExY1x57vOtU2zneFjgAwGs/nkBqxwiP/pyT2oXqh0Ta446BatzfIQCzv0WxU6vsvXYwgNWBj9y/GTcckhBCiDHaefAzO/OFpyUZWnJXb6gjlPq0hUpNM5ZsNalrsDGlVggWwKLx16O2sQVvbj9h8YrnwnEpeIJnhyhbJyBjUuPx6NBEm8XOt6eq8WOecz8/sb3w7VEoglwT49/Wsx12nbjikmNb4k+7HfZUaJqxM7/U42vgw51dkLip2a6eM8EFKk+sy7E4i4YFbKZ90RwIQog99l5HHD2mL6DgwY9szyt2uJMSRx2h1L9Zbs8rxlMZFuoaROqzP2dkMgDY7fv+7MgevK68hyqC8PbEGyyegGh1LDYfsX71lAHwW6HjaVKmxxLrBaDSyRoSW367OjXbXXzlRdFfXKhqsHsfrY7F2qxCtw5Us9XiWUy2ApXbU9W8XitpDgQhhJij4MFPaHUsFm12vKDWNN/YlXUNnE6RwXjxu6N2r3g+N6Ynr+MFSRiMSlFb/BqfNpEVmhZEh8qdnpqsMuk4Fa9SIj0pBhtznOv6JBYGbYFWXRO/3Hnimz7LKsJNidFGJ+qxYW3T3cs0TSgqq8f6g+dQUuP+gWrumjMxKkWNcKXsav0Ui8HdYjEoKQYHCyt4BQ9ltU3YlHuRujARQszowIAROSFa5yMJ1hQ8+ImDhRW8TwJMWUr3cbZ2go9FP+Sj1kbxJ3fFs6KOX6FwVUOL1aujfE98bkqMwo95l3nd1xplkAT/+/tNKKtr0p90AMCvp8tELXp2FAugVev+6dD+xBdSsBi0pb0t2nxMlN87XxuoZqkAPOPgOdyd1hEjerWHOkKByzVNVv8dJQyM5sNQFyZCCGlDBdN+wpmrgmqV0qyziDu2620FDobKNc0IkUnt3xHW1833xOfHvMuIDJEhVM7v+SwpqWmChGEwIa2jUcHqkO7tHD6m2BqdaIMbaIJlEqgjjH9/1Col7rzBu08iWbSlvTkbOFhqQuDtrBWAV2hasCarCFM++Q2NrTr9DqclprXSYhaPE0J8HzfnQewPX0A7D37C0auC0aEy7P7nMOSerzLanvemq4xChpFZW7e9NpGGqutbnL6qbBjEeGriNhHHm/f1QXSIHNlnygC0pdtU17fgyQx+hfy+jHsbmzSgC37485JPpO/wTbmsvppaGMxz+KPYxeOEEN+mYxkwNGGa+LKBidFQRygFpy5VaFqQvmwXKjTGOfrzx/ZCZLBMtOJoTrBMgoYW11z1jgyRQadjodWxZm/strqvmBIjHYULYqwN0xPCFf8OhJ+Rvdrh9W3HjQK/jYfO894183WRITKwgFHDAm9P3+Gbcsn9TQoZ/khdmAghhNKW/IZUwmDR+BSHHmsYOABtb45PZhxGbJjwKbn23NO3o+jH5FTVt2DKmt8w4LWdWLLlGLILyo36tHPdV1Qh4rSatYRL8ejfNQpZp8ow7xvLBeFCRLlwvf5MjCvDmcevmM8+qGmCxs3Txj3h3r4dUFnfYjY13tvTd9yRckldmAghLOuaD19AwYMfGZMaj9VT+yFSpJPN01c0ohzH0OY/L4l+TFNcXvPkjw9gyLLdZic5pidDYmIBpMSHY9DSTExZ85soOwaF5fXOL8yLhMilZjUErkADvpzzXa7lv1VHhqhpdSyyC8r1gyZd+Th3pFx6U1onIYS4G6Ut+Rmuh/qBM+XIOl2Gz7OLUNfkPVdJaxvduxbDeRGjUtSY9+1Rlz0Xlw7lzsFrvqi+WYuPH7oREgmDz7LO4CcXDlNj0JZ648p5Gd6Iu4DgTP2OrfN0Iek7lmp++KQ+Ofo4IfVNjogKkflU8TghxDVcUeDsKwXTPrXzsHfvXowbNw4dOnQAwzD4/vvvPb0krySVMEjvHot//u06zLqlm6eX41GGV0n3ny5z+a4D4ae0thGDk2Iw7eZElz4PC+DxW5MCLvWruUWLhwd1BWC9m5AY7KXvWOt6ZC/1ydHHAdfqm1ylsr4FO/O9axI9IYS4k08FDxqNBn369MGqVas8vRRROLqVz8f2vGIMWbYbyzNPiXZMX8VdJf0254Lgx/rGNQDfww3iG9QtRrQ0O2suVDZguouDFG9T36LDv3efRrBcarPGx9mgylb6jq2uR7ZSnxx9nCGuvileZX19zvxtz/v2KKXFERLgqFWrj7j99ttx++23e3oZonB0S57vsZ3t8OOPhBa5zhnZA1/+fo5arLpAVIgc2QXlKK1txIybE426+Yjt+9wLbk+X8xb1zVrUN2sxZ2QyEmJDjSZMx4W3dWeb81Wu4OOaTqS3hM9Ud0upT44+zhSXwnmwsAI780vwfe4lo+nxapUS4/vE46O9hfrj8lVV34KVu0/jmZHJAh5FCCH+waeCB6GamprQ1HRtQFJNTY0HV3ONtZN7w/x8RwMIvj3OA9GAhCj8lM9venS8SonZI7rjiWFJ+CK7CHtPXsEvp8pcvMLA8eq2fKMuX5EhMrRqWdQ1id8CNVADB0MZv53F/hdGmnWgyi4oF3wsSxPpLeHbkcj0fo4+zhKppG0ux+CkGLw0NgUHCytQWttoNK+ib5coh+awfLa/ELNHdKd5D4QEKJrz4KeWLl2KxYsXe3oZRuxtyTs7hIhvj3NvxwBgGNtFm0KOpVYp0bN9BEJ4DoRaOC4FO/NLaLibi5i2B+YKe0MVUmi8qMDfX1yubcbzG4/glh7tjE6c+RQXS0z+DtU8d0j5diQyvZ+jj7OHCyRMGe5QlNY2oqy2CUu2Hrd7vKr6Fpr3QEgAc0VrVV9p1erXwcMLL7yAuXPn6j+vqalB586dPbgi8bbkrXGk/zgXonjL7yy3nlm3JOKjvYVOrYvrgNTQosVDnx20e//IEBneuKc3AFDqlxtxgbNcKoEGzgcP9gYBBqKNORexMecigLbJ8q9OSMUdN3SwOjyR+ztcObkfokLlZlfs7bEXmFhLfXL0cc4wDCy0Ohb/2X2aV5tlmvdACAlEPlUwLZRCoUBERITRh6eJuSVviaP9xx8d6tqCUnWEAqFyKb/7qpT4YGo/vHBHCj6Y2g/RofyLOpUy419prhjXXpclVXAQ5ozsgUMvj8KoFDWlflkQqQxCZLDMZUXkLOB0S9VbkmPx0h09EREcWN2VhKrQtODJjMNYui1fX1ysNiku5v4O77ghHoOTYjAhrSMGJ8Xw3hE17Hpk+ghbqU+OPs4Zhs0rDhZWYPrNCbweR/MeCAlcbTsPYhdMe/q74sevdx68kau25IG2N0CdjkVksEzQcDJViAx9u0Rh9dQoLNqcj5Iaca6m3devo1GaxM78EptX8x9JT8DIFDX6d43CobOV2JR7EXHhSuz9vxHovXgHrz+qxhYdnr2tO1p1AAsWGb+dtXl/hVSC23urcW+/Tri5eyykEgbZBeWUqmRBVaP49QhiG9ajHXqqI1AtwnA+oK0bUVOrFvXNOlGO520+3FuIPp2icMcNxqk7QnYYrNHqWKiC5ZiZnoDvci8aparZS33iAhrTtEG+KVNCWGpewV3ssNZkwRW7H4QQ4it8Knioq6vD6dOn9Z8XFhYiNzcX0dHR6NKliwdXxp+rtuQtvQHyVV3foi/Uzpo3AgcLK1BS3YCyuiYcOluJPX+VoqlVeDh8S492mJDWUf+5tRMCwy5T2/OKcetbe4y+Hh0qExSN/3v3ad61Ek1aHb7PvYTvcy/pU5aaWv3zRDEQLNl6HBFK8V7W7r+xEz682o3HX738/VGoQmQoq2vrwHR7ajwOna3ED39ecjiIsPR6FB0qx11pHTAqRc3rmKa1CGIENJbWaemCxuWaJqsXOVy1+0EI8S2BPCTOp4KHP/74A8OHD9d/ztUzTJs2DWvXrvXQqoThtuRt5RgLfVNytjWraaG2Ya1F57xi7DjGr0ORKUu7J7ZOCKx9H6bFtfY4WmRdVd+Cx9fl4M4bxLuqqVJKUdOkdXgrcv7YXrhU1YA1WUWirYnDXP0fX9km5atGpB2SZ27rjg1/CJ8N4gkhMgl0LNDoQOBbUd+CKZ/8pv/ctEA6XqXE/LEpvOserP0dV2qa8VlWkaAAwFqRsxj4NK9QhcigDJIa7ca6YveDEEJ8iU8FD8OGDQPrB2c6Ym7Ji9Wa1VKhtjPHjrexe2LphMCbWsz+8Kf16bVA20lFVIgMDwzojENnK3GwqNLqfYf2aIctfwqfRsvtQD00OAG3vrVH8OP5YPX/Qyxp1up8Jn2tvqUtaAhTSFHnZLcq0+C7uLoRT2bkGN1mbSaNq7vJiYlP84qq+hb875F+kEgYl+1+EEJ8Ewvx30J95S3Zp4IHf2J4Bb6kphEVdU2IDpVDFSyHVsfyfnMSuzVrZn6J/sTe0WMzsL17otWxZjsPvtZiduKNnfB97iW7a3Y0cADafoaHzlb61M/Fn+ziORPEmwRJJWCudqty5ZtQcXUjHl+Xo69T4k6oXd1Nzh5Lry3WXof4NqUo0zQZpV8SQkigo+DBg6QSBtUNzXhz+wmHJ02XVDeIuqY1WUUYkBiNManxjrV9ZYD/PJBmde2WixOVSOuicnjN7jYoMdrpFrK2RIbIsPSe3hiTGo9NuRdd9CzEnpOlGk8vQbCq+hbMGdkD6w+eE63xgS1rsoqwJqtI/5rFt17ox7y23T0xr+Jbem2x9VoqpHmFkKCEEBIYqOaBeIQYk6azTos/9ZhLK3Ck4xPLAgu2HENQkMRs7Va/35pGbM/jd6ITHSpHhaZZ8LrElF1Y4dLjG7YrpVaQRKiahma4e/Obe816dmQPXvf/PPssPs8+K+hCiS2OvJbybV5RqWnGkGW7Hb7AY4oCEUL8RADnLfn1nAdvptWxWLT5mNXcYABYtPkY9p28grd3nMDbO/5C1ukyaA0SkrU6FjuPl4q+Ni6tgHtzFfq2VqFp6960Pe9a7YCzNQ0M2t6ws54fgflje2FYj1iEKYznRvjL+y+XF67VsQ7/G5DAtSarCCU1TW59Tu7v+svfz0EdoeD9OC796b3MU0avbULYq7MArv09GeIzT2J8n3g8lZFjlorFBSWGr3F8bM8rxpBluzH54wN45stcTP74AIYs2y34OIQQ4kmiBQ9HjhyBVMpvCBgBVu4+bfMNngVQUtOEhz49iJV7CrByz2lM+eQ39H91p/6N5mBhhWj97E2V1jbafHPlw/AN25maBsM38hHv/IwlW4/j55NlZoWhEUqZw2v1JoZ54dy/gY9cjCABjPu9HZAQJfixyzNPIv2NXQ6dRAupszBla0Deqgf7YvORYsFBiTXc7ohYgQghxMNEHxDHAD6StiTqzoM/dEJyh+15xVieedKhx3LtRLfnFfOuSQiRS8FA2Ek1ly5j7c3VHtM3bEcnZgNtqUqPDk3ER3sLbZ4kcIGUKsQ/pgtzP7NRKWr9pGxCvJ0jTQKAtosljpxE831tsVYfNiY1Hr8+PwLrZw3Ce5PSsH7WIPz6/AhEhSocDkpMObo7Qggh9qxatQoJCQlQKpW46aabcPDgQZv3r6qqwlNPPYX4+HgoFAr06NED27ZtE/ScvGse7rnnHptfr66uBsP4RsTkSdybiLMWb8nH2xP78LrvHalqjOgZhyVbj9u9+m9pSJ1hZ6id+SX4VMDMgdLaRmh1LMpqHU+jePH2nnh750m7V9+5VpDKIAm+mDkQ/1h/WNCkbW/DBXAHzpSjqt53vw/iWxgPz/4Q2sqVb13Qkq3Hca6iAQmxIWa1BpbaR/MNSvjcz9NdqAgh4mNZ8V8rhR7vq6++wty5c7F69WrcdNNNWLFiBUaPHo2//voLcXFxZvdvbm7GqFGjEBcXh40bN6Jjx444e/YsIiMjBT0v7+Bhy5YtGDVqFNq3b2/x61qtc73FA4VYLUmLqxsBFjYL/jgbcy4iq6BcP+gpM7/E5tAxS21WuTfXwUkxGJgYjRe/y+NVuFxUpjErNhSqqqGF9+O5dK/fCiswIz0ByzNPmQ3j8wUM2oZqbc8rxrxvjnp6OSSAGL55RYfKcG+/jvjhzxK3tAy2dRJtrdDYXuEzp0LTbLTja6/oWUg3JnvEDEQIIYTz7rvvYtasWZgxYwYAYPXq1di6dSs+/fRTzJs3z+z+n376KSoqKrB//37IZG0ZDQkJCYKfl3fw0KtXL9x777145JFHLH49NzcXP/zwg+AFBBox3xzKNE1Wp1WbKqluxFMZbV1H5o+7HkFSBh/vKzQaCCVhgFm3JNrtIDImNR4jerbHoKWZNqc/R4XIsDzzlLBvyoQ6QoHoMP4FmJyVe04DgD7dx9eu3LOA2WAuQtytUtOCT/YVYdWDfREVqtDvPJq+3ogdoJu+Ttprw8q9Dgphr6sd325M1oZhGhIzECGEeAdXtmqtqakxul2hUEChMD4Xam5uxqFDh/DCCy/ob5NIJBg5ciSys7MtHn/z5s0YPHgwnnrqKWzatAnt2rXDgw8+iOeff15Q3TLvmof+/fsjJ8f6i7NCoUCXLl14P3GgEvPNIS5ciTGp8Xh0aCLsZYwZ5tVu+/MSPtpbaDZJVscCH+4txDY7E5YBQB4kwcT+nWzeh2/Pd1sWjb8e6gjHf2bV9S2orm9BmIK6EhMiFPcSsWTrcQxMjMaCcddjtZUC4zk827TyUVR2bcYGn0JjrjbLtAObLVyXxRe/O4pmC69VfLox2RqGache1zSumxyfQIQQ4v86d+4MlUql/1i6dKnZfcrKyqDVas0ygtq3b4+SEsu1Z2fOnMHGjRuh1Wqxbds2zJ8/H++88w5effVVQevjfUa1evVqm6lJvXr1QmFhoaAnD0T9u0YhOlRm84o9HxLmWloL34FlXErAS9/n2bz/7PU5WIm+uOOGDlbvo9Wx2HzEdpBR3+x4KluIXIp37++DManx0OpYRIbIHNo94L7PuqZWh9dCiLMMTxp9LYXONJXIsAaqtLYRsWEKgG3bLYgOlaNS02z1e5QwMLtoYcnyzFO4Th2OUSlqm4XGXFvjUSnqq3USRwEIe92p0LRg0NJdeP3uVLMdCC4oMRtsKXDOAxeIWNolFhqIEEK8hCu6I1093vnz5xEREaG/2XTXwVE6nQ5xcXH46KOPIJVK0b9/f1y8eBFvvfUWFi5cyPs4vIMHsRYeyLitd2cDB6DtDfipjByoQmSCT0Yq7ZyE61jgyYzDWC1hrL45ilW7YUoZJMFjtybh6duS9W+kO/NLfC7tiBBD3Mnm4XOV+HCvb15kMUwl4mqgtucV419fH+HViAEAVk7ui1OldXbTGbmgIFwpE9TxyNHW1RWaZqspTKbBkqOD3cQKRAgh3sGVBdMRERFGwYMlsbGxkEqluHz5stHtly9fhlqttviY+Ph4yGQyoxSlXr16oaSkBM3NzZDL5bzWSbkcbmJtAqotcimDZq31R7BwbS4/d0UPgNkbp9iFfZHBMsxIT8DsEclGb8pidadyFVVwEKobru1qRCilqGmk5gHkmjkjkzF7RDIAIFwhw++FFcg5X+3hVQlnmnIp5DXN/ASZsdmumgsKsgvKea2ttLYROifbnLJoG8xpqdMTFyxxRds//HnJoSBCrECEEELkcjn69++PXbt24a677gLQtrOwa9cuzJ492+Jj0tPTkZGRAZ1OB4mkrXLh5MmTiI+P5x04ABQ8uIWj05VtBQ7uUFzdiOc3HsGvp8tRUmNcqDhpQGenjx8dKsP8O9tqGqy9gbpqh0MMIXKpWXtiqUQCoWkTxL99+ft5JMeF48Xvj5oF+1IJg76dVfirpA61Xpxax+XjcyfPJTWNWPLDMV6vadGhcswfa3xlPSE2hNfzFlyp5XW/uHAl8i85H5CV1DRh5e7TeGZkstnX7BVt82WpLSwhxAdxhVNiH1OAuXPnYtq0abjxxhsxcOBArFixAhqNRt996eGHH0bHjh31NRNPPPEEVq5ciWeeeQb/+Mc/cOrUKbz++ut4+umnBT0vBQ9u4M0nwPZszLlodltJdSOWZ55CZIgM1fUtDv/tvDqhN+64wfabrje3Lqxv1prVddhLCSOBp7i60WrnLK2OxR9nq9y7IAcsHJeCnfklZifPfFRqmts6vUmupQTxbRzxY95lm68zhh2PDC9wOGN55klcpw4zCgis7bJY69hkra0sIYSI6YEHHsCVK1ewYMEClJSUIC0tDdu3b9cXUZ87d06/wwC0FWLv2LEDc+bMwQ033ICOHTvimWeewfPPPy/oeSl4cANvOAEOU0hR1yTOFXGuUJHjaJvGqFD7W2TUupAYkgdJLHbGIa4hYdrqFAAITrvkmBY2G85m4FMrwRgcw1ahsTNd2UwZrtXedGjT702sHQpCiHdzZatWIWbPnm01Tennn382u23w4ME4cOCA4OcxxLtVq6nTp09jx44daGhoAACwnhxJ6uW84QT44cEJoh6Pq7d4dmQPs7aN3GwFe3bmW24lZshei0N7IoP5rYV4Ny47jAsc6Bque6yc3A+jU+MdSrs0ZFrYbNgG1d7jKutbMGdkssX2sIZX/LnXCjEYrlXIdGg+bWUJIcTXCd55KC8vxwMPPIDdu3eDYRicOnUK3bp1wyOPPIKoqCi88847rlinT+M7AdWV0rvH4rvDF0VfQ4tWh1/+bzgOna3Ub9HrdCymrPnN7mM35V7CS2Nttye01eLQGqVMgpnpiUjvHgsAmPKJ/bUQ72Z6bYIuVbhWTKgcSyak4o4b4pFdUC5a2qXhLuyY1Hg8kp5gc9o9JyE2FL8+P8JmKpDhawXg/O9IaW0jtDoWWaev8Lr/r6eu4H+/neO9Q0EI8QMB+mYkeOdhzpw5CAoKwrlz5xAScq3o7YEHHsD27dtFXZy/4HuVzRW44UODusVYHXjkjJV7TuPWt/aguqEZE9I6YnBSDAYlxSCUx7Cmck2z/uqeLVyLQ9Mrj9Y0tujw/s8F+NfXR1Bd3+zUzgUhgahc04wlW/OxPa9Y1LTLWJNp8SNTLLcTNBUXrtQXGnOvM5ZOwK29VsSEyjGiZztBay0q02DIst1YuaeA1/1X/VyAKhutYk13XwghxFcJDh5++uknLFu2DJ06GU8XTk5OxtmzZ0VbmL/h3tSsbavHq5SIDJHZPMkNkTmWZcblBHNraC9ibjBgeUuebxYb3xOTManx+PX5EZg/tpegdT2VcRjj+1CeMSFCFVc34vF1OThzpU60Y/5zQ67R64QrJi9zrxXrZw3Ce5PSsH7WIGS/cBuOF/Pr3AQAoXIplmeeckmjC2+ogSOEOI+reRD7wxcITlvSaDRGOw6ciooKGiRnh2GP75KaRlTUNSE6VA61KhgDE6OxM7/E5gTSBwZ0wWf7iwQ9p8qk/mBMajzCFTJeaUV8GW7Jj+jZHl9kF/GeLh0XruTdmUQqYRAbzv93jFvX5iPFeOa2ZKzYZXswFSHE3H92n0ZksAzVDY53VuNcrmky6k7kqsnLpu1QhaZeaV1Yw+cNNXCEEBF4QatWTxEcPNxyyy34/PPPsWTJEgAAwzDQ6XR48803MXz4cNEX6C9MT5DH9+lg9oZobwKpKlguOHiorm8xayVYpmly+vsxxW3JD1qayXuCdmSIDJWaJgxZttvo+7U2MA4Q/sbLrauoXCPocXyEyiVgGAnqvLg/PyHO0rGwmY4jhOmFhkNnK9HUqsOzI3tg/cFzRu1WxZy8nMmjOYOhxhbXdPSKDJZBx7LQ6liqeyCE+CzBwcObb76J2267DX/88Qeam5vx3HPP4dixY6ioqEBWVpYr1ujzhLTuszWBVKtjebU3NGSpUM+VV774Bg4AkN4tBk9mHDa7vaqhBcszT+Gz/UV4457eRj8jR4vPv8+9JODe9illEhxeMBpb/7yEORuOiHpsQryRIkiCJhHa5F670LALFZpm/e3qCAXmjExGQmyoqLMRtDoW3+Waz6vxhKqGFkz55DdEh8pxV1oHjEpR0wwIQnwW10xa7GN6P8FJ9KmpqTh58iSGDBmCCRMmQKPR4J577sHhw4eRlJTkijX6NEda91krDOS2+IX+upoW6jnb/lQs2/JsXw2surprYvgz8mTxuaEVD6RBHiSBWhXs6aUQ4hZiBA6GDAMHoC2laUXmKSiCJFYLorU6FtkF5diUexHZBeXQ6uxfQjhYWCHoooY7VGia8WlWESZ/fABDlu2mFq6EEJ8iKHhoaWnBbbfdhtLSUrz00kvYsGEDtm3bhldffRXx8VSUasrecCGgbUeAzxsgR2jnIUNcoZ63nIDz+a5ZmP+MxqTG49GhifDExbp4lRKrLfSW93QgRoijZPYbo7mFvdfE7XnFGLJsNyZ/fADPfJnL+8TbkwXKfF4XimkGBCG+iXXRhw8QFDzIZDL8+eefrlqL3xEyXEiIManx+OX/hmP+2F54eHBXPDSoC6/HGaYr6YOQCP4FyJHBnhlIXlzdiLVZhfqrjdv+vISP9hZCQMzltJT4CKyfNQi/Pj/CKI1KKmEwf2wvX/l7J8TII0MS0CLO4HkjSgc7w1l7TRS6g2u4Q1FWK36NF19CXheEXkgihBBPEXw2OHXqVKxZswZvvPGGK9bjV/he8bJ1P0udiHbml5jVUEgYWD2ZZtBWfGja7pCrr1i5+zSWZ560v1DG8nW0mFA5yk1SEMS2ZOtx/X9LGPcH5/PvTDHq3sLZnldstDa+VMogVDdSoTXxHFVwENQRrkm7UwZJnCo6NnxNtLeDa1rTZanGzNbrozfggqblO/9Cevd2VAdBiC+gbkv8tba24tNPP0VmZib69++P0NBQo6+/++67oi3O1/EtTLZ2P0tvgpEhMlTVm+fv2gocAOvtDqUSBs+MTMZ16jDM+/aoxWOHyqXQNGstfg0A7k7rgK15JW6boO3ukwAGQKVJcKTVsfyDLgMxoXK8dncqRqWoceBMOZ76X45onWwIEaK6oRW/F7lmYFlVQyvmjEzGR/vOQNMkfGuDe03U6liszSrkvYNb3dCMJ9blmL0OeXPgYGjlngKs3FNgtaEGIYR4A8HBQ15eHvr16wcAOHnS+MSJsXJlOlDZ6wxkbUcAuLZNb/o4ayfwHNMrbFy7w1EpamQXlNucpWDt2Bo7Mxs+ySrCrFsS8cm+QrNe7f6ABfBkRg7eRz/ccUM8tucVY9HmYyipEZYOER0qQ/YLt0Ee1JbSkd49Fm/c2xuPr8txwaoJsS/YwfQiPrrEhCJIIgHAP3gwfE20dPHElpLqBry54y+brz/evgPB4dKxDFtsE0K8DMu0fYh9TB8gOHjYs2ePK9bhlxwdgGRrm94eHQvcldYBDIAOkcG4OSkW1Q0tZrMUDK9scc/njG9zLmLVg32xZOtxl0xl9Qaz1+fgkfMJ+GRfkUP/Nq9OSNUHDoYig4NQ1eBYCtOzt3VHbWMrvj18EZV2AkviGr4cMGcev+yy9W84eB7VAnbVDF8TuYGZQtZVoWm2+9qjY4GHBnXBFwfOCTiy+1lKxyKEeBeWbfsQ+5i+wDMVsAHE3uA3S1eV7BVa22M402DVzwUW72N4ZUsVLHf6hL9c04yoUAV+fX6EvkbjzBUNPs8uMjqpjVcpMb5PPD7aWwjAt066dCzw8b4ihx+/ZOtxSCSM/t/c2u6SEJ8fOIsJaR2d3vVTypzLUQ9kLIAwhRS3JMdi6k0JqG5owYvfW04B9DaaZtf9m2cXlgu6v+Eu6ZBlu3n/XXC7FdFh/Jo/9OsajczjpW5Ls3SUYTqWpXorZ1iqpaMAhRDCl+DgYfjw4TZPVHbv3u3UgvyRrcFvlgidhuoIwytbz42+TpRjltY26mdUcJ6+Ldni9923S5R5QBWhwOSBXZAQG4o9J0pFH+zmaYYB26gUtcO7S4YqNC34LKvIqWNQ4OC8uiYtfsy7jOwzFXjjnt449PIoPLcxF9/k+NfvsCvcnqrGw4MT9K8N2QXlvC9mcK+g88f2woXKBl6PiQ2VY+G4FJ9JFxS71ayQoaWEEBuoYJq/tLQ0o89bWlqQm5uLvLw8TJs2Tax1+R3Tk2prtucVY42TJ4N8cVe2TIc1OcpS4be179teQBUbqvC74MEwYAtXyLwmvWvKwC5u+53zd1X1LXh8XQ7ef7Afdh2/4unleD0GwHuT+hql8wk5WVZf3ckUki55oqQGnaNDrDafEIOYqWB8G2/Y2k3gvrYzvwSfWvhbpxoLQogQgoOH5cuXW7x90aJFqKurc3pBgUyM2gNHRIcpbBZ28xGmkGJgYrSg7XBbAdWgpBhEBstE7UTkDbnpXMCWfabMwytp89jQRITIKXtRbPM35VEXLR5YAF9kF2F6eqL+dYLvyfJDg7ogSCrBh1dTIPn64c9iHLlQLXSpgkSFyo0uyjhSqG2roYYpW7sJAOwWnlONBSEOoIJp502dOhUDBw7E22+/LdYhA46ztQ6OUkcorRZ281XXpMUzXx7GH0WVKKlxfjt8Z34Jv/GsAng6cDC09ah3TJPdlHsJDXa6aTlKJmHQ4gutbVzA1XNP/MmSrcfxya+F+tcJe13qgLaRM44WPbs6cADa0qjUqmD9RZRKTROeyjgMgN/rkKWGGtYuzFirnSqpbhSUmuXKGgtCiH8RLXjIzs6GUsnvihGxTOzcVj4ig2XQsSxGpagtFnYL8cOf5ifE1rbDbe1QbPuzGE9muCYf2TQ4Ent3g6/Csnq3P6clQtvNChGogQMRrvjqie77D/bFHTd0sHsxw9s7kpTVNWN8WkejK/gfSBiLuwPj+8Rj85Fimw01rO0szB+bgiVbrQ/Qc4Qn3ocI8UUM2/Yh9jF9geDg4Z577jH6nGVZFBcX448//sD8+fNFW1gg4rtdL6aqhhZM+eQ3/Q4B1y3JWm6sUHwnwHLPr9OxmL3+sNPPa2s9ADAzPQGjUtTIu1iF17adcNnzEUL4m73+MFaCwR03WO5S5yte23Ycq34+jTfu6a0PAEzrvGJDFQADlNY0IjZMiar6ZjAMMLhbLAYlxegDD1s7C664yBIbprA7E4gQEtgYlhV2DWf69OlG3ZYkEgnatWuHESNG4G9/+5voCxRTTU0NVCoVqqurERER4enlmNHqWAxZttsjLQS5f1HDHQKhQ5rsWT9rkNUJsO6uR4hXKfHr8yOwOfci5mw44sZnJoTYs/rq65BWx/r8JPbVFoqQbb22ms7gMZ3R4yoMgMgQGRRBEqMdSerERDzBm8/XuLV1XvEKJMHiXvTVNTTi/LMLvPL7NiR452Ht2rUuWAYBbA+Vc0Z0qAyvTkiFKliOpzIsvwlb2iEwvFL2eXYRfsxzroVsSU0j3tx+QtQtdkdxub3nKrwjfYgQcs2L3x3FiJ7tIQ+SQMIwXhk48E15NHxN1epYrNx9CsszT1m9f7HIM3j44N5vLA2apE5MhFgRwAXT5uNu7ejWrRvKy82H/1RVVaFbt26iLCqQcUPl1Crxotn5d16PO27oAInE9puwYcEch+uItPLBflBH8BvCZE1FXZNXpSBcrKzH+oPePWmWkEBUoWlB/1d3YsuRS8g67V0tb9URCjw2NBHNWn6NBoqrG7E2qxCvbDmGAa9l2gwcOCzagg7D5hOupFYpERkis7oWFsC8b44i63QZtFTLREjAE7zzUFRUBK2FF82mpiZcvHhRlEUFEkuFw6a5sacu12HlntMOP4c6QgmtjkXWaX7tQS0VzEklDBaNv96hicj6CbChcoGPdK3tx4pdWjBMbFMESRAsk6CqodXTSyFeqLaxFf9wYf2TI2JC5Xj5jl6Y/WWuoMct2Xpc8HMVVzeioo7/65Mzu9Uz0xPs1n6Z1sfRLgQJeDQkzr7Nmzfr/3vHjh1QqVT6z7VaLXbt2oWEhARRF+fv7E365NrlZReUOxQ8cCftlZpmQXmzRWUai7dzuyLzvvlT0Akfi7aWg6FeNk/gl5PeMWshUDW16tDUSpOtie8o1zRjwZZjbnu+yGAZ7xk8DGPchcr0c1vO85zODVxrAXt7ansktQvHgK5ROFlah/OV9egaHYKHBicYDf0jhPgf3mdzd911FwCAYRizSdIymQwJCQl45513RF2cP7PVQcM0v5RP33NTXNbc+D7xeCpD2G7B8sxTuE4dbvHK0qgUNRZtzgcEBA8z0xMAAP9Y75r2q45q0fpIiE8I8RoVGvfVX1TUt2DSgC5YnnnS7n25bKJH0hOgVgXjtW38dzu6Rofwvi/3qvlj3mUAl82+/tq245h1SyJeuCOF9zEJ8UkBvPPA+/KATqeDTqdDly5dUFpaqv9cp9OhqakJf/31F+68805XrtVvcJOkbRUOL96Sr88t5QqpAfO5adznpvmqapUSqx7si81Hih1KMzJ8fkMHCysE5+HWNLTg8XU5lJ5CbGIAdIqkWTGEcFbuOcUrcOAwaBtAmXexivdj4lVKPDQ4wWrNg1A6FvhwbyGWbssX5XiEEO8jOI+ksLDQFesIKPYmSZtO+tTqWKiC5ZiRnoDvcy+hwmB6LTdMyLBGgqudOHCm3KECZWuTRoXUTRjamEO1MMQ+FsCFKu8pqCfE06oFXnBh0Tb4cdMR/hPsF45Lwe4Tl1FlodOSMz7eV4h//q0npTAR/xXAOw8OJaFrNBr88ssvOHfuHJqbm42+9vTTT4uyMH/Gd4JnaW2jxbqIqBAZBnWLQVK7UKOBQoYn+tvzijHvm6NOrfPLg+fQv2sU5EES0Wc+EEII8awx16sRrpThnxtyRT+2jgWe23gEDwzogoGJ0QBgdoGLhs8R4psEBw+HDx/GHXfcgfr6emg0GkRHR6OsrAwhISGIi4uj4IEHvpOki8rqsSLzpFkgWlnfop+5sHJPgb7Imtt9yMwvwRoRpkNvOnIJm49cwsiUOGTml/pKQEwIIR7HnRZ78+vm9mMl2H7Mufk9tnyfewnf517Sp0QZ7m5Q1ybi8wJ4zoPg4GHOnDkYN24cVq9eDZVKhQMHDkAmk2Hq1Kl45plnXLFGv8OnAJoB8NHeAl5vPFz3izBFEOqaxK0rYAHszC8V9ZiEEOLvQuRSaJq1og789FWWUqJo+BwhvktwMmJubi7++c9/QiKRQCqVoqmpCZ07d8abb76JF1980RVr9DtSCYPxfeJtvqGwADTN/IYQcccRO3AghBDiGO71WyVSIbK/4dLFF2/JR3OrDtkF5diUexHZBeU0iI74BIZ1zYcvELzzIJPJIJG0xRxxcXE4d+4cevXqBZVKhfPnz4u+QH+0Pa8YH+2lwnNCCAkEL93RE+crG9A1OgTtw5WY/aXt4XeRwTJUNbivJawnFVc3YsCrP6G68drFMnWEAovGX2+xEQjVSRCvQQXT/PXt2xe///47kpOTceutt2LBggUoKyvDF198gdTUVFes0SdZmhwtlTA227QSc9GhMkwe0AWrfi7w9FIIIUSwqvoWo+nN8SolHhuaiC8OnEO9ye4ywwCP3pKIELlMUItWX2cYOABtHaMeX5eDyBCZUcpTdKgcr05IxR03UJoTIZ4kOHh4/fXXUVtbCwB47bXX8PDDD+OJJ55AcnIyPv30U9EX6ItsTY5WBcupY5EAFZoWHDhDk6AJIf6huLoRH1rZeWZZ4KO9hZhxdbBmoDOtlajQNOPJjByMParGvyf3g1bH4ovsIpytoOnWhLgTw7J8B9j7vpqaGqhUKlRXVyMiIsIlz2FtcjTQVgQ9Mz1BlE5IhBBC/FO4QoraJn41b8RYiEyChHahuCUpFkN7xOlbmQPWMwKI93HH+ZqjuLV1WfYqJMHiDjbVNTTi3PMve+X3bcihOQ+tra34+eefUVBQgAcffBDh4eG4dOkSIiIiEBYWJvYafYa9lCQWwHe5NDCNEEKIdRQ4OK6+RYf8S7XIv1SLD/e17fAogxgEB0lQ2Wj+c01uFwKlPAgpHSIAFsgvrkGEUoZHh3TDkOvaUXBBrGIgfoGzr/y2CQ4ezp49izFjxuDcuXNoamrCqFGjEB4ejmXLlqGpqQmrV692xTp9gr3J0UBbGk50qNxoSjQhhBBCXKOxlUVjq+WA7NSVegDA0Ys1RrdnFZQDAKQMEC6XQAcWgAQMAwRJGMgkDMo1LWhh29pWKmUMlEEShAfL0C5UjpNXNGjR6qAIkiKtswodI0MQrJDi+KUaNLXo0DEqBCkdIhAXroBaFYz+XaNw6Gwl7YoQnyA4eHjmmWdw44034siRI4iJuTbR+O6778asWbNEXZwlq1atwltvvYWSkhL06dMH//nPfzBw4ECXPy8fJdUNvO6X2iECe09RHj8hhBDizbQsUNWk4z6zeB8dgPoWFvUtWlQ0aHG24tpFxIaWVvx8shxAudFj/jhXhU1HLtl8brkU6BYbinZhChw+X4XGFh2C5RJ0VCnRomVR3diKFi2LFq0WErRlN7TqWDBgIJMyqG/RQcu2Xc2WSdu+F60OkEkAKYBmXdva7ZEyQIRCirtu7IiRPeMxqFsMBTYADYkTYt++fdi/fz/kcrnR7QkJCbh40bUpOV999RXmzp2L1atX46abbsKKFSswevRo/PXXX4iLi3Ppc/PBdzeBAgdCCCGE2NKsBU5c1uDEZY3+ttomHU6U1tt5JItGLWvwWduxOC06QEgjYC0LVDZq8dmv5/DZr+cQGSLDG/f0puF+AUxwWwKdTget1jz6vnDhAsLDw0VZlDXvvvsuZs2ahRkzZiAlJQWrV69GSEiI13R5ig5TeHoJhBBCCCEuU1XfgsfX5WB7XrGnl+JZrIs+fIDg4OFvf/sbVqxYof+cYRjU1dVh4cKFuOOOO8Rcm5Hm5mYcOnQII0eO1N8mkUgwcuRIZGdnW3xMU1MTampqjD5cSR0hbtU9IYQQQog3WrwlP7CngVPwwN8777yDrKwspKSkoLGxEQ8++KA+ZWnZsmWuWCMAoKysDFqtFu3btze6vX379igpKbH4mKVLl0KlUuk/Onfu7LL1AcDAxGhEBstc+hyEEEIIIZ5WXN2Ig4UVnl4G8QDBwUOnTp1w5MgRvPTSS5gzZw769u2LN954A4cPH/aKugNDL7zwAqqrq/Uf58+fd+nzSSUMZqQnuvQ5CCGEEEK8QWlt4A69ZVjXfPgCXgXT/fr1w65duxAVFYVXXnkF//rXvzBlyhRMmTLF1evTi42NhVQqxeXLl41uv3z5MtRqtcXHKBQKKBTurUOYPaI7PttfaDYZkxBCCCHEn8SFU7p2IOK183D8+HFoNG3V/osXL0ZdXZ1LF2WJXC5H//79sWvXLv1tOp0Ou3btwuDBg92+HmukEgZv3NPb08sghBBCCHGZeFXbPIqAFcA1D7x2HtLS0jBjxgwMGTIELMvi7bfftjpJesGCBaIu0NDcuXMxbdo03HjjjRg4cCBWrFgBjUaDGTNmuOw5HTEmNR6rp/bD4i35dofGEUIIIYT4moXjUmjeQ4DiFTysXbsWCxcuxA8//ACGYfDjjz8iKMj8oQzDuDR4eOCBB3DlyhUsWLAAJSUlSEtLw/bt282KqL3BmNR4jEpR42BhBUprG1F4RYP3dp3ylaCSEEIIcatwZRBqG1s9vQxiR1SIDEtpzoNrdgp85CSRYVlW0FIlEglKSkq8rjiaj5qaGqhUKlRXVyMiIsKtz63Vsej/6k6qhSCEEEKIyzFoOxf1xQnTnjxfs4dbW8KS1yBRilvzoWtsRNH8l7zy+zYkeMK0TsfnV42YOlhYQYEDIYQQQuy6r18nvH5Pb+w+cRmLNh9DSU2T/mtRwUGYdnMiEtuFIjZMAbBtXY8qNM2IDlNAHdFWi0ApRa7liu5IftVtiTgvkNuZEUIIIYEuMkRm9yKiaUqQaQp0XDgFBl6DZdo+xD6mD6DgwU2onRkhhBDivYJlEjS0uC67guvEOO/bo2ZBRIhciseGdsPsEclmgYFUwmBwUozL1kWIUBQ8uMnAxGhEh8pRoWn29FKIiVC5FJpmraeXQQghxIM+eXgAfi+qwIpdp0Q9ruluwqgUNQ6cKUd2QTkAFoO7xWJQkuvrCIjIArhgmoIHN5FKGNyV1gGfZhV5einEBAUOhLgHV8BJiDUhcinqPfCaHK9SYlBSDNKTY9EzPtys1XpUiAyVdlKOIkNkeP2uVKiC5cg+UwagbcfAtMBYKmGQ3j0W6d1jXfXtEOJSvIOHgwcPon///pBKpRa/3tTUhE2bNuH+++8XbXH+ZlSKmoIHQkhAmJmegNt6tgcYoKyuCXHhSlRqmvBkxmFPL414MU8EDoDxzAJrdQY780ssphyFyqV4dGgSZo/orj9GejIFBv6OCqZ5GDx4MIqLi/UtWiMiIpCbm4tu3boBAKqqqjB58mQKHmwYmBgNdYQSJTVUPE0I8V9zRvbAMyOTAQDNrTp8kV2EQ2cr0TU6BE+P6I5/7z7t4RUScs3tqWqzmQWW6gy4oOJAQbnNnQVC/B3v4MF0HISl8RACR0YEHKmEwaLxKXh8XY6nl0IIIS7TotViU+5F7My/jG1Hi6EzeGugUyzibaYO6sr7vlIJg/TkWNpZIFTzIBaGobcFe8akxmP11H4Wtz4JwDAAxaD8KIMkaGyluSvE+6zcU2D1a/TnTbxJVIgMg7pRJyNChKCCaQ/Qb31e7bZQcKUWP+Zd9vSyPEImYSAPkuiLlilw4I8CB0IIcc7Se3pTyhFxjAtqHnzl6oqg4CE/Px8lJSUA2lKUTpw4gbq6OgBAWVmZ+KvzY1y3hUHdYjBk2W5PL8djWnQsWqjbkVtEhsgwpHssfi+swOXaa9NK1REKTEjrgI/2FgLwmdcun6GUSdDowt7xhBDh1BEKLBp/vVmtAyG8UdoSP7fddptRXcOdd94JoC1diWVZSltywMHCCqN2cISITRUchPcf7K/vI67VsRanlfbtEkXpdC7Q2KLDvNHX4Y0df3l6KYQQtBX0G3ZGIoQIwzt4KCwsdOU6AlZpLQUOxDESBkaFqNbMTE9EmaYJBwsr9IGCpWmlI3q2B4OjLlgpWfUzdRcixFFt8xN6Y8nWfKcutsWrlFg4LoV2G4g4aOfBvq5d+XcjIPzFhSs9vQTio7jAwdrgrVC5FLIgCZZnXpuWaunNU6tjsXL3KXy07ww0TZRC5gq19HP1qMeGJmLzkWLa5XXQw4O74vbUeFRqmp0+gXfEG1enM49ObZu98NOxEmzMuYDaxlarj+FeF+eMTEZCbKjRLishxDm8g4dz587xul+XLl0cXkwgGpgYjXiVEiXVjb4ScBIv8kh6ArYeLUZJzbUaBpUyCLf0aIetfxaDNaknKaluxBPrcvDsyB5IiA1BUVk9PttfSKlKxG9Fhsjw3Jhe6NMpkgbUOSgmVK7freRO4Hfml7h86KlpXQK3azo4KQYv35miT78sKtNg/cFzRq+DatplIC5GQ+J4SEhIsFjTYFjrwDAMWlutXwkg5qQSBgvHpeCJdTlWryATYk1EsAymnfOVMil+PV1m8XeJu2155klXL80mdYQCfTpHYsexwOwyRtynqr4FB86UY8nW455eis9af/AcZo9IhlTCGJ3AD0yMdlmdlL26BNP0y9kjki3WchFCxMc7eDh82PIVG5Zl8eWXX+Lf//43wsLCRFtYIBmTGo8PpvbD4i3G28HxKiUmDeiCLtHBWLL1OCo1zRRcEABt4UJkiMwoJYlj2EnJWy0afz1UwXIKHgJUZIiM1wlnhEKKGhFSvrILyillyQklNW01U9YmLu8/XYbH/3dIlLTHyBCZPk1JCGu1XIQQ8fEOHvr06WN2W2ZmJubNm4eTJ0/iueeewz//+U9RFxdIuBdha1dOguVS2p0gAK7tM/j67wE1C/AvYYog1DVZ33k2zD3X6VhMWfOb3WN+MPVG/HG2UoSdMl//a/E8a3+vUgmDW3q0wzsT++CJdTkAHPtp35XWARP7d9Z3hSOEeC+HhsTl5OTg+eefx759+/D3v/8d27ZtQ1xcnNhrCzi2rpxY253ga8pNXfD94Yv6YWzEd6mv7kh5OvXIUQyAed/8ieoGSnH0dfPH9kJsuEJ/sWNnfonZa1R0qAyvTkjFHTd00N+m1bE2a70YtP2eD0qKQXpyLK5Thzn82hcTKsfgbrE2p177oniVEvPHpkAVLMNTGTmoanBt3ZK95h7W3qPUEQrUNLai3sp7D/dv/c79aRQ0EN9C3Zb4KSgowIsvvohvvvkG999/P/Lz89GtWzdXrY2YGJMajxE92+OL7CL8VliBn/L5p3zceUMHxIUrLKa5EN8we3h3pHePxcDEaPzw5yVPL8dhLIAqDwYOkcFBaGrVoYEGtzklXqXE9PREoxO+Manx0OmAlzfloULTDACo0LRgydbjkEgYo8JXa7Ve3NEWjkvRH5s77pMZOYLXOSGtAwYlxfhkY4rR17fHjV2jrwZoCoAFyjRNZjvTb9zb2+JVf8OOQ9UNLfg0q8jiz9vWz4Q7uR+YGG13vdZ20Hfml+Dxdeb/dpb+rQnxFVQwzcOTTz6JNWvWYPjw4fjjjz+QlpbmwmURS7bnFTt09S0mVI6BidEYmBiNz/YXUWcdHyRhgKdvS4Y8SAIAiA1TeHhFvufWHu3QLkyOjTkXPb0UvzC+T7zZCd/2vGI8lZFjdjLKdfn6YGo/fQBh9Uq1lXbCS7bmO7TOUSlq0RtTMAzw9yGJ+Cbnoj5IElNUiAxLBeT98/1ZDkyMtnif8X3iLU6Yd+Tk3tIO+pjUeKzm+W9NCPF+vIOH1atXQ6lUorS0FDNnzrR6v5wc4VeGiH3b84rxxDrzN2U+JqR1uHaF6p7eDh+HeI6OBQ6drbz2pkz/gIL9cvKKp5fgVz7cW4i+XaL0J35aHYvFW/KtdvliACzekq8/mQfs13pxDhZWOJSyFK9Son/XKGQXlKOpVYdnRyabtfR0xKrJ/XDHDfFIiY/AnA1HHD4OwwCswQ8sMliGGekJ+s5GQvD5Wdq6T98uUS49uef7b02ITwnQ92LewcPChQtduQ5ig603ZT5Gpaj1/81doVq0OR8lNVSw6ksMCxbLNN7fUYn4v39+fQQjeraHPEhi9wSfBVBc3WjWtYdPlxxHi+vH94nHrW/tMcnBV+LZ25Lx0b4zVvPwASBELkWEUmb0Omk6ZFGtCnZoXdzp8qrJ/RAVKhftZJrPz9Lafdxxck8dkQjxDxQ8+ABHr7oBbW92prmqY1LjEa6Q8ep2QiyTXL1i6M6LDoYFizSZnLiS6RVxazRNWgxauguv352KplZ+NSSOBAKO/L6HyqX4aG+h2d/o5ZpGvLfrFILlUpuPVwRJsPe54fi9qALZBeUAWAzuFotBBie/fId8SphrE+EB703XoZN7QgSggmnH/fLLL9BoNBg8eDCioqLEWBMx4ehVNwbWc1XpyrVzhl/XDrtOuCcNhgHQPkIBHctiU+5FxIW3pWJEh8pQoaH6FSI+PoEDp0LTrJ9azocjgUClpsnsBNwea53luEPY2nUAgMr6Fnzw82l8+ft5/cWblXsKjHYf+NRSzBmZjCeGdcehs5WUrkMI8Qu8g4dly5ahrq4OS5YsAdA2HO7222/HTz/9BACIi4vDrl27cP3117tmpQHMkTfb6FAZ7k7rCFWwHFoda/ZGRVeunePOwIEFUNvUiimfXNspilcp0bdzpNvWYbgWQiz58vdzUEcocLmmyWb7VT5dewy1FWEf9sjvnqXudKbF37aGfBruLtAVfUL8C3Vb4uGrr77C888/r/9848aN2Lt3L/bt24devXrh4YcfxuLFi7FhwwaXLDSQ2dsa565Mv3N/GnYdv4zvcy+hQtOMNVlFWJNVBHWEEpMHdkFCbIj+qhd3TJq66t0UQQwaW1mzya3F1Y1u/7fzkdc04gFcPcOckclYkXmKV/tVPpyt93IFS8XfVAxMCAkkvIOHwsJC3HDDDfrPt23bhvvuuw/p6ekAgJdffhkTJ04Uf4WEV0/0ReOvR21jCz7LKjJvk1jTaDRQjLsixh3Tm96YibHGVtv/OkJTOQhxpYTYUF4tQ7U6lteJtjP1Xq5kqfib6gUICTBU82Bfa2srFIprveWzs7Px7LPP6j/v0KEDysrKRF0cucZeH+9RKWoMWbab1++d4bY7dV5yP6VMgkaRBpRR4EC8SVy4EoOTYmxehbc0r8Y0xYfjSL0Xd4ElMkSG6voWwe/FQtLzHK1HI4T4Pkpb4iEpKQl79+5Ft27dcO7cOZw8eRJDhw7Vf/3ChQuIiaGrLq5ka2s8u6Cc9xU67nfzxe+OYv6d1+Od+/vgi+wibD/Gf2I1cZxYgQMh3sK0nsHaVXhr82osDZEDHKvN4i6oAHBoKJxapcSkAV2MdmutodoxQkgg4h08PPXUU5g9ezb27duHAwcOYPDgwUhJSdF/fffu3ejbt69LFkmusfam7MgVsApNC+Z8lQsAiA6VO7s0IoA8iEGznZQkQnwB33oGR4bI8an3UquUePu+PijTNJntcljarbVl/themJ6eCKCtANze8wot/iaE+JEATluS8L3jrFmz8O9//xsVFRUYOnQovvnmG6OvX7p0yebkaeJazl4Bq9A0i7QSwgcFDsRfqFVKsx0DS4QMkeNw9V7AtSCFYxi0pCfHYkJaRwxOijGbqPzr8yMwe3gSr+8lNlwBqYTh/bxUEE0I8bRVq1YhISEBSqUSN910Ew4ePMjrcV9++SUYhsFdd90l+Dl5Bw8AMHPmTHz33Xf44IMPoFarjb72/vvv4+677xa8ACIO7godvZURQtzhkfQErJ81CL8+P4LXsDO+u6Om9+PqvdQq4wskfIMWqYRBevd2vJ7b8CKMs89LCPFzrIs+BPjqq68wd+5cLFy4EDk5OejTpw9Gjx6N0tJSm48rKirCv/71L9xyyy3CnvAqp4bEjR07Fp988gni4+lF1NP4DCsihBBnWStutofv7qil+znSCtWwo1NsmMKhGRTUgpUQ4s3effddzJo1CzNmzAAArF69Glu3bsWnn36KefPmWXyMVqvFlClTsHjxYuzbtw9VVVWCn9ep4GHv3r1oaGhw5hBERNY6MhFCiBiiQ2WYP7aXzcDBWhtWvvUL1uoIuGNwxz5YWGH1RN5SR6fIEJm+tkLIDApqwUoIscSV3ZZqamqMblcoFEYdTwGgubkZhw4dwgsvvKC/TSKRYOTIkcjOzrb6HK+88gri4uLwyCOPYN++fQ6t06nggXgf0ytlRWUafJpViOqGVk8vjRDi4yo1LXgq4zA+uDoYzZS9Nqz25tXYqiPg2+LVWken6voWAIAqRIaqq/8NmM+gIIQQT+vcubPR5wsXLsSiRYuMbisrK4NWq0X79u2Nbm/fvj1OnDhh8bi//vor1qxZg9zcXKfW51Tw0LVrV8hkMqcWQMRneKVse16xywKHULkU9c1aSpHyEIYBWPrhEzey1hUJ4N+Glc8QOVPWjl1c3YjH1+Xg/Qf74Y4b4nl1dAqWSbHqkX4WuzMRQghvLuy2dP78eUREROhvNt11cERtbS0eeughfPzxx4iNjXXqWIKDh3PnzqFz585gGAZ5eXn621mWxfnz59GlSxenFkTEo9WxWLT5mOjHjQ6V4dUJqZBIGKqx8CAKHIgnWJquLKQNq9A6AlvH5sxen4OV6IuoUAWvjk4SCYMJaR15fseEEGKBC4OHiIgIo+DBktjYWEilUly+bDyj6/Lly2ZNjQCgoKAARUVFGDdunP42na5t7lRQUBD++usvJCXx60wnOHhITExEcXEx4uLijG6vqKhAYmIitFqt0EMSFzlYWIGSmiZRjhUTKsfLY3tBrQo266NOE6oJCTyGXZGEtGHl2qnyrSOwd2ygbdL6kxmHMTM9gdcxaTI0IcTXyeVy9O/fH7t27dK3W9XpdNi1axdmz55tdv+ePXvi6NGjRre9/PLLqK2txXvvvWeWKmWL4OCBZVkwjPkVorq6OiiVNG3Tm4j5Bvna3ak2coLpEjghgcawK5KjbVjFfsym3Eu87keToQkhznJlwTRfc+fOxbRp03DjjTdi4MCBWLFiBTQajb770sMPP4yOHTti6dKlUCqVSE1NNXp8ZGQkAJjdbg/v4GHu3LkAAIZhMH/+fISEhOi/ptVq8dtvvyEtLU3QkxPXEusN8r5+HdHUqkN2QbnRroO1PGRfFyqXIlwZJNqujT8IU0hR10S7isRyVyRn2rCK+ZhyTTOiQ2Wo1LTQZGhCiN974IEHcOXKFSxYsAAlJSVIS0vD9u3b9UXU586dg0QiaKQbL7yDh8OHDwNo23k4evQo5HK5/mtyuRx9+vTBv/71L9EXSBw3MDEa6giFUyfBEgbYmHMRG3MuArjW3WRUihrzvj3qd4EDAGiatXh2ZA+kxEegtLYR6w+ew8GiSk8vy6NWTe6H2V8eRm0jde3yZ/IgCZpbdTbvw8K8K5KzbVhtaXsdU/JOjbw7rSM+zSri3dHJWmtZQgixyYU1D0LMnj3bYpoSAPz88882H7t27VrhTwgBwcOePXsAADNmzMB7771nt5CDeJ5UwmDR+Ovx+Loch4+hM/lFLrna3WRwtyijdodikDDA0yOSsWLXKbv3VcokkIBFfYtrwpfXth3XB0rPjOyBKZ/85pLn8QVRITI8/+2fFDgEAHuBAwDMGZlslsJoa0glnzastkglDCYP7ILlmSd53X9kihoDEqN5dXSy1P41OlSOu9I6YFSKmgIJQgixQHDNw2effeaKdRAXGZMaj9VT+2HuhiOob3Y+7YQ7Kcg+I/6VeB0LDEhou4Jpr0CyscX+SY6zuEBJpZS6/Lm8WaXIQSLxbQmxoRZvd7QNqyFruwAJsSF2HwsAkcEy/WPsdXSylnZZoWnGp1lF+DSryOFp2oQQ/+cNNQ+eQkPi/Bj3RtzUqsOckT3w2rbjnl6SXdlnyjF/bAqeynBdLUWQBOBxgVX//NWNvpHrH69SYnyfeGw+UizKhHGlTAIGQIMbAjVf0K+zCjnnqz29DIuiQ+Wo0DS75bls1SAIbcNqyNYQOL51DzPSE/TPZaujE5/2r0BbhyjDGRWEEEIoePBblt6IJYx5GpIpdYQCd/SOx6dZRa5doBUr95xGZIgMwVcH0LnC0B7tsPvEFZcc2xNC5FJ8/PCNGNStrQXmc2N66U/eTpbUYtXPBQ4d1x27O77k8PlqzLolEZ/sK/S6Wp+pN3XBmqxCaFxc1M5d2bdFSBtWjr0Bc6se7GezpgJoS6+bPSKZ1/Pxaf/KYQH838YjqG/SIj4ymFKZCCFtvKTmwRPEL8EmHse9EZu+OdoLHOaM7IGsebdhVIr5cBF3qqpvcVngAMCvAgcAqG/W4vPsIhwsrIBWx+pP3iakdcSQ5HaeXp5f+Sbnole+tn+efdblgQNgfGVfLPYGzAHAkq35mD+2F4BrNRSGGABL7+nNe21CW8bWNmox9+sjmPzxAQxZthvb84oFPZ4Q4odYF334AAoe/Ayf7XjT99d4lRKrp/bDMyOTIZUw+s4p/nhtzV8vGO44dtniiQ33b0mcxwJuSw0SqqrB9XUpDAM8May73ftpdSyyC8qxKfcisgvKobVz1YLvgLmoUAU+mNoPapPf53iVUnBakTNtrLlUJgogCCGBitKW/Azfaazzx/ZCbLjCYk6yrc4pvor7Puztvvi6Yn2aR19EhSpQWtuIfl0isfVoiaeXRrxYTKgc5XYCI5YFDp2ttJmSZKtuwdrJvZABcxPSOjpcU2FoYGI0IkNkTnWMW7wlH6NS1JTCREiAYmB5J9TZY/oCCh78DN834thwBSakdbT6dWudUxwVGSLDjJsTkRAbgtgwBbJOX8H7P59x+rh8qVVK3JGqxhoP1XIAcPpkhS8WwFMZh/0i6PNVUcEyVLphN0As4/rEY+3+s3bvZ+v1xV7dgrXdAaED5hypqTC1M7/Eqb9FbjfkYGGF02shhBBfQ8GDn+H7RlxW24Tvci6gQtOM6DAF1BHmV/BMO6cUldVjxdVe60JPTJVBEswe0V1/fAnDuDR4+O/0AZDLpEZXJw8WVng0eGhscV/XJgocXIMBECyToN5GMXmoQoqHb+6K93addulaIoNloqQrMQC2HOGXgmPt9cVe3QID61fqxRwwx2fgG7dWMQitnSCE+JEALpim4MHPcG/E9nYLlmw1b9tqL71gYGI0Vj3YF0u2HjcbqmQvF7ykpsnoKp29EwYxcAFDaW3bFcL+XaNc/py2UPci38cCNgMHANA0aXGiuNal63jmtu4IU8hEab/MAijXNINh2lKTLLF3As+3bsHSlXqxBszxTZkS0mnJHmdqJwghxFdR8OBnpBIG88f2wpMZhwU/1rSnubU34/ljUxAVKr+6G6HBp78W8jq+4VU6V9dVzPriDwTLpahuuDYVOSpEhvv6d8Qn+4pEfjZCjO3Iv+yyY995Qzw2/HFBtBNgjrXAgWPrBF5I3YIlzg6YE5IyJcZugZDdEEKIf6IhccSvRIUqnHr84i350OlgcVBbSXUjnspoezNWBEmwIvMU7xN/06t03AnDvG+Pil4L0Kxl0WwQOABtk5I/3leEUSlxOHqhBiU1lHJAfM8Pf7q3yw/DAKsm97V5Ai+0bsESRwfMCU2ZEmu3gM9uCCGE+CNq1eqHnLmyxqUXvLwpz2bf9cVb8rFo8zHegUO8lat0QmdKKKTOv1nvzC/FS2N7Yc5IfgOlCAlkLAucKq2zeR977Z0ZWH8NMGQ4o2RwUgyvk3MhKVN81mqPI61hCSF+iOY8EH8ixpU1WzUM3JtxSU0T7+ON7xNv8URg5e5TgnYdlHIpFEHO/9ou3HwMs0ckY/XUfjQHgRA7PssqsjmvgUtDBMxbDQqpW3CE0JQpw7VaEyKXGn0erpRixs1dsX7WIPz6/AgKHAghbQIwcAB8KHh47bXXcPPNNyMkJASRkZGeXo5X88Yhbx/tLTQbqqTVsfhwr7COSzUNrWhqdb7wuELTjIOFFRiTGo9fnx/h1bsQ3vTvSAJTVUML1mYV2gwguDRE0yFuahdfqXckZWpMajweHZpo9b4NzVrMGdkD701Kw/pZg5C7YDQWjk/lvRtCCCH+zGdqHpqbmzFx4kQMHjwYa9as8fRyvJozxcgMgKhQGSo04veoN23VuHL3adQ3C2tfyn0vYQopWrSsU4GE4RXLL38/7/BxXI1F25XPAV2jsPuvMk8vhwSoJVuP45NfC20WMDtat+AMR1q9anUsNttpT/vl7+fw6/MjKFgghFgUyAXTPrPzsHjxYsyZMwe9e/f29FJ8grWrgPawAF6dkMorf1kdoeB9Vdw071irY/FZFr8uTZbUNWmd3oHgrkSK2brRVWobtRQ4CJDaMcLTS/AJQk+LS6ob8fi6HLyXeRKbci8i61QZsk6XYVPuRWQXlEOrYx2qW3CGvZQpFsDtqW0BDbdzIrROghBCyDU+s/PgiKamJjQ1XcvLr6mp8eBq3M/SVcBKTZPZnAZDkSEySHj2XQcgeHeDu9p/sLBClAFXjgqVS6HTsdDqWBr05IcKSusQIpcK3tkKNNGhcozvE4+vD11EXVOr3ftzf+fLM09Z/Lo6QolF4+23VuXwGerGh7VWr9zsik+zivBpVpF+7gPfCw/02kAIsSqAh8T5zM6DI5YuXQqVSqX/6Ny5s6eX5HamVwHvuKHD1Rz/HhbvX13fgifW5QCA3fxlR3Y3uKv9nn5T1jRrMWXNbxiybDeKyuo9uhYivoYWHQUONtzWsx2iQ2Uo1zTjs/1neQUOfJTUtO1MmNY3WbI9rxhDlu3G5I8P4JkvczH54wMYsmw3r8dawtUvrZ81CI+kJwAATEs0uLkPRWUaXsekIXCEEGLOo8HDvHnzwDCMzY8TJ044fPwXXngB1dXV+o/z5703r93dvvz9nMXbDVuxjkpR69+MucJB004j3Bv2/x65CZHBMqvPxwBQRyigY1lsyr2Islr+nZpcqaS6ESsyT5p1VyHEH0kYYNYtCdh94opL6po4L3x71GZxNTfUzXQHlDu5txdAaHUssgvKjdKlgLaLJQMTo7Etr8Ti47gV/Xd/EVR2Xq/4tJYlhAQuruZB7A9f4NG0pX/+85+YPn26zft069bN4eMrFAooFM4NTPNHQvJ9ByfFYHBSjM3jSSUM0pNj8ca9vfW7FqapTiyAxlYdpnzym/52CWN+ZdDduCFSOk8vhBA3mD2sO77OuWBzZzxCGYSaRud2IirrW3DgTDnSu8eafU3oUDdT2/MsT77nCrn5vL5V2GgP7erWsoQQ4us8Gjy0a9cO7dq18+QSApLQvuh8cWlMizYfM5oBEREchOqGVrN5Dt5yvs4FNr4gJlSODpFKHL0YWPU7RBw6sHabA9Q0tiI6VIZKTYtT6bfZBZaDB6EXLwxxOxam6yq+Wsj9SHoCguXOva2pDQIRQgixKoBrHnymYPrcuXOoqKjAuXPnoNVqkZubCwDo3r07wsLCPLs4H+NIX3RhjK/W1dq5imltByI6VIZXxqUiJlyBkuoGLNl63ObwukBQrmlGeYD/DHyJXAI0e1Vcyu9K+t1pHfFpVpHgVs/GLD/S0YsXtnYsOGuyiniuzVxksAyrpvTDoG40y4EQQmzxmYLpBQsWoG/fvli4cCHq6urQt29f9O3bF3/88Yenl+Zz7A2RczTfl7sqWFJj/KZvb4dBxwLzx/bCjJsTEK68Fs9WaFrw2o/HUd3QjLv7dcLE/h0FrYcQT/OmwCFepbSbgsgZmaLGB1P7QRVivS7AnsHdzHcdAMcvXri6pXJVQwskDEOBAyGEl0CuefCZ4GHt2rVgWdbsY9iwYZ5ems+x1xcdEJ7vy+eqoC2Xqhqwdn+R2S4FV0C5dFs+Pvz/9u48Lqp6/x/4a0D2fZNBQ0HUFNEAF0Ra1DBNK73tZqZef9wsrcwWtXLpWqk3b1lZmkvdvldN773e2+aNm0u5BW6kRS4pgpoxKIqgKIvM/P7AM80+58yc4cwwr+fjMT1imDnzYWT0s7yX7Y73hSDyJGI/evdmiF9Qz7k7Ff07xYjeOBiSqkZgG8cKCUQG+6G/yUJFSHLW1NQhOkR6snJLVGhTugocEXkQnYtuHsBjFg8kL2tlVg1LsQLWq5qYcnZX8D8HzlhNoNQBWL6DCwfyHk8N7izqcf/54Yyox03MSdJ/ph/um2i1EzPw+8bBntILZqeIYi24t6fR5kN+cTlyFjSXZX12/QGrlZ5sbV60RNlUlmYlIrLPY3IeSH6WmsgZNmmyV9XEkKM7dio0N6qyF8evc6PVePoNETh4ptqtxkStS6e4UDyb28VqMzaB2F/B3FS1xc+zIdNEYUc+0/Fh/nh1ZJrR3w/5xeWYdL0Kmz22kpWFcEtNdZ2kzbkpg1KQ0jYM87762eaiRc3SrEQkBROmyVsJTeRMWatqIoQRGZ5OAI7t2An7iiPT2+EjJxIdW9qIXgn4x6QB+HtBGcrOX8E/959GXaMbBbeTx6u8VC9LYrwwKa6qbcDkteafZ8GzuV0xZXBn/cZBk1bnUC8Wlcr4MLtJq8OMf/9k8zmhAW0wb2QPqCOCbHaYFsItpXa1z+kch+yUGAT5+VgtJQ2wNCsRkVgMWyIz9uqwA8112A1DmOwlYQPmcdxCiNSQVLWzQ25R249VYv/JKozPSca8UWl464GblB4StSIqAPM2Hsb/FZx0+lo6NBcjmLfRej6SCsZNI4XOz/M2Hpb8ehU1xk3eCk+cNyvRbOpy/TW0DW9O5rY3eZfS1d40d0JsqCYRkRjenDDNkwcy40gddlu7gsJ0YMnoTESF+JuFSDVpdVCHBxj1hnBnO45VYsexSkQG+WFCThKmDO6Cx2+9yIRukoXc/3YcO3tZ9Oe5+mqDxRNHsUybvBWUnBf1PGs9ISwxDLfcdEhjsaSstdMEe6GaRERkH08eyIyjddjt7ewN75WA7JQYjExvb7TL6Oujwuh+HeQZfAu6eLURb28+ht6vbUJGhyh88EgmokP8lR4WkZ4KwMciQwI11VedqpgmMFyMiF8KSXtVIdxy9t09sEziaYLwXNO/h4iIJPHiaks8eSAzzjSRc3RnLyk2xKGxuoOLVxoxaXURPngkA3tfzjXaEaXW4fFbk5HRIQpzvzjkcAUiJejQvMgV40Jtg6x9FM5eqkN2p1gs+bbE7mOt9YQQg6cJREQti4sHMmOvqom9yiTWkrBtaQ0lEqd8+gOWjFZheK8E9EuOxrq9p3GloUnpYZGTnh7cGSltQxER5I/tLw7C3wvKJOUDPH5rMr44WO7SBmf2RAb5ofpqo83Pc3RogKyvKUziI4P9bOY9WOoJIZUjf+cQETlDpdNBJXPZRbmv5ypcPJAZMfkLclcmcbQMozvR6oAn1xZhmU8mQvzbKLJwSIgIhK9KhV8vXm3x126NAtv44N2tx/VfJ0QEIjUhTPTzn83tgmdyu+LFYd2xp/QCvvm5HB9/73witFQTcpKxePMvNj/PEUHyhNwZbi74+qiw4N6eNku1mvaEICLyCF5cqpU5D2SREpVJrDWv8jTP//MgJn6yt0VeKzLID2OyEvFo/w64P/MGNDVpuXCQUd014xK85dV12HLknKjnRof4Y8rgLgB+3xmfc08aHr81WfZxWiNUHJoyuLPdz7OYimmCqGA//fVNXw8w3lwYlpbQnJcQbnyyERXshw8eyTD6u0RsU0oiIlIOTx7IqpaKJbbXvMqaEH9f/e6+O00xLte33InDxauNWLP7dIu9Hon32sg0i5+VmcNTcdMNUXjl82JcMOjlEBrgK+vvjulE3t7n2fDE0d5159/bEwDMPrfWmrwNS0uAVgujn7nqSiPmbTwMn+tjk9KUkohIaa4oreoppVpVOp2HBFjJoKamBhEREaiurkZ4eLjSwyFYb0YnRmSwH94Y1RPzNkpfeFDrJaWBmKs8fmsyZg5P1X/dpNWZTdoB6O8rq6zFmsIynL0sLrlZDEcn3rYW86bXtPRzWVowWfucC4/8063JWL691Or32YeByLu483xNGFvGmNfh6y9vvmZTQx1+WPOyW/7chnjyQIqx1YxOjItXGhEV4o+d0wej8MR5TF5TJLqyjBjuMAkl6ZT+M+sQHYSBN8ajSauDr4/K6o76rBGpiArxx8HTF11SmWvWCMd27A1PKDQ1dbhwuR7RIf4WO0CLSVQW03RyxQ7zhYPwfcO+EcyNICK34cU5D1w8kGLsNaMT4+ylOvj6qJDTORYL7uvpVIMrQ3m3JOPLg795TOM6ch+nLlzF6BWFSIgIxD03JVjcUS+vrsOTa22HBzmjuUv1IQxNc2zCbbooEE4YvvrxN8nhi2I+57ZSGyw1pSQiIuVw8UCKEduMzhbDEq9Ckrcj+ROmvvqxHG/efxPGfrTH2SF6pegQP4zu29z47+LVBq/MyyivrlOs67gw4S48Ybtzs5iwI2dzEeT4nMt5HSIiOXhzzgMXD6QYZ3s7JFjoNWEYcvHbxauY++XPuFR3TfK1y6vrsLv0vFPj82YXahvx/nfNzcEig/wUHo33mrymCAvu62lxki9mUWAtV0FTXYcnVheJykWQq4dLa+gFQ0TUGrBUKymmqrYejoYwqwDMGtFcO9+0rKMQcnFf7xvw/27u5MQIGV8tBznzUEiai1cb8cTqIuQXlxvdLywKTE/ohEVBfnG5qFyFV788ZLecqpgSsD4q6582odystaaUYrEMLBHJSueimwfgyQMpIr+4HJPX/uDQ50SIJZ+38bDdUIqk2GCHx5idEoMNRb96dOM6Ih2ME47tLQqEBOWwQD+b4X9CaNTfdpVifE6y1RwIMU0n825prrbkqqaULANLRHLz5rAlnjxQi3OkylK/pChMHpiCNROzMGtEKpZvL7W5aypwJNRB2Ons3ykGc+5Otft4IncnJBwD9hOYhUVBQYm4sL15Gw/j5oVbzU43DNlrOjlzeKrLmlKKOWUhIiLxePJALU5KlSUfVXMllj1lVdhTVoUNRb+i7ppWdFlHIWRCSgK1Ds0hUcJOZ0SwHy5eYegNeTYh4XjTIY3IZ4hf3ovJgbDXpM4VTSnFnrKwDCwRScZSrUTyEFO9RUrVFNOwZHulU03LOgohE5PsdM01NW/jYRz89aLFMptEnqhtWCDyi8tF95TI7hSLDUVnRIXtiZ2I2+sLIaZvhBRiT1lYBpaISDwuHkg2YuOKW6JqiuECZVhaAt4bnYGnPv1B9POVLLNJJLeYEH/07hiF2978VtTjEyIC0T8lxmqugiXuOBEXu1HBMrBE5AhPyVGQG3MeSBZS4orFVF9xlukCJTY0wIWvJi8GT3ivP6S3w7O5XaEOF7fAVgGiKpbNG5mG/SerRIfvCQnK1nIVbJE6EXdlFSSxGxUsA0tEJB5PHshpUuOK7VVfcWbqoEJzkqVpWUdP2lmMDw/AQ30T8cn3J1nm1IqANj6ov6ZVehiyCwvywzO5XTBlcGd9+F9ZZS3e3nzM4mdDB2BQ11hsPVpp9ZpDUttieK8EfH7gjKgxTMxJMjopFHIR/rarFPM2Hrb7fCkTcVdXQRI2KqyFXln7+4KIyC6drvkm9zU9AE8eyGlS4ooFtqqvPJvb1anxWCrr6Ck7i34+KtRf0+KdLce5cLBhcLc4pYfgEh2jzUsL90uOwQePWN/9t7VwAIDNh84iv7hc9GcgN1Vtdp+vjwrjc5JtnhhK7ccg5bTS0dMJYaNCGJ/peAHny8ASEXkbnjyQ0xyNK7ZWXQUA1u09Jbm/go8KWDLavNpLk1YHrU6HyCA/t5+QN2p1qGJlJ7se6dsRB05Xt6oeHCoAY7OTrO7G39UrASt2OJaH8+qXh7DthUFO7cKL6dcgdiIu5bRy0yGNU6cTwkaF6TXU7PNARE7w5j4PXDyQ05yJK7ZWXUVKoqZAqwOiQvyN7ssvLsfcLw5BU+M5YUtk3wsbfsTI9IRWldSe2TESW49U4InVRWa/8+XVdQ4vHISTv/0nq5ye/Ms1ERd7Wrlk6zEs3nzM7P0QUxrWdNxyl4ElIi/HUq1EjnNFXLG1SYo9hqcb+cXlkku0kmeoqJFeDWvKoBR0iQ9DbGgApqwtcrsTnt8u1mHuFz+77N+Os5fqMDK9vdOTfzkm4mJPKz/eVSZbjwa5y8ASEXkrLh7IaXKGMxgynKTsOl6JJd8et/sc4XSjSavDjH//JOn1yHM4MsGOCm4+lfJRqXBv5g1YtdO9Ti2kLJIdUXmpHp8fOIO2YYHY9sIg7D9Z5fDk39mJuNjTSlthhu5YGpaIvIdK23yT+5qegIsHkoWr4oqFSUq/5GhsKPrV7gSrqrYBAFB44nyr7Qrt38YHDa2w0pAr+aggqlJQa2X68ws5AyPT2ysyHjGnlWI7u3tSJTUiotaA1ZZINsPSErBz+mB8mtcf7zycjk/z+mPn9MGyJCT6+qgwa0R3u4+bt/GQvjJLa8WFg3Qytg7wSGad2i1UNGpJYqogTRiQLOpanlJJjYhaGZ2Lbh6AiweSlXBSMDK9PbJTYmRNSIwKsd/o7feSsB7yCSQyEB7gK2uTQGsfP+HT8eqXh2RtyiaFrXLNSx/NxJTBnWUtDUtERPJg2BJ5DCklYbOSY7Dk2xIXj4jcWXhgG9TUXVN6GJLc0UONDUVnHGqWmBARiFkjUhEV4o+zl+pQeaneZqiWO+QM2Eu+dkUuFRGRHFiqlcgDSCkJW3hC3rClzMQIHK24jNqGJv196vAA1F3TttrcCncQGeyH6iuNkifSKgA5nWPxdbHGFcNymZwucchNjRddZSzIzwcP903EHT0SzJKexXaUVjpnwFbyNXs0EBG5Hy4eyGOILQnbu2MUnli9X9K1wwJ9MX9UL7z+9WGjSUpksB8AoOh09e/3BflhQk4ypgzujE2HNBbr8pM83hjVE/8tLsdXP0qLzQ/y94UjoWuq6//RKfQHqg4PRHZKDIakqlFYch6T1xbZrDh0tVGLv31/ElmdzEMEnem/4k7ElIZt0urYw4GIWpZOJ/8/Fkr94yMRFw/kMcSWhN1/skpyJ+kHeyfirvR2uLNXgn4SUlZ5BYs3/2I2Ba2+2ojFm3/BjepQ/c7ojH//xBMImd3VKwF//sqxBn9XGprwdXGF5OfpANzVM0HyYkUOhvH7vj4q+PioRP0e69CcuxAW4IfK2nr95NkV/VeUYut0wlpHbp5MEJEreXPYEhOmye0I1ZI+P3AGBSXnjRI67SVZDktLcCgMIzdVDeD3Scpdvdph3d5TVhtUAb8nmw5JVSOwDT9Kcgpso8JXP5a3eGfw8QM6IikmuEVfU3X9Zhq/L+X3uLy6DmNW7cYz6w5g9IpC3LxwKzYd0titaOTpOQP5xeV4YnWRWYiX0tWkiIhaM548kFsRs4sohDEUlpxHwYlKAM0T/v6dmncmpYRhqADEhwdAq9PpG2j1S47GntILNmPOhWTTwhPn4aNSQVNT78iPS1bUXVNm++WLg+W4cL1XSEtRqYC8W5LNdsmdCScSJs9LH81stTkDTVodXv3ykGwdqImIJHFFaVUPOXng4oHchrCLaPrZMZwICZOdTYc0RhOiJd8e1y8yhqSqbYZrCITQp7prWoxZuVt/f0JEIO5MU4sa8+Q1RbgvU5lGWyS/ll44AM09GJZvL0VGhyijybwQduRI52nDyfPO6YPt5gxYIncegdzXE7vAZwdqIiJ5cfFAbkHKLqK1JGXDRYaQG2GL0MHWNFdBU12Hj3aViRr3xauNWCXysdT6Bfv74opBRS4pTHfJhRyfSXZ+j60xnTxLmUDLnUfgirwEKaWbiYjkxpwHIoWJDhMqOW9zkQH8Pgn7063iOtRauo4K1htsWeKjMo8rJ88g15/b47cm460Hb3LouYYTfUPD0hKw7NFMfdUvR0idPMudR+CqvITWUk2KiMjTcPFAbkHsBKfgRKXoXIQvDtqelNiqjqRDcziJWFqdx4QqOq21LZLE/rlNHpSCZ27vjIhA4wPbqOA2+OCRDMwcnur0ZN/S52BYWgL2vzIEd/VKcOi9lzJ5tncCCEjrSi339QwJYV223pPIID9odTrFumgTUSsmlGqV++YBuHggtyB+giNu+lRQct6hWHFTE3OSEBnk+K5va6QD8PLwbnjn4XRMvb2L0sNxmEriTPzTPafwzpbjqDbpWh3Qpg18DI6phMm+I++Ntc/BpkMabPyxXNICVQXj8q9iSMkjUOJ6hoSwLsD63woXrzZizMrduHnhVlZeIiKSCRcP5BbE7CJGh/hBJ3r6JM/qPTdVjfcfyZTlWq1J9dVGjExvj6lDumLZo5mIDvFXekiSSd3guVBr+aRKU1OHSauL8OcvfzYqLbx+32lJ1/dRAb07Rpndb2v33hYdgOFpzYnSYnfe5c4jcHVegrXSzaZYupWI5CbkPMh98wRcPJBbELOLeKG2Ee9/W2LzOsJua3anWFnGVVVbj/4pMXYXNt7HeKe9cObtiAr27voLH+0qw+gVhchZsBXT//Wj5JMvrQ7Yf7LK7H57u/eWCAchq66PSezOu9x5BC2RlzAsLQE7pw/GmolZVk8JnQ2RIiIyo3PRzQNw8UBuQ+wuojWGja+qrzbKMtn/81eH9Nc0fA1vZ1q5Z+uRCuj47gBoPon4V9GvDj3X0g682F35KYM64485SQDM83Xs7bwLjRk11VcRHeJv9U/SMBTKVjNHgb0TRUdCqywR05HbmRApIiL6nXdvFZLbERrA7Sm9AE31VczbeFh07X2h8RUATF5rXsrVEZqaeuwpvaBf2JiWm/RGKgDVV37/M7HWn4OkK6u8Ynaf2F357E4xeP5fBy1+z1bTNEtlVC0xXJyb9lkBLJdeFU4Un1hdpO+rYul6cjRxY+lWImpJLNVK5EZ8fZo7RqsjgkQtHKYM6oxP8/rrm2E5Eh9uy67j5/D5gTOICPLHS8O7IyzQu9fcOgBPrv0B8778GbuOVWLuF/K+395s8eZfzE4HxO7eQwXJycnWyqhaoo4IxNJHm/N/pJRetXaiKFxPri7XLN1KRNQyvHsWRG5N7A5hl/hQfRiNXFWWDC2xk2fhSh2jg3HygvlutDtYtauMDfJcwFqzOHu795WX60VdX/hciUnEDvH3xficJAxIiUX/Ts2fsZsXbhXVzNHXpAKVI12upRAWWdY6y6vQvGBxNkSKiAhAc3yo3DlUHpKTxZMHcluO7CSKXXBEBvl5RAlWd104kGvYahZnb/de6udFTCJ2bUMT3v+2BM//8yA2HdI4VXpVOFEcmd4e2Skxsi4chOtby02SO0SKiMib8eSB3JbUncQmrQ6Vl8Ttvr7/SCYu1Tdi0uoi+QZMJBPDRXCTVoc9pRdQf02LRQ/cBOiAytp6s917KZ+XJq0Ou46fEz2e8ushSROuJ2RLGX9LspabpLaQj0FE5BRXVEfyjIMHLh7IfUlJtpSS9KmOCET/6zufyx7NxIx//2Sz2zS5XligL26MD8O+kxeVHopbEE4HLP1eC4nJphWvxH5eLCU7i6ED8I994qpIKZlX0BIhUkRE3oxhS+TWxIRriE36tBS6IHQDfnl4d1cMn0RQAVh4by9kdYqx+9jWzrB0qbXfa1tlV+19XgDLyc5iXa6/hpAAX5eXXnWWq0OkiIhUcEGTOKV/KJF48kBuz9ZOopTuu9ZCF3x9VGgbHuCawZNNkUF+eKjvDZi38bDXl8AFmnf3hbh9a7/XlhKThdAm4fOx7YVB2H+yyujzAlhPdpY6SGEMriy9SkTk1nS65pvc1/QAXDyQRxB2Ek2J7b47tn8HzLqrB/zbWD5sY/lGZTyW3RHvbj0u+vEJEYHQ6XSoqKn3lNBQSaKC/fQLZbGJydVXG6yGNo1Mb6+/T65KZLUNTXg2twvW7T3NvAIiIi/kEYuHsrIyzJs3D1u3boVGo0G7du3w6KOP4uWXX4a/v7/SwyMFiU3M/HvhKWw+fNbq5MZesqm7iQxurhTlaK7GrZ1jcV+fGxAbEoDJa4tsduZ1lcigNljyrbiFg+GuNtAcetMaVV1p1J8giLHpkAYf7yoz+50VQpsM+yjImcScFBuCndMHy5pXYHp6wjwFInJnbBLn5o4cOQKtVosPP/wQP//8M95++20sW7YML730ktJDI4VJOTGwFStuq8yjOxDG9MecJHya1x9vjEpDoJVTFDEOnK7CXb3aoX9KjKQf+K5eCVCbhHglRATi8VuTmxuVSXDx6jXRJa0Nc1z0cf3hrfO0SJg8i/HZgd+shjYBzaFNTdffZDlP19qGBdrMK2jS6lBQch6fHziDgpLz+jFYk19cjpsXbsXoFYV4Zt0BjF5RiJsXbrX4WSUiot+9//77SEpKQmBgILKysrBnzx6rj12xYgVuueUWREVFISoqCrm5uTYfb41HnDwMGzYMw4YN03/dqVMnHD16FEuXLsWiRYsUHBkpTcqJga0mVoD1Mo8hAb6orW+SfexSRIf44/U/pGFIqhpLth7D25uPOXW9mvomfS1+sacXKgD7T1Zh+4uDzeLpfX1UeHFYd+wpvYBdxytFnyiIMWVQCp4dcqPFpmPvbTmGxVucey/cTVllLe7q1c5u2dWoED+bHdgNQ5uyU2JEl3K90nAN1VevWbymmEZrtipEWTr1ExLDxZyeEBG5DTco1bp+/XpMmzYNy5YtQ1ZWFhYvXoyhQ4fi6NGjaNu2rdnjv/vuO4wePRoDBgxAYGAgFi5ciDvuuAM///wz2rdvb+EVLPOIkwdLqqurER1tu6JHfX09ampqjG7Uukg9MbDVxAponpTunD4Yn+b1xzsPp2PNxCyEBSjfTO6VEc3VoHIWbHV64SA4e6lOUiiL8N7tP1llccdZ2InuEh8qy/gEOZ3jLIav+PqoWmWFprc3H8OmQxq7Dc/+kC7uL3rhz1hsE7WF9/WyeB0xCdFSK0TZKnhg6fSEiIh+99ZbbyEvLw8TJkxAamoqli1bhuDgYHz00UcWH79mzRo8+eSTSE9PR7du3bBy5UpotVps2bJF0ut65OLh+PHjeO+99/D444/bfNz8+fMRERGhvyUmJrbQCKklWStPaYutSbNhOIaPjwqaGuWrAJ26cBVPrC6SdSxtwwIdCmWxt+DY9LN8oSbB/r7Q6nRWJ49KNSNzJcPTMVtlV3NT1aKuZ/hnLKb08bC0BCx7NNMsDM3wMZY4shBwpmM1EZGSVDqdS24AzDa+6+vNG+A2NDRg//79yM3N1d/n4+OD3NxcFBQUiPoZrly5gsbGRrub8aYUDVuaMWMGFi5caPMxhw8fRrdu3fRfnzlzBsOGDcMDDzyAvLw8m8+dOXMmpk2bpv+6pqaGC4hWSghj+duuUszbeNju48VOmt1lcvrx96Wyno6qwwP0oSdSE8VtvXevbzyEr36qkGGEza40NGHMyt1Ww17KKq/I9lruwnDCbK9MsZQO7IIhqWqEBfih4EQlgOaFcv9OMRbDwqQkMEtZCAiV08R+vtzlc0hE1BJM56pz5szB3Llzje6rrKxEU1MT4uPjje6Pj4/HkSNHRL3O9OnT0a5dO6MFiBiKLh6ee+45jB8/3uZjOnXqpP//3377DYMGDcKAAQOwfPlyu9cPCAhAQADr93sLXx8VxuckY+XOUskTKmvcpYSr3B2w597TQz8RnHN3KiaJqF5k6b0zrJBTeq4WK3aUyjpOQbmF+PcmrQ6f7jnlktdzB4bhRpbKFEvpwC6wlI+woehXq/1PLL2uvfFKeZzYz5e7fA6JiPS0129yXxPA6dOnER4err/bFXPZBQsWYN26dfjuu+8QGCjt71hFFw9xcXGIi4sT9dgzZ85g0KBB6N27Nz7++GP4+HhkxBW5mCMTKls8rYSrPcH+vnjrwZuMJopDUtUI9vfFlQb7SeGG711+cTnmfvEzNDXmx6muYpjsXlhy3i1CylxFzITZWpK/pZ4Lrk5MdmQhIDaJW+mO1UREpgzDjOS8JgCEh4cbLR4siY2Nha+vLyoqjE/7KyoqoFbbDmtdtGgRFixYgM2bN6NXL8t5brZ4xAz8zJkzGDhwIDp06IBFixbh3Llz0Gg00Gg0Sg+N3JCYuG6x3L2Eq1QrHutjtHNfUHIef/3miKiFwzO3d9E/N7+4HJNWF7XowsEw7CW/uByT18rf6+HZ3K4IDXB8T6VfUhSmDOqMezPaOXwNFZpDycROmE2T/D/N64+d0wcb/Z63RGKysBCw9jmx9HOJTeJmvwciImP+/v7o3bu3UbKzkPycnZ1t9Xl/+ctfMG/ePOTn56NPnz4OvbZHlGrdtGkTjh8/juPHj+OGG24w+p7OQ1p5U8tyJGbb1rUs7e56moSIQPS/Xp3IUviKPWXna/WTyxn//sklYxTDWmM0Z0UF+2HK4M7oEB2EZ/9x0KFrnLpwBeMHJGN14UmHnu/ohNleiJEj+QhSOXrqJ+X0hIjIbbhBqdZp06Zh3Lhx6NOnD/r164fFixejtrYWEyZMAAA89thjaN++PebPnw8AWLhwIWbPno21a9ciKSlJvwkfGhqK0FDxlRI9YvEwfvx4u7kRRKakxmzbIixGCkvOK9KRWY5eEy/f2Q17Si9g8yENVu0qk/z8zw78ht2lF/Bgn0TZczCk+Me+X10SQlZ1pRGbDmmgjghy+Bqamno86cSJiKsmzC2VmOzoQkDOxT4Rkbd46KGHcO7cOcyePRsajQbp6enIz8/XJ1GfOnXKKMx/6dKlaGhowP333290HUsJ2baodF60dV9TU4OIiAhUV1fbjSUjskaIHQfk33Sw5oNHMvDSZ8VOTdpVKsDZT7vpjnJLc3XDvsggP7w3OgMv/Otgi4VkxYT445UR3aGOCHLZhLmg5DxGryi0+7g1/y8LPiqV0xN4w0R6LgSISCp3nq8JY7s1ZxbatJG3mMO1a3XYvmueW/7chjzi5IGoJVib8JjeL9Tft9RFt/pqo6j8AbEig/2w4N6e13dsVU7tasuxTaD0ToPWxc3CLl5txNiP9iAiqOX+ajxf2wB1RBCyU2L0eShyT7rFJCZHBvth2voDqLj0+6JJHR6IufdIPwmR89SPiIjcCxcPRLCcA5AQEYh7bkrAFwfLze6fc3cqdk4fbLSo0Gp1GLNqtyzjiQz2w4QByZgyuLN+8hgRpHynayX17xSNwhMt0yys+uq1FnkdwdlLdVZ/B+UIY7KXj6BDc9iWKU1NHSatLsIyJysxERG1Nipd803ua3oCj6i2RORKQhiSaUJpeXUdPtxeana/UNpy0yGNvhN1dkoMKmvlCXOZMigF+18ZgmdyuxiVRXVFdSFP4uzCISbEX6aRyK/03GVMsvA7KPyu5Rc737XbVhWyYH9fm8+d+e+fnKrERERErQdPHsir2SphaY0Ozbu1hj0HAPkaWeV0jjNr7GWpPj/ZFx3ihz+kt0duqhq9O0bhtje/daueHUK40Dtbjlv8vrXfNXusheBZSky+1qTF2I/22Lxe1ZVGFJ44j5zOsdJ+QCKi1kqnkyce2PSaHoCLB/Jq9kpYWmOptKWzDeWsdXCWurih31XVNuKjXWXomxwN/zY+VkN3lGArXMiQ2DKqwoJh8yEN/nPgDC7U/n5dw/An03yERf87Kmq8BSVcPBAREcOWyMs5W5rS8PlyNJQzrYPv6OKGmgkLhLlf/IxdxytRf02LqbldEB8eoOi4gOaFYmSw+DwWW7+r+cXluHnhVoxeUYhVu8qMFg6AvfAnscsopZdbRETuQ6V1zc0TcPFAXs3ZUCPT51uLK48O8cPEnCR8mtcfebckwzT6xEcF/OnWZLOkVGcXN9Q85dXU1GPMyt14Zt0BvL35GAAV+naMVGQ8kUF+WPP/srDo/pskld619rtqLWfHkK0u0tmdxJ0miH0cEZFXEMKW5L55AIYtkVdzNNTIUoiRwDCuXFNThwuX6xEd4g91RBCqahuwckep2WvpdMDy7aXI6BBltICQK4+CjFXU1EFT07ILM2G9uOC+nsjpHIvPD5wR/dwEK79rUsLarIU/9U+JQWSwn82FTGSwH/qz9CoREYGLB/JytkpYWiNMAk1DjEyvW321AX/JP2K0I+yjsvwa1hJj+yVH25zYqdDc/I2FcKRx5dulDg/Aw30T8bfvTxp1IjftsixlYWjtd82RsDbT0yxfHxUW3NsTk1Zbr+a14N6ebPJGRGRIB/n/MfGQf8u5eCCvJ4Qaie3zYDoJtMRahSRbk3xLO8ObDmls7gjr4DGnnF7j7pvaIatTLDrGhhqdOpk2fLO3MASaF4fvP5Jh9XfNkbA2S4uWYWkJWPZoJuZ+8bNRZ211eADm3tODPR6IiEiPiwciwGIJS2Gy9+Kw7hbvt8bZCknChFC4ji0h/r6oldDROjTAF7X1TS7Z3AgNaIPL9S3bXM0drdpZihU7SvVfq8MDMLpfB4e6RkcG+2GojYm7lNMLW6F2gO3PABERGVPpdFDJvHsn9/VchYsHoutMS1jau98aZyskCRNCMdeRsnAAgNSEcOwtq7LaZTjY3xdXJF5T8Jf7emHexkNeXx3K9HRJU1N/PUm7WXSIP14bmYaoEH+7CdNVVxptlmiVmrNjK9QOkP67TkRE3ofVlohk5kyFJHV4gH5n2BWVlvaUVSEi2A8RJiVCVdfnk44sHNThAVj2aCaG90rAXb0Y3mLPhdoGPLm2CCt3lIh6vK3fA7HlgRMiArH00UyGHxERyYXVlohILs5USBrdr4PsHatNCbvd92fegLBAX3z8/UmHEq6nDEpBTuc4fWjLf3/8Dat2ltp/IgEAthw5J+px9n4PrOXsxIT4Y2R6OwxJVTP8iIiIZMPFA5HMnOk0nRQbov//qtoG+NiopKRCcwjM+doGh8b5r6JfHXqeoEt8mD7EJb+4HE+u/cGp63kj1fV4MUt/xPZyFAwxX4GIqIXpAMjd1M0zDh4YtkQkN2c6TQu7zPnF5Zi8tsjuicC8kWlIiAh0uKO1M4Sxiknsbo3keM91ut/L9Fq6tr0cBUNCvsLI9PbITonhwoGIyIWEhGm5b56AiwciF7DWadqWmBB/9O4YJapak4+quYTn8F4JDi9UHKWCcdMyZxPEPYnws3/wiPmfraNz9du7xZldS80cBSIiclMMWyJyEdNQkrLKK1i8+RcAlk8mz9c24LY3v8XDfRPtTsa1OiAqJED/OpZi3l3B0o64KxK73ZHhzz4sLQFD04zDhLYe0WDFjjLJ1/3h9EUUzszF/pNVDDkiIvIUrmi05BkHD1w8ELmSaenLG9WhNif5muo6o7KethhO2oWFytubfsGSb487N2gDpjkXpg3ymrQ6VF6qt/Ls1sX0Zzf8s80vLsdKBxYOAHChthH7T1axRCoREXkELh6IWtCwtAQM7haP/vM340KteY1/KZsOplV4fH1UyOkcK8viQdjzXjI6A1EhARZ3xPOLy1vktENpf8xJslixqEmrw57SC9BUX8W8jYed2jDyltMbIqJWwxWlVT0k54GLB6IWtv9klcWFgxQ+quZqTKacqfRkyHSX3VR+cTmeWF0k+wlrZFAbBPq1QUWNc+OXiwrA18UavDzCOHFZ7oWTvXKswkKFYU1ERKQ0Lh6IWpgcu8xaHTB5bRGW+hgn1QqVnp5YXWTWRVqMyQNTcHOXOJuTUzEJ3Y5acF8vAHB4/HLTASivrjPq8iznwklMOVZLC5UEO4s7IiJyMS3kr1Qid+lXF2G1JaIWJrb52zO3d7FbwefVLw+hySApoUmrQ1iAH4alxSMkwFfSuIL9ffFMblcAwFc//oaCkvNG1xa4orqS0KV6WFqCQ5WqXG3zIQ0AeRdOYsqxCgsV0/dbU12HJ1YXIb+4XIaREBERiceTB6IWZi+0yHA32lafB9Nd8fzicsz490/6DtKCgDYq1F+zP90dfGMc+s/fggsG4VCWdrjlis+/P7M9bukaZzEMx7xSVa3oRHJXWLWrDH2ToxER5C954aQCEBLQBr4qoLrumv5+e6FhthYqQm+IV788hCGpaoYwERG1MFf0ZfCUPg9cPBC1MFuhRYa70ZWXxVUxOnupDvnF5Zi0usji98UsHADgq580ZveVX9/hNuw5IPbkxJbIYD8svP8mm5Ne80pVYYomaL/65SG8OPRGyc/TARiTlYjn7uiGvxeU4eSFK+gYHYyx2Unwb2P98NfeCY+lkCoiImohXpwwzbAlIgVYC80xbA4We72Pgz3Rwf6Y+8XPrhgmgOZJqmF4lHBy4sxe94J7e0reLR+WloCd0wcjIzHSiVd2XHl1ndGpjBQfbi9Fvzc2Y97Gw/i/gpOYt/EwbnvzW5thR2JPeFipiYiIWhJPHogUYhqaYxa+I3JufURzCZoa1/ZaMNzhdiYp29lE37/kH8YPpy869Fw5RIcGOFzNyjScTGPhVMeQ2BMeOU6CiIhIIp48EJEShNCckent9RNzgdiwpdNVV1w1PCOmTemWPpqJ+HBxpyMAMGtEd+ycPljUwqFJq0NByXl8fuCMPnG74ZoWK3aUOjR2uVy4XI8709T6nANnCP9EmCa9C+yd8KjQvBizVamJiIhIbjx5IHJTYneUO0YHu3gkzcoqa42+HpaWgLBAP4xZuVvU82PDAkSFKlkrTZqTEmMzgdzVfFTAvI2H9V+rVM5vEtnKWxCbG6NksjT7TxCR1+LJAxG5G7E7z2Ozk6AWcQLgo3Jut/zTPafMdsjFno4A4hZDtkqT/qvojOjXcgXThYvw9cScJMwa0d2pa1vLWxCTG6OU/OJy3LxwK0avKMQz6w5g9IpC3LxwK8vHEhG1clw8ELkpYecZMJ/0G+48+7fxwdx7eti9Xt4tyRavJZamph57Si8Y3Sf2dCQ6xM9ueI290qQtJTLIz+hrWxvpKgD/LdbgkayOdnty2GLrfRQSxT/N6493Hk7Hp3n9RYd/uQr7TxCR19O66OYBGLZE5MaEnWfTMB7THgHD0hKw7NFMi30eooL9MP/enhiWloCMDlFOlTs13SEXTkfsXe+1kWl2w1lc0XzOEe8/kgkfHxXOXqpD5aV6o1AlU0LY0drdJx0KqRLTYRowL1urJPafICLyblw8ELk5u1WZTB5XWHIeBScqATRPOPt3+j0R2/Bampo6zP78J1yqaxI9FtMdcsO4fGtz57t7qTFUxC650iVHhYl8f4PE9c8PiAuVOnlBetK6u+QtSMX+E0REbBJHRG5O7M6zr48KOV1ikdMl1u61CkrOS1o4WKvsY+10RPDljxrsO7nVbolWJUuOWpvIuzJp3V6HaXfV0v0nmJRNRG7JixOmuXgg8lJSJncq2N4hF040lmw9jrc3/2L2fXs9DYDfQ6Ac6aHgLGsTeXtjEk4rxmYnYeXOUruPW3T/TaisrffoSXBL9p+wVnnLExddREStBROmibyU2MldTIi/6Mo+6/aesni/vZ4GgHGCeEuICvbDnWnxmDKoMxY9cBOGpKptjsle0rqYx+V0ibXY08OTtFT/CSZlE5Fb0+pcc/MAXDwQeSl7k0AACPH3xeKH0i1OrE0VnjgvOhbeGiEEyrTikStUXWnE18UVWPLtcYxZudtqmVGx5VLduayqnMQuqJxZHImpvGVrIUpERK7DsCUiL2WrCZmgtqEJYz/aYzdUJL+4HDM2/CTqde2FSw1LS0BYgB/GrBLXfE4utkKrpCatt/YYfbFVwBzFpGwicnvMeSAiJSidDGov2Vlga2IthJeI/SsvNsR+Q7v+KTF28x+C/XxwpVG+otj2yoxKSVr3hgmtKxdKLZ2UTURE4nHxQKQQd0kGNSzx+uSa/aiuu2b2GGsTa1vhJVaJmFvaOhURnr7ogXTM23hI1gRr7mhL46qFUksmZRMROcYFJw8tXi7EMcx5IFKAuyWD+vqosO9klcWFg8BSzoIjjd0qL9eLepy9HILhvRKsxt47izvaymqppGwiIpKOJw9ELcwdO/TmF5dbLLFqieHE2pFJtpTdYnuhMWLDrlw5RpKfmJMnT2uuR0StDHMeiKiluFsyqLCYEctwYi11ku3IbrG90BjTBUbpucv4pKAMVVesn6JYI/Rj4I628lydlE1E5BStDrKHGXlIBTkuHohamLslg0oJPTKd/PdLjkZkkB8uXm0U9XxX7RYLC4z84nKs3/er0cIhOsQf92W2x1c/ltv8Obmj7X68pXoVEZEn4eKBqIW5SzKoUOnpawn5FVcbm7DpkEa/6+vro8KEnCS8vfmY3ec+m9vVpbvF1qo+VdU2YOWOUrz/SAYigvxRcKISJedqUXjiPKqu/L7o4Y62e/KW6lVE5GF02uab3Nf0AFw8ELUwIRnUWpWglgidsVTpSYzqK41mJVunDO6Cj78vw8Ur1k8f1OEBmDK4s1NjtkVMHslLnxUjsI0vNDW//8zRIf4Yld4OQ1LV3NEmIiISgdWWiFpYS3TotcVapScxLHX39fVRYcG9PS1WxlFdv829p4dLJ+Zi8kguXmk0WjgAzacSH+8qQ/XVBi4ciIhIPCFhWu6bB+DigUgB9sqQuip0xqG+DCYslWwVfp6EFv55BI7mh1haDBEREZF1DFsiUogSyaCO9GWwxnTCrmRyqzP5IWwMR0REkrHaEhEpoaWTQeWs4GRpwq5Ucqu9PBIx2BiOiIjIPoYtEXkRsTv00SF+HtXd11YeiVhsDEdERKIx54GIvIGwQ29vYfDayDT916bfB9yzF4LVPJLwAEQGe9ZiiIiI3JwOLlg8KP1DicOwJSIvIuzQP7G6CCqY/z2lA/Bw3w4YmpaApY+qPK67r7W8i02HNBZ/ZndeDBEREbkjlU7nIWckMqipqUFERASqq6sRHh6u9HCIFGOvz0PC9UVCa+rua+lnTnDzxRARkTdy5/maMLZc9Z/Qxsdf1mtf0zZgs2a5W/7chnjyQOSFhB36JVuPWewOramuM2sG5+mUrAZFRETUWnhMzsM999yDDh06IDAwEAkJCRg7dix+++03pYdF5NHW7T1t8f7W2v9AqAY1Mr09slNiuHAgIiLHaLWuuXkAj1k8DBo0CP/4xz9w9OhRbNiwASUlJbj//vuVHhaRxxLTldm0GRwRERF5N48JW3r22Wf1/9+xY0fMmDEDo0aNQmNjI/z8/Cw+p76+HvX19fqva2pqXD5OIk8htq+BO/Q/aNLqGG5ERETuwxWlVT0kDdljFg+GLly4gDVr1mDAgAFWFw4AMH/+fLz66qstODIizyG2r4HS/Q+Y6ExEROQ+PCZsCQCmT5+OkJAQxMTE4NSpU/j8889tPn7mzJmorq7W306fthzfTeSNxPZ8ULL/QX5xOZ5YXWQWXiUkdOcXlys0MiIi8mpsEqeMGTNmQKVS2bwdOXJE//gXXngBP/zwA7755hv4+vriscceg61KswEBAQgPDze6EVEzW12Z5eh/0KTVoaDkPD4/cAYFJeclJ143aXV49ctDFnvmtNaEbiIi8hBanWtuHkDRsKXnnnsO48ePt/mYTp066f8/NjYWsbGx6Nq1K7p3747ExEQUFhYiOzvbxSMlap2ErsxyN4OTI9RISkJ3dkqMQ+MkIiIiaRRdPMTFxSEuLs6h52qvl7MyTIgmIunk7n8ghBqZ7p9I7R3hSQndRETkXXQ6LXQ6eUuryn09V/GIhOndu3dj7969uPnmmxEVFYWSkhLMmjULKSkpPHUgkoHQ/8BZ9kKNVGgONRqSqra7OPGUhG4iIiJv4hEJ08HBwfj3v/+N22+/HTfeeCMmTpyIXr16Ydu2bQgICFB6eER0nZy9IzwhoZuIiLyUzgX5Dh6SMO0RJw89e/bE1q1blR4GEdkhZ6iRkND9xOoiqACj0ww5ErqJiIhIOo84eSAizyB3qJGQ0K2OMH68OiJQdO4EERGR7Ly4VKtHnDwQkWcQQo001XUW8x5UaJ74Swk1kjuhm4iIiBzHxQMRycZVoUZyJXQTERHJQqsFVDJXR/KQaksMWyIiWTHUiIiIWj2GLRERyYehRkRERK0TFw9E5BIMNSIiotZKp9VCJ3PYkqc0iWPYEhERERERicKTByIiIiIiKXQ6wGJdQWev6f548kBERERERKLw5IGIiIiISAqtDlDx5IGIiIiIiMgqnjwQEREREUmh0wGQu0kcTx6IiIiIiKgV4ckDEREREZEEOq0OOplzHnQecvLAxQMRERERkRQ6LeQPW2KTOCIiIiIiakW4eCAiIiIikkCn1bnkJtX777+PpKQkBAYGIisrC3v27LH5+H/+85/o1q0bAgMD0bNnT/z3v/+V/JpcPBAREREReZj169dj2rRpmDNnDoqKinDTTTdh6NChOHv2rMXHf//99xg9ejQmTpyIH374AaNGjcKoUaNQXFws6XVVOk/JzpBBTU0NIiIiUF1djfDwcKWHQ0REREQm3Hm+JoxtIEaijcpP1mtf0zXiO3wu+ufOyspC3759sWTJEgCAVqtFYmIinnrqKcyYMcPs8Q899BBqa2vx1Vdf6e/r378/0tPTsWzZMtHj9KqEaWGdVFNTo/BIiIiIiMgSYZ7mzvvb19AIyDy8a2gEYD5PDQgIQEBAgNF9DQ0N2L9/P2bOnKm/z8fHB7m5uSgoKLB4/YKCAkybNs3ovqFDh+Kzzz6TNE6vWjxcunQJAJCYmKjwSIiIiIjIlkuXLiEiIkLpYRjx9/eHWq3GTo30XAExQkNDzeapc+bMwdy5c43uq6ysRFNTE+Lj443uj4+Px5EjRyxeW6PRWHy8RqORNEavWjy0a9cOp0+fRlhYGFQqlc3H1tTUIDExEadPn3a7IzNPxvfVdfjeugbfV9fhe+s6fG9dg++r6xi+t2FhYbh06RLatWun9LDMBAYGorS0FA0NDS65vk6nM5ujmp46KM2rFg8+Pj644YYbJD0nPDycf0G4AN9X1+F76xp8X12H763r8L11Db6vriO8t+524mAoMDAQgYGBio4hNjYWvr6+qKioMLq/oqICarXa4nPUarWkx1vDaktERERERB7E398fvXv3xpYtW/T3abVabNmyBdnZ2Rafk52dbfR4ANi0aZPVx1vjVScPREREREStwbRp0zBu3Dj06dMH/fr1w+LFi1FbW4sJEyYAAB577DG0b98e8+fPBwA888wzuO222/DXv/4VI0aMwLp167Bv3z4sX75c0uty8WBFQEAA5syZ43ZxZp6O76vr8L11Db6vrsP31nX43roG31fX4Xsr3UMPPYRz585h9uzZ0Gg0SE9PR35+vj4p+tSpU/Dx+T3IaMCAAVi7di1eeeUVvPTSS+jSpQs+++wzpKWlSXpdr+rzQEREREREjmPOAxERERERicLFAxERERERicLFAxERERERicLFAxERERERicLFg0gbN25EVlYWgoKCEBUVhVGjRik9pFajvr4e6enpUKlUOHDggNLD8XhlZWWYOHEikpOTERQUhJSUFMyZM8dl3TBbu/fffx9JSUkIDAxEVlYW9uzZo/SQPN78+fPRt29fhIWFoW3bthg1ahSOHj2q9LBanQULFkClUmHq1KlKD6VVOHPmDB599FHExMQgKCgIPXv2xL59+5QelkdramrCrFmzjP69mjdvHljLx72xVKsIGzZsQF5eHt544w0MHjwY165dQ3FxsdLDajVefPFFtGvXDgcPHlR6KK3CkSNHoNVq8eGHH6Jz584oLi5GXl4eamtrsWjRIqWH51HWr1+PadOmYdmyZcjKysLixYsxdOhQHD16FG3btlV6eB5r27ZtmDx5Mvr27Ytr167hpZdewh133IFDhw4hJCRE6eG1Cnv37sWHH36IXr16KT2UVqGqqgo5OTkYNGgQvv76a8TFxeHYsWOIiopSemgebeHChVi6dCk++eQT9OjRA/v27cOECRMQERGBp59+WunhkRUs1WrHtWvXkJSUhFdffRUTJ05Uejitztdff41p06Zhw4YN6NGjB3744Qekp6crPaxW580338TSpUtx4sQJpYfiUbKystC3b18sWbIEQHP3zsTERDz11FOYMWOGwqNrPc6dO4e2bdti27ZtuPXWW5Uejse7fPkyMjMz8cEHH+C1115Deno6Fi9erPSwPNqMGTOwa9cu7NixQ+mhtCp33XUX4uPjsWrVKv199913H4KCgrB69WoFR0a2MGzJjqKiIpw5cwY+Pj7IyMhAQkIC7rzzTp48yKCiogJ5eXn4+9//juDgYKWH06pVV1cjOjpa6WF4lIaGBuzfvx+5ubn6+3x8fJCbm4uCggIFR9b6VFdXAwB/R2UyefJkjBgxwuh3l5zzxRdfoE+fPnjggQfQtm1bZGRkYMWKFUoPy+MNGDAAW7ZswS+//AIAOHjwIHbu3Ik777xT4ZGRLVw82CHs1M6dOxevvPIKvvrqK0RFRWHgwIG4cOGCwqPzXDqdDuPHj8ekSZPQp08fpYfTqh0/fhzvvfceHn/8caWH4lEqKyvR1NSk79QpiI+Ph0ajUWhUrY9Wq8XUqVORk5MjucspmVu3bh2Kioowf/58pYfSqpw4cQJLly5Fly5d8L///Q9PPPEEnn76aXzyySdKD82jzZgxAw8//DC6desGPz8/ZGRkYOrUqRgzZozSQyMbvHbxMGPGDKhUKps3IXYcAF5++WXcd9996N27Nz7++GOoVCr885//VPincD9i39f33nsPly5dwsyZM5UesscQ+94aOnPmDIYNG4YHHngAeXl5Co2cyLrJkyejuLgY69atU3ooHu/06dN45plnsGbNGgQGBio9nFZFq9UiMzMTb7zxBjIyMvCnP/0JeXl5WLZsmdJD82j/+Mc/sGbNGqxduxZFRUX45JNPsGjRIi7K3JzXJkw/99xzGD9+vM3HdOrUCeXl5QCA1NRU/f0BAQHo1KkTTp065coheiSx7+vWrVtRUFCAgIAAo+/16dMHY8aM4V8cFoh9bwW//fYbBg0ahAEDBmD58uUuHl3rExsbC19fX1RUVBjdX1FRAbVardCoWpcpU6bgq6++wvbt23HDDTcoPRyPt3//fpw9exaZmZn6+5qamrB9+3YsWbIE9fX18PX1VXCEnishIcFoHgAA3bt3x4YNGxQaUevwwgsv6E8fAKBnz544efIk5s+fj3Hjxik8OrLGaxcPcXFxiIuLs/u43r17IyAgAEePHsXNN98MAGhsbERZWRk6duzo6mF6HLHv67vvvovXXntN//Vvv/2GoUOHYv369cjKynLlED2W2PcWaD5xGDRokP6kzMfHaw8ZHebv74/evXtjy5Yt+tLMWq0WW7ZswZQpU5QdnIfT6XR46qmn8J///AffffcdkpOTlR5Sq3D77bfjp59+MrpvwoQJ6NatG6ZPn86FgxNycnLMygn/8ssvnAc46cqVK2b/Pvn6+uqjPsg9ee3iQazw8HBMmjQJc+bMQWJiIjp27Ig333wTAPDAAw8oPDrP1aFDB6OvQ0NDAQApKSncgXTSmTNnMHDgQHTs2BGLFi3CuXPn9N/jjrk006ZNw7hx49CnTx/069cPixcvRm1tLSZMmKD00Dza5MmTsXbtWnz++ecICwvT55BEREQgKChI4dF5rrCwMLO8kZCQEMTExDCfxEnPPvssBgwYgDfeeAMPPvgg9uzZg+XLl/NU10l33303Xn/9dXTo0EFfcfGtt97CH//4R6WHRjZw8SDCm2++iTZt2mDs2LG4evUqsrKysHXrVtZ3Jre0adMmHD9+HMePHzdbiLEyszQPPfQQzp07h9mzZ0Oj0SA9PR35+flmSdQkzdKlSwEAAwcONLr/448/thuaR6SEvn374j//+Q9mzpyJP//5z0hOTsbixYuZ2Ouk9957D7NmzcKTTz6Js2fPol27dnj88ccxe/ZspYdGNrDPAxERERERicJAaCIiIiIiEoWLByIiIiIiEoWLByIiIiIiEoWLByIiIiIiEoWLByIiIiIiEoWLByIiIiIiEoWLByIiIiIiEoWLByIiIiIiEoWLByIiN3bkyBH0798fgYGBSE9PV3o4RETk5bh4ICKvM3DgQEydOlXUY1esWIGbbroJoaGhiIyMREZGBubPn6///ty5c6FSqTBp0iSj5x04cAAqlQplZWUAgLKyMqhUKou3wsJCq68/Z84chISE4OjRo9iyZYvkn9UalUqFzz77TLbrOeLHH3/ELbfcgsDAQCQmJuIvf/mLouMhIiL72ig9ACIid/XRRx9h6tSpePfdd3Hbbbehvr4eP/74I4qLi40eFxgYiFWrVuG5555Dly5dbF5z8+bN6NGjh9F9MTExVh9fUlKCESNGoGPHjo7/IC7U0NAAf39/yc+rqanBHXfcgdzcXCxbtgw//fQT/vjHPyIyMhJ/+tOfXDBSIiKSA08eiMirjB8/Htu2bcM777yj3/kXTgdMffHFF3jwwQcxceJEdO7cGT169MDo0aPx+uuvGz3uxhtvxKBBg/Dyyy/bff2YmBio1Wqjm5+fn8XHqlQq7N+/H3/+85+hUqkwd+5cAMDp06fx4IMPIjIyEtHR0Rg5cqTRz7B3714MGTIEsbGxiIiIwG233YaioiL995OSkgAAf/jDH6BSqfRfjx8/HqNGjTIaw9SpUzFw4ED91wMHDsSUKVMwdepUxMbGYujQoQCA4uJi3HnnnQgNDUV8fDzGjh2LyspKq+/DmjVr0NDQgI8++gg9evTAww8/jKeffhpvvfWW3feQiIiUw8UDEXmVd955B9nZ2cjLy0N5eTnKy8uRmJho8bFqtRqFhYU4efKk3esuWLAAGzZswL59+2Qba3l5OXr06IHnnnsO5eXleP7559HY2IihQ4ciLCwMO3bswK5duxAaGophw4ahoaEBAHDp0iWMGzcOO3fuRGFhIbp06YLhw4fj0qVLAJoXFwDw8ccfo7y8XP+1WJ988gn8/f2xa9cuLFu2DBcvXsTgwYORkZGBffv2IT8/HxUVFXjwwQetXqOgoAC33nqr0anF0KFDcfToUVRVVUl9q4iIqIUwbImIvEpERAT8/f0RHBwMtVpt87Fz5szBvffei6SkJHTt2hXZ2dkYPnw47r//fvj4GO+9ZGZm4sEHH8T06dNt5iYMGDDA7LmXL1+2+Fi1Wo02bdogNDRUP9bVq1dDq9Vi5cqVUKlUAJoXAZGRkfjuu+9wxx13YPDgwUbXWb58OSIjI7Ft2zbcddddiIuLAwBERkbafQ8s6dKli1F+wmuvvYaMjAy88cYb+vs++ugjJCYm4pdffkHXrl3NrqHRaJCcnGx0X3x8vP57UVFRksdFRESux8UDERGAHj166E8YbrnlFnz99ddISEhAQUEBiouLsX37dnz//fcYN24cVq5cifz8fLNFwGuvvYbu3bvjm2++Qdu2bS2+zvr169G9e3eHx3nw4EEcP34cYWFhRvfX1dWhpKQEAFBRUYFXXnkF3333Hc6ePYumpiZcuXIFp06dcvh1DfXu3dtsTN9++y1CQ0PNHltSUmJx8UBERJ6JiwciIgD//e9/0djYCAAICgoy+l5aWhrS0tLw5JNPYtKkSbjllluwbds2DBo0yOhxKSkpyMvLw4wZM7Bq1SqLr5OYmIjOnTs7PM7Lly+jd+/eWLNmjdn3hBOFcePG4fz583jnnXfQsWNHBAQEIDs7Wx/WZI2Pjw90Op3RfcJ7YigkJMRsTHfffTcWLlxo9tiEhASLr6VWq1FRUWF0n/C1I6chRETUMrh4ICKv4+/vj6amJqP7xFYzSk1NBQDU1tZa/P7s2bORkpKCdevWOTdIKzIzM7F+/Xq0bdsW4eHhFh+za9cufPDBBxg+fDiA5gRr0+RlPz8/s/cgLi7OrJLUgQMHrCZ0G45pw4YNSEpKQps24v5Zyc7Oxssvv4zGxkb99Tdt2oQbb7yRIUtERG6MCdNE5HWSkpKwe/dulJWVobKyElqt1uLjnnjiCcybNw+7du3CyZMnUVhYiMceewxxcXHIzs62+Jz4+HhMmzYN7777rsXvnz9/HhqNxuhWV1cneuxjxoxBbGwsRo4ciR07dqC0tBTfffcdnn76afz6668AmnMS/v73v+Pw4cPYvXs3xowZY3aakpSUhC1btkCj0egTlAcPHox9+/bh//7v/3Ds2DHMmTPHbDFhyeTJk3HhwgWMHj0ae/fuRUlJCf73v/9hwoQJZgsUwSOPPAJ/f39MnDgRP//8M9avX4933nkH06ZNE/1eEBFRy+PigYi8zvPPPw9fX1+kpqYiLi7Oai5Abm4uCgsL8cADD6Br16647777EBgYiC1bttjszfD8889bjP8XrpmQkGB0k9KsLTg4GNu3b0eHDh1w7733onv37pg4cSLq6ur0JxGrVq1CVVUVMjMzMXbsWDz99NNmORh//etfsWnTJiQmJiIjIwNAc7WjWbNm4cUXX0Tfvn1x6dIlPPbYY3bH1K5dO+zatQtNTU2444470LNnT0ydOhWRkZFmeSGCiIgIfPPNNygtLUXv3r3x3HPPYfbs2ezxQETk5lQ60wBXIiIiIiIiC3jyQEREREREonDxQEREREREonDxQEREREREonDxQEREREREonDxQEREREREonDxQEREREREonDxQEREREREonDxQEREREREonDxQEREREREonDxQEREREREonDxQEREREREovx/Q8FlEh/UxD4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}